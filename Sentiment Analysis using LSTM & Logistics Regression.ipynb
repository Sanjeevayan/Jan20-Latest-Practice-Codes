{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/KumarSanjeev/Downloads/sentiment labelled sentences/yelp_labelled.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "path = \"/Users/KumarSanjeev/Downloads/sentiment labelled sentences/yelp_labelled.txt\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(path,sep=\"\\t\",names=[\"Tweet\",\"Sentiment\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[\"Tweet\"]\n",
    "y=data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 670)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 330)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "X_train=vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 1616)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 1616)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarsanjeev/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796969696969697"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarsanjeev/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libraries.....\n"
     ]
    }
   ],
   "source": [
    "print(\"importing libraries.....\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 25000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  171,   26,   75],\n",
       "       [   0,    0,    0, ...,  810,  318,  229],\n",
       "       [   0,    0,    0, ...,   37,   40,  811],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   28,   33, 1867],\n",
       "       [   0,    0,    0, ...,  115,   72,  385],\n",
       "       [   0,    0,    0, ...,  806,  292,  510]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words,300, input_length=max_len))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 300)          7500000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 7,660,501\n",
      "Trainable params: 7,660,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 680 samples, validate on 170 samples\n",
      "Epoch 1/10\n",
      "680/680 [==============================] - 4s 6ms/step - loss: 0.6916 - acc: 0.5574 - val_loss: 0.6898 - val_acc: 0.5647\n",
      "Epoch 2/10\n",
      "680/680 [==============================] - 2s 4ms/step - loss: 0.6740 - acc: 0.7103 - val_loss: 0.6887 - val_acc: 0.5059\n",
      "Epoch 3/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.6366 - acc: 0.7147 - val_loss: 0.6699 - val_acc: 0.5824\n",
      "Epoch 4/10\n",
      "680/680 [==============================] - 2s 4ms/step - loss: 0.5505 - acc: 0.8515 - val_loss: 0.6154 - val_acc: 0.7000\n",
      "Epoch 5/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.4375 - acc: 0.8721 - val_loss: 0.6219 - val_acc: 0.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2eb2aa58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5523098889986674, 0.686666669845581]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)\n",
    "accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.552\n",
      "  Accuracy: 0.687\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "model1.add(Dense(100,input_dim=input_dim,activation=\"relu\"))\n",
    "model1.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               161700    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 172,202\n",
      "Trainable params: 172,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/25\n",
      "670/670 [==============================] - 0s 239us/step - loss: 0.0708 - acc: 0.9985 - val_loss: 0.4593 - val_acc: 0.8000\n",
      "Epoch 2/25\n",
      "670/670 [==============================] - 0s 175us/step - loss: 0.0522 - acc: 0.9985 - val_loss: 0.4641 - val_acc: 0.8152\n",
      "Epoch 3/25\n",
      "670/670 [==============================] - 0s 175us/step - loss: 0.0396 - acc: 0.9985 - val_loss: 0.4839 - val_acc: 0.8182\n",
      "Epoch 4/25\n",
      "670/670 [==============================] - 0s 170us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.5290 - val_acc: 0.8061\n",
      "Epoch 5/25\n",
      "670/670 [==============================] - 0s 168us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.8152\n",
      "Epoch 6/25\n",
      "670/670 [==============================] - 0s 197us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5730 - val_acc: 0.8152\n",
      "Epoch 7/25\n",
      "670/670 [==============================] - 0s 170us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.5776 - val_acc: 0.8152\n",
      "Epoch 8/25\n",
      "670/670 [==============================] - 0s 155us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.8182\n",
      "Epoch 9/25\n",
      "670/670 [==============================] - 0s 165us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8061\n",
      "Epoch 10/25\n",
      "670/670 [==============================] - 0s 157us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8121\n",
      "Epoch 11/25\n",
      "670/670 [==============================] - 0s 161us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.8152\n",
      "Epoch 12/25\n",
      "670/670 [==============================] - 0s 158us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.8182\n",
      "Epoch 13/25\n",
      "670/670 [==============================] - 0s 158us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.8152\n",
      "Epoch 14/25\n",
      "670/670 [==============================] - 0s 238us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.6370 - val_acc: 0.8121\n",
      "Epoch 15/25\n",
      "670/670 [==============================] - 0s 245us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.6431 - val_acc: 0.8091\n",
      "Epoch 16/25\n",
      "670/670 [==============================] - 0s 273us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.8121\n",
      "Epoch 17/25\n",
      "670/670 [==============================] - 0s 267us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.8121\n",
      "Epoch 18/25\n",
      "670/670 [==============================] - 0s 254us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.6701 - val_acc: 0.8091\n",
      "Epoch 19/25\n",
      "670/670 [==============================] - 0s 235us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.6752 - val_acc: 0.8121\n",
      "Epoch 20/25\n",
      "670/670 [==============================] - 0s 281us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.8121\n",
      "Epoch 21/25\n",
      "670/670 [==============================] - 0s 216us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6861 - val_acc: 0.8121\n",
      "Epoch 22/25\n",
      "670/670 [==============================] - 0s 261us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6973 - val_acc: 0.8121\n",
      "Epoch 23/25\n",
      "670/670 [==============================] - 0s 203us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.8121\n",
      "Epoch 24/25\n",
      "670/670 [==============================] - 0s 169us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7078 - val_acc: 0.8121\n",
      "Epoch 25/25\n",
      "670/670 [==============================] - 0s 177us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7206 - val_acc: 0.8121\n"
     ]
    }
   ],
   "source": [
    "history=model1.fit(X_train,y_train,epochs=25,validation_data=[X_test,y_test],batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 0s 45us/step\n",
      "Training Accuracy: 1.00000\n",
      "0.002734439439181961 1.0\n",
      "330/330 [==============================] - 0s 53us/step\n",
      "Training Accuracy: 0.8121\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model1.evaluate(X_train,y_train)\n",
    "print(\"Training Accuracy: {:.5f}\".format(accuracy))\n",
    "\n",
    "loss,accuracy=model1.evaluate(X_test,y_test)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Watch, 'VERB'),\n",
      " (live, 'ADJ'),\n",
      " (stream, 'NOUN'),\n",
      " (of, 'ADP'),\n",
      " (the, 'DET'),\n",
      " (ICC, 'PROPN'),\n",
      " (U-19, 'PROPN'),\n",
      " (World, 'PROPN'),\n",
      " (Cup, 'PROPN'),\n",
      " (2020, 'NUM'),\n",
      " (semi, 'NOUN'),\n",
      " (-, 'PUNCT'),\n",
      " (final, 'ADJ'),\n",
      " (between, 'ADP'),\n",
      " (India, 'PROPN'),\n",
      " (U-19, 'PROPN'),\n",
      " (and, 'CCONJ'),\n",
      " (Pakistan, 'PROPN'),\n",
      " (U-19, 'PROPN')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "doc=nlp(\"Watch live stream of the ICC U-19 World Cup 2020 semi-final between India U-19 and Pakistan U-19\")\n",
    "a= [(token,token.pos_) for token in doc]\n",
    "pprint(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
