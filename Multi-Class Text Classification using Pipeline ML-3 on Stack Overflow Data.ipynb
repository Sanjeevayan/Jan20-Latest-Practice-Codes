{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://github.com/nxs5899/Multi-Class-Text-Classification----Random-Forest/blob/master/multi-class-classifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kumarsanjeev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sqlite3 import Error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sqlite3\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path= \"/Users/KumarSanjeev/Desktop/Training Data/spam.csv\"\n",
    "path= \"/Users/KumarSanjeev/Desktop/Training Data/stack-overflow-data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(path,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is causing this behavior  in our c# datet...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have dynamic html load as if it was in an ifra...</td>\n",
       "      <td>asp.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to convert a float value in to min:sec  i ...</td>\n",
       "      <td>objective-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net framework 4 redistributable  just wonderi...</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying to calculate and print the mean and its...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post         tags\n",
       "0  what is causing this behavior  in our c# datet...           c#\n",
       "1  have dynamic html load as if it was in an ifra...      asp.net\n",
       "2  how to convert a float value in to min:sec  i ...  objective-c\n",
       "3  .net framework 4 redistributable  just wonderi...         .net\n",
       "4  trying to calculate and print the mean and its...       python"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(columns=[\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.groupby(\"v1\").v2.count().plot.bar(ylim=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "data['cleaned'] = data['v2'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is causing this behavior  in our c# datet...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have dynamic html load as if it was in an ifra...</td>\n",
       "      <td>asp.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to convert a float value in to min:sec  i ...</td>\n",
       "      <td>objective-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net framework 4 redistributable  just wonderi...</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying to calculate and print the mean and its...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>different output if at end of function rather ...</td>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>multiple arrays  is there a way to access/stor...</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>c - how to differentiate a second same key pre...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>state.go not working (#! &amp; url is being append...</td>\n",
       "      <td>angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>understanding the mechanisms of intentservice ...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post         tags\n",
       "0      what is causing this behavior  in our c# datet...           c#\n",
       "1      have dynamic html load as if it was in an ifra...      asp.net\n",
       "2      how to convert a float value in to min:sec  i ...  objective-c\n",
       "3      .net framework 4 redistributable  just wonderi...         .net\n",
       "4      trying to calculate and print the mean and its...       python\n",
       "...                                                  ...          ...\n",
       "39995  different output if at end of function rather ...          c++\n",
       "39996  multiple arrays  is there a way to access/stor...       iphone\n",
       "39997  c - how to differentiate a second same key pre...            c\n",
       "39998  state.go not working (#! & url is being append...    angularjs\n",
       "39999  understanding the mechanisms of intentservice ...      android\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[\"post\"]\n",
    "y=data[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 165790)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(data['post']).toarray()\n",
    "final_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarsanjeev/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         .net       0.58      0.67      0.62       487\n",
      "      android       0.89      0.87      0.88       507\n",
      "    angularjs       0.97      0.97      0.97       516\n",
      "      asp.net       0.74      0.72      0.73       500\n",
      "            c       0.76      0.85      0.81       510\n",
      "           c#       0.58      0.59      0.58       502\n",
      "          c++       0.76      0.73      0.75       499\n",
      "          css       0.79      0.83      0.81       499\n",
      "         html       0.66      0.64      0.65       520\n",
      "          ios       0.58      0.60      0.59       493\n",
      "       iphone       0.63      0.57      0.60       501\n",
      "         java       0.87      0.80      0.83       488\n",
      "   javascript       0.77      0.76      0.76       490\n",
      "       jquery       0.84      0.87      0.86       515\n",
      "        mysql       0.79      0.84      0.81       511\n",
      "  objective-c       0.66      0.65      0.66       498\n",
      "          php       0.86      0.84      0.85       474\n",
      "       python       0.94      0.91      0.93       485\n",
      "ruby-on-rails       0.98      0.92      0.95       501\n",
      "          sql       0.80      0.80      0.80       504\n",
      "\n",
      "    micro avg       0.77      0.77      0.77     10000\n",
      "    macro avg       0.77      0.77      0.77     10000\n",
      " weighted avg       0.77      0.77      0.77     10000\n",
      "\n",
      "[[324   4   1  50   7  52   9   0  11   4   0   2   3   2   4   4   1   3\n",
      "    1   5]\n",
      " [  9 441   0   2   2   9   2   1   4  14   8   6   1   0   1   1   2   0\n",
      "    1   3]\n",
      " [  1   0 501   0   0   2   0   1   3   0   0   0   6   0   1   0   0   0\n",
      "    1   0]\n",
      " [ 42   7   2 361   2  26   3   2  18   0   7   0   4   8   5   5   0   1\n",
      "    0   7]\n",
      " [ 12   2   0   1 435  15  19   3   2   1   3   5   1   0   0   4   1   4\n",
      "    0   2]\n",
      " [ 68   7   0  16  17 295  21   0  12   5   6  17   9   3   4   3   6   5\n",
      "    1   7]\n",
      " [ 20   1   0   1  64  22 365   0   2   2   1   6   3   0   0   4   2   3\n",
      "    1   2]\n",
      " [  6   0   2   6   0   0   2 413  47   1   1   0   5  11   0   1   3   1\n",
      "    0   0]\n",
      " [  5   3   4  19   1   2   1  78 335   2   0   3  31  16   0   3  15   2\n",
      "    0   0]\n",
      " [ 10  12   0   6   5   6   3   2   7 295  71   1   3   0   1  67   2   1\n",
      "    1   0]\n",
      " [ 15   6   0   5   1   5   5   1   6 104 284   2   2   0   1  62   2   0\n",
      "    0   0]\n",
      " [  9   8   0   5   8  38  12   1   6   0   1 390   1   1   0   3   1   2\n",
      "    0   2]\n",
      " [  7   2   6   5   3   6   6   5  21   3   2   9 370  32   0   1  11   1\n",
      "    0   0]\n",
      " [  2   0   0   2   1   1   3  10  18   0   0   0  26 447   1   0   2   0\n",
      "    0   2]\n",
      " [  1   0   0   0   0   3   0   0   0   0   2   0   0   0 431   0  10   1\n",
      "    1  62]\n",
      " [  8   2   0   1   8  13   8   0   1  67  59   2   3   0   0 322   2   0\n",
      "    1   1]\n",
      " [  6   1   0   4   4   7   4   3   8   1   4   3  11   4   8   1 398   2\n",
      "    1   4]\n",
      " [  3   0   0   0   8   6  10   3   2   1   0   1   2   0   3   3   2 441\n",
      "    0   0]\n",
      " [  1   1   2   0   1   1   5   2   7   4   1   0   0   4   6   1   2   1\n",
      "  461   1]\n",
      " [  7   0   0   2   3   1   1   0   0   1   1   1   0   1  81   0   2   0\n",
      "    1 402]]\n"
     ]
    }
   ],
   "source": [
    "# this block is to split the dataset into training and testing set \n",
    "X = data['post']\n",
    "Y = data['tags']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# instead of doing these steps one at a time, we can use a pipeline to complete then all at once\n",
    "pipeline = Pipeline([('vect', vectorizer),\n",
    "                     ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "with open('RandomForest.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libraries.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarsanjeev/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print(\"importing libraries.....\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,SpatialDropout1D,MaxPool1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'numbers')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)\n",
    "plt.title(\"ham-spam breakup\")\n",
    "plt.xlabel(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le= LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 836)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTokenize the data and convert the text to sequences.\\nAdd padding to ensure that all the sequences have the same shape.\\nThere are many ways of taking the max_len and here an arbitrary length of 150 is chosen.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenize the data and convert the text to sequences.\n",
    "Add padding to ensure that all the sequences have the same shape.\n",
    "There are many ways of taking the max_len and here an arbitrary length of 150 is chosen.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x1a31e6ac88>\n"
     ]
    }
   ],
   "source": [
    "print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  47, 351],\n",
       "       [  0,   0,   0, ...,  20,  14,   9],\n",
       "       [  0,   0,   0, ...,   2,  27, 130],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 384, 242, 809],\n",
       "       [  0,   0,   0, ..., 728,  79, 411],\n",
       "       [  0,   0,   0, ...,  94, 670,   2]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(max_words,100, input_length=max_len))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,SpatialDropout1D,MaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option2: Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# model = Sequential()\n",
    "# model.add(keras.layers.Embedding(input_dim = max_words, \n",
    "#                            output_dim=100, \n",
    "#                            input_length=max_len))\n",
    "# model.add(keras.layers.GlobalMaxPool1D())\n",
    "# model.add(keras.layers.Dense(10, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 150, 100)          100000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101,021\n",
      "Trainable params: 101,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option3: Adding CNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# model = Sequential()\n",
    "# model.add(keras.layers.Embedding(input_dim = max_words, \n",
    "#                            output_dim=100, \n",
    "#                            input_length=max_len))\n",
    "# model.add(keras.layers.GlobalMaxPool1D())\n",
    "# model.add(keras.layers.Dense(10, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          100000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 128)          64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 165,429\n",
      "Trainable params: 165,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=max_words, output_dim=100, input_length=max_len))\n",
    "model.add(keras.layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(10, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 3s 843us/step - loss: 0.4488 - acc: 0.8683 - val_loss: 0.3698 - val_acc: 0.8639\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 3s 709us/step - loss: 0.2807 - acc: 0.8823 - val_loss: 0.1622 - val_acc: 0.9589\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 3s 684us/step - loss: 0.0864 - acc: 0.9794 - val_loss: 0.0572 - val_acc: 0.9884\n",
      "Epoch 4/10\n",
      "3788/3788 [==============================] - 3s 664us/step - loss: 0.0363 - acc: 0.9905 - val_loss: 0.0489 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "3788/3788 [==============================] - 3s 674us/step - loss: 0.0226 - acc: 0.9947 - val_loss: 0.0454 - val_acc: 0.9905\n",
      "Epoch 6/10\n",
      "3788/3788 [==============================] - 3s 667us/step - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0437 - val_acc: 0.9905\n",
      "Epoch 7/10\n",
      "3788/3788 [==============================] - 3s 671us/step - loss: 0.0095 - acc: 0.9987 - val_loss: 0.0432 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      "3788/3788 [==============================] - 3s 698us/step - loss: 0.0063 - acc: 0.9995 - val_loss: 0.0437 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3219eac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 0s 211us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.040595826639406134, 0.9904306220095693]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)\n",
    "accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.041\n",
      "  Accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(200, 32, input_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 2], [41, 39], [16, 48], [46, 39], [16], [13], [12, 48], [26, 41], [12, 39], [11, 36, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  2  0  0]\n",
      " [41 39  0  0]\n",
      " [16 48  0  0]\n",
      " [46 39  0  0]\n",
      " [16  0  0  0]\n",
      " [13  0  0  0]\n",
      " [12 48  0  0]\n",
      " [26 41  0  0]\n",
      " [12 39  0  0]\n",
      " [11 36  2  1]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length,padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6894 - acc: 0.8000\n",
      "Epoch 2/45\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.6882 - acc: 0.8000\n",
      "Epoch 3/45\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.6869 - acc: 0.8000\n",
      "Epoch 4/45\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.6857 - acc: 0.8000\n",
      "Epoch 5/45\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.6845 - acc: 0.8000\n",
      "Epoch 6/45\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.6833 - acc: 0.8000\n",
      "Epoch 7/45\n",
      "10/10 [==============================] - 0s 127us/step - loss: 0.6820 - acc: 0.8000\n",
      "Epoch 8/45\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.6808 - acc: 0.8000\n",
      "Epoch 9/45\n",
      "10/10 [==============================] - 0s 137us/step - loss: 0.6795 - acc: 0.9000\n",
      "Epoch 10/45\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.6783 - acc: 0.9000\n",
      "Epoch 11/45\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.6771 - acc: 0.9000\n",
      "Epoch 12/45\n",
      "10/10 [==============================] - 0s 128us/step - loss: 0.6758 - acc: 0.9000\n",
      "Epoch 13/45\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.6746 - acc: 0.9000\n",
      "Epoch 14/45\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.6733 - acc: 0.9000\n",
      "Epoch 15/45\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.6721 - acc: 0.9000\n",
      "Epoch 16/45\n",
      "10/10 [==============================] - 0s 130us/step - loss: 0.6708 - acc: 0.9000\n",
      "Epoch 17/45\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.6695 - acc: 0.9000\n",
      "Epoch 18/45\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.6683 - acc: 0.9000\n",
      "Epoch 19/45\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.6670 - acc: 0.9000\n",
      "Epoch 20/45\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.6657 - acc: 0.9000\n",
      "Epoch 21/45\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.6644 - acc: 0.8000\n",
      "Epoch 22/45\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.6631 - acc: 0.8000\n",
      "Epoch 23/45\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.6618 - acc: 0.8000\n",
      "Epoch 24/45\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.6605 - acc: 0.8000\n",
      "Epoch 25/45\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.6592 - acc: 0.8000\n",
      "Epoch 26/45\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.6578 - acc: 0.8000\n",
      "Epoch 27/45\n",
      "10/10 [==============================] - 0s 138us/step - loss: 0.6565 - acc: 0.8000\n",
      "Epoch 28/45\n",
      "10/10 [==============================] - 0s 283us/step - loss: 0.6551 - acc: 0.8000\n",
      "Epoch 29/45\n",
      "10/10 [==============================] - 0s 366us/step - loss: 0.6537 - acc: 0.8000\n",
      "Epoch 30/45\n",
      "10/10 [==============================] - 0s 712us/step - loss: 0.6523 - acc: 0.8000\n",
      "Epoch 31/45\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.6510 - acc: 0.8000\n",
      "Epoch 32/45\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.6496 - acc: 0.8000\n",
      "Epoch 33/45\n",
      "10/10 [==============================] - 0s 325us/step - loss: 0.6481 - acc: 0.8000\n",
      "Epoch 34/45\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.6467 - acc: 0.8000\n",
      "Epoch 35/45\n",
      "10/10 [==============================] - 0s 498us/step - loss: 0.6453 - acc: 0.8000\n",
      "Epoch 36/45\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.6438 - acc: 0.8000\n",
      "Epoch 37/45\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.6423 - acc: 0.8000\n",
      "Epoch 38/45\n",
      "10/10 [==============================] - 0s 262us/step - loss: 0.6409 - acc: 0.8000\n",
      "Epoch 39/45\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.6394 - acc: 0.8000\n",
      "Epoch 40/45\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.6378 - acc: 0.8000\n",
      "Epoch 41/45\n",
      "10/10 [==============================] - 0s 328us/step - loss: 0.6363 - acc: 0.8000\n",
      "Epoch 42/45\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.6348 - acc: 0.8000\n",
      "Epoch 43/45\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.6333 - acc: 0.8000\n",
      "Epoch 44/45\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.6317 - acc: 0.8000\n",
      "Epoch 45/45\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.6301 - acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a36820278>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs,labels,epochs=45,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=model.evaluate(padded_docs,labels,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicGET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\n"
     ]
    }
   ],
   "source": [
    "num=51\n",
    "a=0\n",
    "b=1\n",
    "\n",
    "for i in range(0,num):\n",
    "    c=a+b\n",
    "    a=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic:  GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\n"
     ]
    }
   ],
   "source": [
    "print(\"toxic:  \" + data[\"comment_text\"][51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
