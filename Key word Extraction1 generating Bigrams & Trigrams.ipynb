{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/KumarSanjeev/Downloads/nips-papers/papers.csv\"\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>5745</td>\n",
       "      <td>2015</td>\n",
       "      <td>Distributionally Robust Logistic Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5745-distributionally-robust-logistic-regressi...</td>\n",
       "      <td>This paper proposes a distributionally robust ...</td>\n",
       "      <td>Distributionally Robust Logistic Regression\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>5746</td>\n",
       "      <td>2015</td>\n",
       "      <td>On some provably correct cases of variational ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5746-on-some-provably-correct-cases-of-variati...</td>\n",
       "      <td>Variational inference is an efficient, popular...</td>\n",
       "      <td>On some provably correct cases of variational\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>5747</td>\n",
       "      <td>2015</td>\n",
       "      <td>Extending Gossip Algorithms to Distributed Est...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5747-extending-gossip-algorithms-to-distribute...</td>\n",
       "      <td>Efficient and robust algorithms for decentrali...</td>\n",
       "      <td>Extending Gossip Algorithms to\\nDistributed Es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>5748</td>\n",
       "      <td>2015</td>\n",
       "      <td>The Self-Normalized Estimator for Counterfactu...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5748-the-self-normalized-estimator-for-counter...</td>\n",
       "      <td>This paper identifies a severe problem of the ...</td>\n",
       "      <td>The Self-Normalized Estimator for Counterfactu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>5749</td>\n",
       "      <td>2015</td>\n",
       "      <td>Frank-Wolfe Bayesian Quadrature: Probabilistic...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5749-frank-wolfe-bayesian-quadrature-probabili...</td>\n",
       "      <td>There is renewed interest in formulating integ...</td>\n",
       "      <td>Frank-Wolfe Bayesian Quadrature: Probabilistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>994</td>\n",
       "      <td>1994</td>\n",
       "      <td>Single Transistor Learning Synapses</td>\n",
       "      <td>NaN</td>\n",
       "      <td>994-single-transistor-learning-synapses.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Single Transistor Learning Synapses\\n\\nPaul Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>996</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bias, Variance and the Combination of Least Sq...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>996-bias-variance-and-the-combination-of-least...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bias, Variance and the Combination of\\nLeast S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>997</td>\n",
       "      <td>1994</td>\n",
       "      <td>A Real Time Clustering CMOS Neural Engine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>997-a-real-time-clustering-cmos-neural-engine.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Real Time Clustering CMOS\\nNeural Engine\\nT....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7239</th>\n",
       "      <td>998</td>\n",
       "      <td>1994</td>\n",
       "      <td>Learning direction in global motion: two class...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>998-learning-direction-in-global-motion-two-cl...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Learning direction in global motion: two\\nclas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>999</td>\n",
       "      <td>1994</td>\n",
       "      <td>Correlation and Interpolation Networks for Rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999-correlation-and-interpolation-networks-for...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Correlation and Interpolation Networks for\\nRe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                              title  \\\n",
       "5241  5745  2015        Distributionally Robust Logistic Regression   \n",
       "5242  5746  2015  On some provably correct cases of variational ...   \n",
       "5243  5747  2015  Extending Gossip Algorithms to Distributed Est...   \n",
       "5244  5748  2015  The Self-Normalized Estimator for Counterfactu...   \n",
       "5245  5749  2015  Frank-Wolfe Bayesian Quadrature: Probabilistic...   \n",
       "...    ...   ...                                                ...   \n",
       "7236   994  1994                Single Transistor Learning Synapses   \n",
       "7237   996  1994  Bias, Variance and the Combination of Least Sq...   \n",
       "7238   997  1994          A Real Time Clustering CMOS Neural Engine   \n",
       "7239   998  1994  Learning direction in global motion: two class...   \n",
       "7240   999  1994  Correlation and Interpolation Networks for Rea...   \n",
       "\n",
       "     event_type                                           pdf_name  \\\n",
       "5241  Spotlight  5745-distributionally-robust-logistic-regressi...   \n",
       "5242  Spotlight  5746-on-some-provably-correct-cases-of-variati...   \n",
       "5243  Spotlight  5747-extending-gossip-algorithms-to-distribute...   \n",
       "5244  Spotlight  5748-the-self-normalized-estimator-for-counter...   \n",
       "5245  Spotlight  5749-frank-wolfe-bayesian-quadrature-probabili...   \n",
       "...         ...                                                ...   \n",
       "7236        NaN        994-single-transistor-learning-synapses.pdf   \n",
       "7237        NaN  996-bias-variance-and-the-combination-of-least...   \n",
       "7238        NaN  997-a-real-time-clustering-cmos-neural-engine.pdf   \n",
       "7239        NaN  998-learning-direction-in-global-motion-two-cl...   \n",
       "7240        NaN  999-correlation-and-interpolation-networks-for...   \n",
       "\n",
       "                                               abstract  \\\n",
       "5241  This paper proposes a distributionally robust ...   \n",
       "5242  Variational inference is an efficient, popular...   \n",
       "5243  Efficient and robust algorithms for decentrali...   \n",
       "5244  This paper identifies a severe problem of the ...   \n",
       "5245  There is renewed interest in formulating integ...   \n",
       "...                                                 ...   \n",
       "7236                                   Abstract Missing   \n",
       "7237                                   Abstract Missing   \n",
       "7238                                   Abstract Missing   \n",
       "7239                                   Abstract Missing   \n",
       "7240                                   Abstract Missing   \n",
       "\n",
       "                                             paper_text  \n",
       "5241  Distributionally Robust Logistic Regression\\n\\...  \n",
       "5242  On some provably correct cases of variational\\...  \n",
       "5243  Extending Gossip Algorithms to\\nDistributed Es...  \n",
       "5244  The Self-Normalized Estimator for Counterfactu...  \n",
       "5245  Frank-Wolfe Bayesian Quadrature: Probabilistic...  \n",
       "...                                                 ...  \n",
       "7236  Single Transistor Learning Synapses\\n\\nPaul Ha...  \n",
       "7237  Bias, Variance and the Combination of\\nLeast S...  \n",
       "7238  A Real Time Clustering CMOS\\nNeural Engine\\nT....  \n",
       "7239  Learning direction in global motion: two\\nclas...  \n",
       "7240  Correlation and Interpolation Networks for\\nRe...  \n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'title', 'event_type', 'pdf_name', 'abstract',\n",
       "       'paper_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['abstract'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: word_count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"word_count\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           abstract  word_count\n",
       "0  Abstract Missing           2\n",
       "1  Abstract Missing           2\n",
       "2  Abstract Missing           2\n",
       "3  Abstract Missing           2\n",
       "4  Abstract Missing           2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"abstract\",\"word_count\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7241.000000\n",
       "mean       81.331308\n",
       "std        80.297257\n",
       "min         2.000000\n",
       "25%         2.000000\n",
       "50%        89.000000\n",
       "75%       148.000000\n",
       "max       317.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         29793\n",
       "of          20918\n",
       "a           16339\n",
       "and         13626\n",
       "to          12869\n",
       "in           8980\n",
       "that         7838\n",
       "is           7666\n",
       "for          7169\n",
       "We           6238\n",
       "on           5579\n",
       "we           5167\n",
       "with         4512\n",
       "this         3677\n",
       "as           3643\n",
       "are          3529\n",
       "an           3366\n",
       "Abstract     3323\n",
       "Missing      3318\n",
       "by           3197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify common words\n",
    "freq = pd.Series(' '.join(data['abstract']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver-based             1\n",
       "evasion.                 1\n",
       "mean/mode                1\n",
       "365x                     1\n",
       "wavelet.                 1\n",
       "(billion                 1\n",
       "maximum-flow             1\n",
       "(DP),                    1\n",
       "similarities)            1\n",
       "security's               1\n",
       "representativeness,      1\n",
       "Mozer,                   1\n",
       "l)                       1\n",
       "(depending               1\n",
       "wants,                   1\n",
       "training?                1\n",
       "founded,                 1\n",
       "(characteristic)         1\n",
       "$\\MO$($n^2$)             1\n",
       "approximate-inference    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify common words\n",
    "\n",
    "freq1 = pd.Series(' '.join(data['abstract']).split()).value_counts()[-20:]\n",
    "freq1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invers'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = \"inversely\"\n",
    "stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inversely'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'non negative matrix factorization nmf previously shown useful decomposition multivariate data two different multi plicative algorithm nmf analyzed differ slightly multiplicative factor used update rule one algorithm shown minimize conventional least square error minimizes generalized kullback leibler divergence monotonic convergence algorithm proven using auxiliary func tion analogous used proving convergence expectation maximization algorithm algorithm also interpreted diag onally rescaled gradient descent rescaling factor optimally chosen ensure convergence', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'spike triggered averaging technique effective linear characterization neural response neuron exhibit important nonlinear behavior gain control captured analysis describe spike triggered covariance method retrieving suppressive component gain control signal neuron demonstrate method simulation retinal ganglion cell data analysis physiological data reveals significant suppressive ax explains neural nonlinearities method applicable sensory area modality', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'known determinining whether dec pomdp namely cooperative partially observable stochastic game posg cooperative strategy positive expected reward complete nexp known cooperation affected complexity show competitive posgs complexity determining whether one team positive expected reward strategy complete class nexp oracle np', 'present first truly polynomial algorithm learning structure bounded treewidth junction tree attractive subclass probabilistic graphical model permit compact representation probability distribution efficient exact inference constant treewidth algorithm polynomial time sample complexity provides strong theoretical guarantee term kl divergence true distribution also present lazy extension approach lead significant speed ups practice demonstrate viability method empirically several real world datasets one key new theoretical insight method bounding conditional mutual information arbitrarily large set random variable polynomial number mutual information computation fixed size subset variable underlying distribution approximated bounded treewidth junction tree', 'abstract missing', 'abstract missing', 'semi supervised inductive learning concern learn decision rule data set containing labeled unlabeled data several boosting algorithm extended semi supervised learning various strategy knowledge however none take local smoothness constraint among data account ensemble learning paper introduce local smoothness regularizer semi supervised boosting algorithm based universal optimization framework margin cost functionals regularizer applicable existing semi supervised boosting algorithm improve generalization speed training comparative result synthetic benchmark real world task demonstrate effectiveness local smoothness regularizer discus relevant issue relate regularizer previous work', 'show suitable assumption primarily linearization simple perspicuous online learning rule information bottleneck optimization spiking neuron derived rule performs common benchmark task well rather complex rule previously proposed cite klampfletal b furthermore transparency new learning rule make theoretical analysis convergence property feasible variation learning rule sign change provides theoretically founded method performing principal component analysis pca spiking neuron applying rule ensemble neuron different principal component input extracted addition possible preferentially extract principal component incoming signal x related related additional target signal biological interpretation target signal also called relevance variable could represent proprioceptive feedback input sensory modality top signal', 'natural viewing condition human observer shift gaze allocate processing resource subset visual input many computational model aimed predicting voluntary attentional shift although importance high level stimulus property higher order statistic semantics stand undisputed model based low level feature input alone study recorded eye movement human observer viewed photograph natural scene two third stimulus contained least one person demonstrate combined model face detection low level saliency clearly outperforms low level model predicting location human fixate reflected finding fact observes even instructed look anything particular fixate face probability within first two fixation m remarkably model predictive performance image contain face impaired spurious face detector response suggestive bottom mechanism face detection summary provide novel computational approach combine high level object knowledge case face location low level feature successfully predict allocation attentional resource', 'abstract missing', 'abstract missing', 'large repository source code create new challenge opportunity statistical machine learning first develop infrastructure automated crawling parsing database storage open source software infrastructure allows u gather internet scale source code instance one experiment gather java project sourceforge apache totaling million line code developer simple statistical analysis data first reveal robust power law behavior package sloc method call distribution develop apply unsupervised author topic probabilistic model automatically discover topic embedded code extract topic word author topic distribution addition serving convenient summary program function developer activity related distribution provide statistical information theoretic basis quantifying analyzing developer similarity competence topic scattering document tangling direct application software engineering finally combining software textual content structural information captured coderank approach able significantly improve software retrieval performance increasing auc metric roughly better previous approach based text alone', 'construct biologically motivated stochastic differential model neural hemodynamic activity underlying observed blood oxygen level dependent bold signal functional magnetic resonance imaging fmri model pose difficult parameter estimation problem theoretically due nonlinearity divergence differential system computationally due time space complexity adapt particle filter smoother task discus practical approach used tackle difficulty including use sparse matrix parallelisation result demonstrate tractability approach application effective connectivity study', 'abstract missing', 'independent component analysis ica powerful method decouple signal algorithm performing ica consider temporal correlation signal higher moment amplitude distribution moreover require preprocessing data whitening remove second order correlation paper interested understanding neural mechanism responsible solving ica present online learning rule exploit delayed correlation input rule performs ica detecting joint variation firing rate pre postsynaptic neuron similar local rate based hebbian learning rule', 'abstract missing', 'present theoretical study discriminative clustering framework recently proposed simultaneous subspace selection via linear discriminant analysis lda clustering empirical result shown favorable performance comparison several popular clustering algorithm however inherent relationship subspace selection clustering framework well understood due iterative nature algorithm show paper iterative subspace selection clustering equivalent kernel k mean specific kernel gram matrix provides significant new insight nature subspace selection procedure based equivalence relationship propose discriminative k mean diskmeans algorithm simultaneous lda subspace selection clustering well automatic parameter estimation procedure also present nonlinear extension diskmeans using kernel show learning kernel matrix convex set pre specified kernel matrix incorporated clustering formulation connection diskmeans several clustering algorithm also analyzed presented theory algorithm evaluated experiment collection benchmark data set', 'abstract missing', 'present epoch greedy algorithm multi armed bandit observable side information epoch greedy following property knowledge time horizon necessary regret incurred epoch greedy controlled sample complexity bound hypothesis class regret scale better sometimes much better complexity term sample complexity bound standard supervised learning', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'present new local approximation algorithm computing map log partition function arbitrary exponential family distribution represented finite valued pair wise markov random field mrf say g algorithm based decomposing g appropriately chosen small component computing estimate locally component producing good global solution prove algorithm provide approximate solution within arbitrary accuracy g excludes finite sized graph minor g bounded degree planar graph bounded degree example graph running time algorithm theta n n number node g constant dependent accuracy degree graph size graph excluded minor constant planar graph algorithm minor excluded graph us decomposition scheme klein plotkin rao general algorithm work decomposition scheme provides quantifiable approximation guarantee depends decomposition scheme', 'abstract missing', 'propose new approach dealing estimation location change point one dimensional piecewise constant signal observed white noise approach consists reframing task variable selection context use penalized least square criterion l type penalty purpose prove appropriate asymptotic framework method provides consistent estimator change point explain implement method practice combining lar algorithm reduced version dynamic programming algorithm apply synthetic real data', 'abstract missing', 'abstract missing', 'propose model leverage million click received web search engine predict document relevance allows comparison ranking function click available complete relevance judgment initial training phase using set relevance judgment paired click data show model predict relevance score document judged prediction used evaluate performance search engine using novel formalization confidence standard evaluation metric discounted cumulative gain dcg comparison made across time datasets contrast previous method provide pair wise relevance judgement result shown query relevance judgment available identify better two ranked list time two relevance judgment query identify better ranking time experiment sponsored search result financial backbone web search method general enough applicable algorithmic web search result well furthermore give algorithm guide selection additional document judge improve confidence', 'propose novel method em linear dimensionality reduction manifold modeled data first show small number em random projection sample point real n belonging unknown k dimensional euclidean manifold intrinsic dimension id sample set estimated high accuracy second rigorously prove using set random projection estimate structure underlying manifold case number random projection required linear k logarithmic n meaning k n handle practical situation develop greedy algorithm estimate smallest size projection space required perform manifold learning method particularly relevant distributed sensing system lead significant potential saving data acquisition storage transmission cost', 'abstract missing', 'abstract missing', 'abstract missing', 'present simple variant k tree automatically adapts intrinsic low dimensional structure data', 'present probabilistic approach language change word form represented phoneme sequence undergo stochastic edits along branch phylogenetic tree framework combine advantage classical comparative method robustness corpus based probabilistic model use framework explore consequence two different scheme defining probabilistic model phonological change evaluating scheme using reconstruction ancient word form romance language result efficient inference procedure automatically inferring ancient word form modern language generalized support inference linguistic phylogeny', 'provide provably efficient algorithm learning markov decision process mdps continuous state action space online setting specifically take model based approach show special type online linear regression allows u learn mdps possibly kernalized linearly parameterized dynamic result build kearns singh work provides provably efficient algorithm finite state mdps approach restricted linear setting applicable class continuous mdps', 'abstract missing', 'address problem adaptive sensor control dynamic resource constrained sensor network focus meteorological sensing network comprising radar perform sector scanning rather always scanning degree compare three sector scanning strategy sit spin strategy always scan degree limited lookahead strategy additionally us expected environmental state k decision epoch future predicted kalman filter decision making full lookahead strategy us expected future state casting problem markov decision process using reinforcement learning estimate optimal scan strategy show main benefit using lookahead strategy multiple meteorological phenomenon environment maximum radius phenomenon sufficiently smaller radius radar also show trade average quality phenomenon scanned number decision epoch phenomenon rescanned', 'abstract missing', 'abstract missing', 'present novel message passing algorithm approximating map problem graphical model algorithm similar structure max product unlike max product always converges proven find exact map solution various setting algorithm derived via block coordinate descent dual lp relaxation map require tunable parameter step size tree weight also describe generalization method cluster based potential new method tested synthetic real world problem compare favorably previous approach', 'abstract missing', 'support vector machine svms suffer widely recognized scalability problem memory use computational time improve scalability developed parallel svm algorithm psvm reduces memory use performing row based approximate matrix factorization load essential data machine perform parallel computation let n denote number training instance p reduced matrix dimension factorization p significantly smaller n number machine psvm reduces memory requirement mo n mo np improves computation time mo np empirical study computer show psvm effective', 'becoming increasingly important learn partially observed random matrix predict missing element assume entire matrix single sample drawn matrix variate distribution suggest matrix variate model mvtm predict missing element show mvtm generalizes range known probabilistic model automatically performs model selection encourage sparse predictive model due non conjugacy prior difficult make prediction computing mode mean posterior distribution suggest optimization method sequentially minimizes convex upper bound log likelihood efficient scalable experiment toy data eachmovie dataset show good predictive accuracy model', 'biological movement built sub block motion primitive primitive provide compact representation movement also desirable robotic control application analyse handwriting data gain better understanding use primitive timing biological movement inference shape timing primitive done using factorial hmm based model allowing handwriting represented primitive timing space representation provides distribution spike corresponding primitive activation also modelled using hmm architecture show coupling low level primitive model higher level timing model inference produce good reconstruction handwriting shared primitive character modelled coupled model also capture variance profile dataset accounted spike timing jitter timing code provides compact representation movement generating movement without explicit timing model produce scribbling style output', 'abstract missing', 'study following question two dimensional structure image strong prior something learned example natural image someone gave u learning task involving image two dimensional topology pixel known could discover automatically exploit example suppose pixel permuted fixed unknown way could recover relative two dimensional location pixel image surprising result presented answer yes thousand image enough approximately recover relative location thousand pixel achieved using manifold learning algorithm applied pixel associated measure distributional similarity pixel intensity compare different topology extraction approach show two dimensional topology exploited', 'abstract missing', 'abstract missing', 'new algorithm line learning linear threshold function proposed efficiently combine second order statistic data logarithmic behavior multiplicative dual norm algorithm initial theoretical analysis provided suggesting algorithm might viewed standard perceptron algorithm operating transformed sequence example improved margin property also report experiment carried datasets diverse domain goal comparing known perceptron algorithm first order second order additive multiplicative learning procedure seems generalize quite well converges faster corresponding multiplicative baseline algorithm', 'abstract missing', 'fair discriminative pedestrian finder available fact pedestrian finder make error pedestrian configuration uncommon training data example mounting bicycle undesirable however human configuration estimated discriminatively using structure learning demonstrate pedestrian finder first find likely human pose window using discriminative procedure trained structure learning small dataset present feature local histogram oriented gradient local pca gradient based configuration svm classifier show using inria person dataset estimate configuration significantly improve accuracy discriminative pedestrian finder', 'show use unlabeled data deep belief net dbn learn good covariance kernel gaussian process first learn deep generative model unlabeled data using fast greedy algorithm introduced hinton et al data high dimensional highly structured gaussian kernel applied top layer feature dbn work much better similar kernel applied raw input performance regression classification improved using backpropagation dbn discriminatively fine tune covariance kernel', 'empirical risk minimization offer well known learning guarantee training test data come domain real world though often wish adapt classifier source domain large amount training data different target domain little training data work give uniform convergence bound algorithm minimize convex combination source target empirical risk bound explicitly model inherent trade training large inaccurate source data set small accurate target training set theory also give result multiple source domain may different number instance exhibit case minimizing non uniform combination source risk achieve much lower target error standard empirical risk minimization', 'line handwriting recognition unusual among sequence labelling task underlying generator observed data e movement pen recorded directly however raw data difficult interpret letter spread many pen location consequence sophisticated pre processing required obtain input suitable conventional sequence labelling algorithm hmms paper describe system capable directly transcribing raw line handwriting data system consists recurrent neural network trained sequence labelling combined probabilistic language model experiment unconstrained line database record excellent result using either raw pre processed data well outperforming benchmark hmm case', 'abstract missing', 'abstract missing', 'peristimulus time historgram psth continuous cousin spike density function sdf staple analytic toolkit neurophysiologists former usually obtained binning spiketrains whereas standard method latter smoothing gaussian kernel selection bin kernel size often done relatively arbitrary fashion even though recent attempt remedy situation cite shimazakibinningnips shimazakibinningneco develop exact bayesian generative model approach estimating pshts demonstate superiority competing method advantage scheme include automatic complexity control error bar prediction', 'abstract missing', 'abstract missing', 'propose active learning algorithm learns continuous valuation model discrete preference algorithm automatically decides item best presented individual order find item value highly trial possible exploit quirk human psychology minimize time cognitive burden algorithm maximizes expected improvement query without accurately modelling entire valuation surface would needlessly expensive problem particularly difficult space choice infinite demonstrate effectiveness new algorithm compared related active learning method also embed algorithm within decision making tool assisting digital artist rendering material tool find best parameter minimizing number query', 'abstract missing', 'stimulus selectivity sensory neuron often characterized estimating receptive field property orientation selectivity receptive field usually derived mean covariance spike triggered stimulus ensemble approach treat spike independent message take account information might conveyed pattern neural activity distributed across space time find concise description processing whole population neuron analogous receptive field single neuron present generalization linear receptive field bound triggered individual spike meaningfully linked distributed response pattern precisely seek identify stimulus feature corresponding pattern neural activity reliably coupled use extension reverse correlation method based canonical correlation analysis resulting population receptive field span subspace stimulus informative population response evaluate approach using neuronal model multi electrode recording rabbit retinal ganglion cell show model extended capture nonlinear stimulus response relationship using kernel canonical correlation analysis make possible test different coding mechanism technique also used calculate receptive field multi dimensional neural measurement obtained dynamic imaging method', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'reliably recovering human pose monocular video requires constraint bias estimate towards typical human pose motion define prior people tracking using laplacian eigenmaps latent variable model lelvm lelvm probabilistic dimensionality reduction model naturally combine advantage latent variable model definining multimodal probability density latent observed variable globally differentiable nonlinear mapping reconstruction dimensionality reduction spectral manifold learning method local optimum ability unfold highly nonlinear manifold good practical scaling latent space high dimension lelvm computationally efficient simple learn sparse training data compatible standard probabilistic tracker particle filter analyze performance lelvm based probabilistic sigma point mixture tracker several real synthetic human motion sequence demonstrate lelvm provides sufficient constraint robust operation presence missing noisy ambiguous image measurement', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'consider continuous state continuous action batch reinforcement learning goal learn good policy sufficiently rich trajectory generated another policy study variant fitted q iteration greedy action selection replaced searching policy restricted set candidate policy maximizing average action value provide rigorous theoretical analysis algorithm proving believe first finite time bound value function based algorithm continuous state action space problem', 'guided goal obtaining optimization algorithm fast yielding good generalization study descent direction maximizing decrease generalization error probability increasing generalization error surprising result bayesian frequentist perspective yield natural gradient direction although direction expensive compute develop efficient general online approximation natural gradient descent suited large scale problem report experimental result showing much faster convergence computation time number iteration tonga topmoumoute online natural gradient algorithm stochastic gradient descent even large datasets', 'important problem many field analysis count data extract meaningful latent component method like probabilistic latent semantic analysis plsa latent dirichlet allocation lda proposed purpose however limited number component extract also provision control expressiveness extracted component paper present learning formulation address limitation employing notion sparsity start plsa framework use entropic prior maximum posteriori formulation enforce sparsity show allows extraction overcomplete set latent component better characterize data present experimental evidence utility representation', 'traditional analysis method single trial classification electro encephalography eeg focus two type paradigm phase locked method amplitude signal used feature classification e event related potential second order method feature interest power signal e event related de synchronization process deciding paradigm use ad hoc driven knowledge neurological finding propose unified method algorithm learns best first second order spatial temporal feature classification eeg based bilinear model efficiency method demonstrated simulated real eeg benchmark data set brain computer interface', 'shown adapting dictionary basis function statistic natural image maximize sparsity coefficient result set dictionary element whose spatial property resemble v primary visual cortex receptive field however resulting sparse coefficient still exhibit pronounced statistical dependency thus violating independence assumption sparse coding model propose model attempt capture dependency among basis function coefficient including pairwise coupling term prior coefficient activity state adapted statistic natural image coupling term learn combination facilitatory inhibitory interaction among neighboring basis function learned interaction may offer explanation function horizontal connection v discus implication finding physiological experiment', 'abstract missing', 'notion algorithmic stability used effectively past derive tight generalization bound key advantage bound de signed specific learning algorithm exploiting particular property much learning theory existing stability analysis bound apply scenario sample independently identically distributed many machine learning application however assumption hold observation received learning algorithm often inherent temporal dependence clear system diagnosis time series prediction problem paper study scenario observation drawn station ary beta mixing sequence implies dependence observation weaken time prof novel stability based generalization bound hold even general setting bound strictly generalize bound given case also illustrate application case several general class learning algorithm including support vector regression kernel ridge regression', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'paper explores use maximal average margin mam optimality principle design learning algorithm shown application risk minimization principle result class computationally simple learning machine similar classical parzen window classifier direct relation rademacher complexity established facilitating analysis providing notion certainty prediction analysis related support vector machine mean margin transformation power mam principle illustrated application ordinal regression task resulting n algorithm able process large datasets reasonable time', 'sound localization barn owl commonly modeled matching procedure localization cue derived auditory input compared stored template matching model explain property neural response model explains owl resolve spatial ambiguity localization cue produce accurate localization near center gaze examine two model barn owl sound localization behavior first consider maximum likelihood estimator order evaluate cue matching model second consider maximum posteriori estimator test bayesian model prior emphasizes direction near center gaze reproduce owl localization behavior show maximum likelihood estimator reproduce owl behavior maximum posteriori estimator able match behavior result suggests standard cue matching model sufficient explain sound localization behavior barn owl bayesian model provides new framework analyzing sound localization barn owl lead prediction owl localization behavior', 'abstract missing', 'abstract missing', 'abstract missing', 'training test sample follow different input distribution e situation called emph covariate shift maximum likelihood estimator known lose consistency regaining consistency log likelihood term need weighted according emph importance e ratio test training input density thus accurately estimating importance one key task covariate shift adaptation naive approach first estimate training test input density estimate importance ratio density estimate however since density estimation hard problem approach tends perform poorly especially high dimensional case paper propose direct importance estimation method require input density estimate method equipped natural model selection procedure tuning parameter kernel width objectively optimized advantage recently developed method direct importance estimation simulation illustrate usefulness approach', 'study relation notion game theoretic equilibrium based stability set deviation empirical equilibrium reached rational player rational player modelled player using regret algorithm guarantee payoff long run almost much could hope achieve consistently deviating algorithm suggested action show given set deviation strategy set player possible efficiently approximate fixed point given deviation exist efficient regret algorithm resistant deviation show player use regret algorithm empirical distribution play converges equilibrium', 'abstract missing', 'planning partially observable environment remains challenging problem despite significant recent advance offline approximation technique online method also proposed recently proven remarkably scalable without theoretical guarantee offline counterpart thus seems natural try unify offline online technique preserving theoretical property former exploiting scalability latter paper provide theoretical guarantee anytime algorithm pomdps aim reduce error made approximate offline value iteration algorithm use efficient online searching procedure algorithm us search heuristic based error analysis lookahead search guide online search towards reachable belief potential reduce error provide general theorem showing search heuristic admissible lead complete epsilon optimal algorithm best knowledge strongest theoretical result available online pomdp solution method also provide empirical evidence showing approach also practical find provably near optimal solution reasonable time', 'abstract missing', 'multiple instance mi learning problem instance naturally organized bag bag instead individual instance labeled training mi learner assume every instance bag labeled negative actually negative whereas least one instance bag labeled positive actually positive present framework active learning multiple instance setting particular consider case mi learner allowed selectively query unlabeled instance positive bag approach well motivated domain inexpensive acquire bag label possible expensive acquire instance label describe method learning label mixed level granularity introduce two active query selection strategy motivated mi setting experiment show learning instance label significantly improve performance basic mi learning algorithm two multiple instance domain content based image recognition text classification', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'describe novel noisy logical distribution representing distribution binary output variable conditioned multiple binary input variable distribution represented term noisy noisy causal feature conjunction binary input standard noisy noisy model used causal reasoning artificial intelligence special case noisy logical distribution prove noisy logical distribution complete sense represent conditional distribution provided sufficient number causal factor used illustrate noisy logical distribution showing account new experimental finding human perform causal reasoning complex context finally speculate use noisy logical distribution causal reasoning artificial intelligence', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'present new analysis combination binary classifier propose theoretical framework based neyman pearson lemma analyze combination classifier particular give method finding optimal decision rule combination classifier prove optimal roc curve also show method generalizes improves previous work combining classifier generating roc curve', 'classical hypothesis bottom saliency center surround process combined recent hypothesis saliency decision optimal decision theoretic sense combined hypothesis denoted discriminant center surround saliency corresponding optimal saliency architecture derived architecture equates saliency image location discriminant power set feature respect classification problem opposes stimulus center surround location shown resulting saliency detector make accurate quantitative prediction various aspect psychophysics human saliency including non linear property beyond reach previous saliency model furthermore shown discriminant center surround saliency easily generalized various stimulus modality color orientation motion provides optimal solution many saliency problem interest computer vision optimal solution hypothesis derived number former including static natural image dense motion field even dynamic texture applied number latter prediction human eye fixation motion based saliency presence ego motion motion based saliency presence highly dynamic background result discriminant saliency shown predict eye fixation better previous model produce background subtraction algorithm outperform state art computer vision', 'cascade detector shown operate extremely rapidly high accuracy important application face detection driven success cascade earning area active research recent year nevertheless still challenging technical problem training process cascade detector particular determining optimal target detection rate stage cascade remains unsolved issue paper propose multiple instance pruning mip algorithm soft cascade algorithm computes set threshold aggressively terminate computation reduction detection rate increase false positive rate training dataset algorithm based two key insight example destined rejected complete classifier safely pruned early ii face detection multiple instance learning problem mip process fully automatic requires assumption probability distribution statistical independence ad hoc intermediate rejection target experimental result mit cmu dataset demonstrate significant performance advantage', 'abstract missing', 'abstract missing', 'abstract missing', 'present novel linear clustering framework diffrac relies linear discriminative cost function convex relaxation combinatorial optimization problem large convex optimization problem solved sequence lower dimensional singular value decomposition framework several attractive property although apparently similar k mean exhibit superior clustering performance k mean particular term robustness noise readily extended non linear clustering discriminative cost function based positive definite kernel seen alternative spectral clustering prior information partition easily incorporated leading state art performance semi supervised learning clustering classification present empirical evaluation algorithm synthetic real medium scale datasets', 'abstract missing', 'abstract missing', 'abstract missing', 'many task speech processing involve classification long term characteristic speech segment language speaker dialect topic natural technique determining characteristic first convert input speech sequence token word phone etc token look distinctive phrase keywords characterize speech many application set distinctive keywords may known priori case automatic method building keywords short context unit phone desirable propose method construction keywords based upon support vector machine cast problem keyword selection feature selection problem n gram phone propose alternating filter wrapper method build successively longer keywords application method language recognition task show technique produce interesting significant qualitative quantitative result', 'abstract missing', 'abstract missing', 'consider estimation problem gaussian graphical model arbitrary structure analyze embedded tree algorithm solves sequence problem tractable subgraphs thereby leading solution estimation problem intractable graph analysis based recently developed walk sum interpretation gaussian estimation show non stationary iteration embedded tree algorithm using sequence subgraphs converge walk summable model based walk sum calculation develop adaptive method optimize choice subgraphs used iteration view achieving maximum reduction error adaptive procedure provide significant speedup convergence stationary iterative method also appear converge larger class model', 'abstract missing', 'abstract missing', 'recent year language model latent dirichlet allocation lda cluster co occurring word topic widely appled computer vision field however many application difficulty modeling spatial temporal structure among visual word since lda assumes document bag word also critical properly design word document using language model solve vision problem paper propose topic model spatial latent dirichlet allocation slda better encodes spatial structure among visual word essential solving many vision problem spatial information encoded value visual word design document instead knowing partition word document textit priori word document assignment becomes random hidden variable slda generative procedure knowledge spatial structure flexibly added prior grouping visual word close space document use slda discover object collection image show achieves better performance lda', 'describe efficient learning procedure multilayer generative model combine best aspect markov random field deep directed belief net generative model learned one layer time learning complete fast inference procedure computing good approximation posterior distribution hidden layer hidden layer mrf whose energy function modulated top directed connection layer generate model layer turn must settle equilibrium given top input show type model good capturing statistic patch natural image', 'abstract missing', 'recent research studied role sparsity high dimensional regression signal reconstruction establishing theoretical limit recovering sparse model sparse data paper study variant problem original n input variable compressed random linear transformation n example p dimension establish condition sparse linear model successfully recovered compressed data primary motivation compression procedure anonymize data preserve privacy revealing little information original data characterize number random projection required ell regularized compressed regression identify nonzero coefficient true model probability approaching one property called sparsistence addition show ell regularized compressed regression asymptotically predicts well oracle linear model property called persistence finally characterize privacy property compression procedure information theoretic term establishing upper bound rate information communicated compressed uncompressed data decay zero', 'abstract missing', 'diffusion process family continuous time continuous state stochastic process general partially observed joint estimation forcing parameter system noise volatility dynamical system crucial non trivial task especially system nonlinear multi modal propose variational treatment diffusion process allows u estimate parameter simple gradient technique computationally le demanding mcmc approach furthermore parameter inference scheme break time step get smaller unlike current approach finally show cheap estimate posterior parameter constructed based variational free energy', 'abstract missing', 'paper develop gaussian process gp framework model collection reciprocal random variable defined emph edge network show construct gp prior e covariance function edge directed undirected bipartite graph model suggests intimate connection emph link prediction emph transfer learning traditionally considered two separate research topic though straightforward gp inference high complexity develop efficient learning algorithm handle large number observation experimental result several real world data set verify superior learning capacity', 'loopy belief propagation employed wide variety application great empirical success come theoretical guarantee paper investigate use max product form belief propagation weighted matching problem general graph show max product converges correct answer linear programming lp relaxation weighted matching problem tight converge lp relaxation loose provides exact characterization max product performance reveals connection widely used optimization technique lp relaxation addition demonstrate max product effective solving practical weighted matching problem distributed fashion applying problem self organization sensor network', 'using multiple regularization hyperparameters effective method managing model complexity problem input feature varying amount noise algorithm choosing multiple hyperparameters often used neural network support vector machine common structured prediction task sequence labeling parsing paper consider problem learning regularization hyperparameters log linear model class probabilistic model structured prediction task includes conditional random field crfs using implicit differentiation trick derive efficient gradient based method learning gaussian regularization prior multiple hyperparameters simulation real world task computational rna secondary structure prediction find multiple hyperparameter learning provides significant boost accuracy compared model learned using single regularization hyperparameter', 'abstract missing', 'abstract missing', 'paper describes new model human visual classification enables recovery image feature explain human subject performance different visual classification task unlike previous method algorithm model performance single linear classifier operating raw image pixel instead model classification combination multiple feature detector approach extract information human visual classification previously possible method provides foundation exploration', 'abstract missing', 'abstract missing', 'abstract missing', 'web server internet need maintain high reliability cause intermittent failure web transaction non obvious use bayesian inference diagnose problem web service diagnosis problem far larger previously attempted requires inference possible fault observation inference must performed le second inference done speed combining variational approximation mean field approximation use stochastic gradient descent optimize variational cost function use fast inference diagnose time series anomalous http request taken real web service inference fast enough analyze network log billion entry matter hour', 'abstract missing', 'article discus latent variable model inference prediction symmetric relational data model based idea eigenvalue decomposition represents relationship two node weighted inner product node specific vector latent characteristic eigenmodel generalizes popular latent variable model latent class distance model shown mathematically latent class distance model representation eigenmodel vice versa practical implication examined context three real datasets eigenmodel good better sample predictive performance two model', 'active learning sequentially selects unlabeled instance label goal reducing effort needed learn good classifier previous study active learning focused selecting one unlabeled instance one time retraining iteration however single instance selection system unable exploit parallelized labeler one available recently batch mode active learning approach proposed select set informative unlabeled instance iteration guided heuristic score paper propose discriminative batch mode active learning approach formulates instance selection task continuous optimization problem auxiliary instance selection variable optimization formuated maximize discriminative classification performance target classifier also taking unlabeled data account although objective convex manipulate quasi newton method obtain good local solution empirical study uci datasets show proposed active learning effective current state art batch mode active learning algorithm', 'markov jump process play important role large number application domain however realistic system analytically intractable traditionally analysed using simulation based technique provide framework statistical inference propose mean field approximation perform posterior inference parameter estimation approximation allows practical solution inference problem still retaining good degree accuracy illustrate approach two biologically motivated system', 'control high dimensional continuous non linear system key problem reinforcement learning control local trajectory based method using technique differential dynamic programming ddp directly subject curse dimensionality generate local controller paper introduce receding horizon ddp rh ddp extension classic ddp algorithm allows u construct stable robust controller based library local control trajectory demonstrate effectiveness approach series high dimensional control problem using simulated multi link swimming robot experiment show approach effectively circumvents dimensionality issue capable dealing effectively problem least state action dimension', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'consider learning task consisting predicting well best function finite reference set g smallest possible additive term r g denotes generalization error prediction function g reasonable assumption loss function typically satisfied least square loss output bounded known progressive mixture rule g n satisfies e r g n min g g r g cst log g n n denotes size training set e denotes expectation wrt training set distribution work show surprisingly appropriate reference set g deviation convergence rate progressive mixture rule better cst sqrt n expected cst n also provides algorithm suffer drawback', 'paper introduces kernel attributed pointsets set vector embedded euclidean space embedding give notion neighborhood used define positive semidefinite kernel pointsets two novel kernel neighborhood proposed one evaluating attribute similarity evaluating shape similarity shape similarity function motivated spectral graph matching technique kernel tested three real life application face recognition photo album tagging shot annotation video sequence encouraging result', 'present general boosting method extending functional gradient boosting optimize complex loss function encountered many machine learning problem approach based optimization quadratic upper bound loss function allows u present rigorous convergence analysis algorithm importantly general framework enables u use standard regression base learner decision tree fitting loss function illustrate application proposed method learning ranking function web search combining preference data labeled data training present experimental result web search using data commercial search engine show significant improvement proposed method existing method', 'abstract missing', 'abstract missing', 'abstract missing', 'address problem factorial learning associate set latent cause feature observed data factorial model usually assume feature single occurrence given data point however data image latent feature multiple occurrence e g visual object class multiple instance shown image deal case present probability model non negative integer valued matrix possibly unbounded number column model play role prior nonparametric bayesian learning scenario latent feature number occurrence unknown use prior together likelihood model unsupervised learning image using markov chain monte carlo inference algorithm', 'abstract missing', 'abstract missing', 'abstract missing', 'computational model visual cortex particular based sparse coding enjoyed much recent attention despite currency question sparse complete sparse representation gone without principled answer use bayesian model selection method address question sparse coding model based student prior validated method toy data find natural image indeed best modelled extremely sparse distribution although student prior associated optimal basis size modestly overcomplete', 'motivated part hierarchical organization cortex number algorithm recently proposed try learn hierarchical deep structure unlabeled data several author formally informally compared algorithm computation performed visual area v cochlea little attempt made thus far evaluate algorithm term fidelity mimicking computation deeper level cortical hierarchy paper present unsupervised learning model faithfully mimic certain property visual area v specifically develop sparse variant deep belief network hinton et al learn two layer node network demonstrate first layer similar prior work sparse coding ica result localized oriented edge filter similar gabor function known model v cell receptive field second layer model encodes correlation first layer response data specifically pick collinear contour feature well corner junction interestingly quantitative comparison encoding complex corner feature match well result ito komatsu study biological v response suggests sparse variant deep belief network hold promise modeling higher order feature', 'abstract missing', 'abstract missing', 'summarize implementation analog vlsi chip hosting network integrate fire neuron spike frequency adaptation hebbian plastic bistable spike driven stochastic synapsis endowed self regulating mechanism stop unnecessary synaptic change synaptic matrix flexibly configured provides recurrent aer based connectivity external aer compliant device demonstrate ability network efficiently classify overlapping pattern thanks self regulating mechanism', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'functional magnetic resonance imaging fmri provides unprecedented window complex functioning human brain typically detailing activity thousand voxels hundred sequential time point unfortunately interpretation fmri complicated due relatively unknown connection hemodynamic response neural activity unknown spatiotemporal characteristic cognitive pattern use data experience based cognition competition compare global local method prediction applying linear nonlinear technique dimensionality reduction build global low dimensional representation fmri dataset using linear nonlinear method learn set time series implicit function fmri data predict value time series future knowledge fmri data find effective low dimensional model based principal component cognitive activity classically defined anatomical region brodmann area furthermore stimulus top predictive region stable across subject episode including wernicke area verbal instruction visual cortex facial body feature visual temporal region brodmann area velocity interpretation relative simplicity approach provide transparent conceptual basis upon build sophisticated technique fmri decoding knowledge first time classical area used fmri effective prediction complex natural experience', 'abstract missing', 'abstract missing', 'contribution develops theoretical framework take account effect approximate optimization learning algorithm analysis show distinct tradeoff case small scale large scale learning problem small scale learning problem subject usual approximation estimation tradeoff large scale learning problem subject qualitatively different tradeoff involving computational complexity underlying optimization algorithm non trivial way', 'abstract missing', 'abstract missing', 'propose method reconstruction human brain state directly functional neuroimaging data method extends traditional multivariate regression analysis discretized fmri data domain stochastic functional measurement facilitating evaluation brain response naturalistic stimulus boosting power functional imaging method search set voxel timecourses optimize multivariate functional linear model term rsquare statistic population based incremental learning used search spatially distributed voxel cluster taking account variation haemodynamic lag across brain area among subject voxel wise non linear registration stimulus fmri data method capture spatially distributed brain response naturalistic stimulus without attempting localize function application method prediction naturalistic stimulus new unknown fmri data show approach capable identifying distributed cluster brain location highly predictive specific stimulus', 'abstract missing', 'introduce supervised latent dirichlet allocation slda statistical model labelled document model accommodates variety response type derive maximum likelihood procedure parameter estimation relies variational approximation handle intractable posterior expectation prediction problem motivate research use fitted model predict response value new document test slda two real world problem movie rating predicted review web page popularity predicted text description illustrate benefit slda versus modern regularized regression well versus unsupervised lda analysis followed separate regression', 'present algorithm called optimistic linear programming olp learning optimize average reward irreducible otherwise unknown markov decision process mdp olp us experience far estimate mdp chooses action optimistically maximizing estimated future reward set next state transition probability close estimate computation corresponds solving linear program show total expected reward obtained olp time within c p log reward obtained optimal policy c p explicit mdp dependent constant olp closely related algorithm proposed burnetas katehakis four key difference olp simpler require knowledge support transition probability proof regret bound simpler regret bound constant factor larger regret algorithm olp also similar flavor algorithm recently proposed auer ortner olp simpler regret bound better dependence size mdp', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'binocular fusion take place limited region smaller one degree visual angle panum fusional area order range preferred disparity measured population disparity tuned neuron visual cortex however actual range binocular disparity encountered natural scene range ten degree discrepancy suggests must mechanism detecting whether stimulus disparity either inside outside range preferred disparity population present statistical framework derive feature population v disparity neuron determine stimulus disparity within preferred disparity range neural population optimized natural image yield feature explained normalization common model v neuron make use feature estimate disparity natural image proposed model generates correct estimate coarse fine multiple scale approach also identify region occlusion approach suggests another critical role normalization robust disparity estimation', 'propose test homogeneity two sample using kernel fisher discriminant analysis provides u consistent nonparametric test statistic derive asymptotic distribution null hypothesis give experimental evidence relevance method artificial real datasets', 'abstract missing', 'abstract missing', 'abstract missing', 'paper propose method support vector machine classification using indefinite kernel instead directly minimizing stabilizing nonconvex loss function method simultaneously find support vector proxy kernel matrix used computing loss interpreted robust classification problem indefinite kernel matrix treated noisy observation true positive semidefinite kernel formulation keep problem convex relatively large problem solved efficiently using analytic center cutting plane method compare performance technique method several data set', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'propose gaussian process gp framework robust inference gp prior mixing weight two component noise model augments standard process latent function value approach generalization mixture likelihood used traditional robust gp regression specialization gp mixture model suggested tresp rasmussen ghahramani value restriction tractable expectation propagation update allow faster inference model selection better convergence standard mixture additional benefit latter method lie ability incorporate knowledge noise domain influence prediction recover predictive distribution information outlier distribution via gating process model asymptotic complexity equal conventional robust method yield confident prediction benchmark problem classical heavy tailed model exhibit improved stability data clustered corruption fail altogether show approach used without adjustment smoothly heteroscedastic data suggest could extended general noise model also address similarity work goldberg et al recent contribution tresp rasmussen ghahramani', 'adaptation initially unknown agent often requires computing effective counter strategy bayesian paradigm one must find good counter strategy inferred posterior agent behavior expert paradigm one may want choose expert good counter strategy agent expected behavior paper introduce technique computing robust counter strategy adaptation multiagent scenario variety paradigm strategy take advantage suspected tendency decision agent bounding worst case performance tendency observed technique involves solving modified game therefore make use recently developed algorithm solving large extensive game demonstrate effectiveness technique two player texas hold em show computed poker strategy substantially robust best response counter strategy still exploiting suspected tendency also compose generated strategy expert algorithm showing dramatic improvement performance using simple best response', 'present new efficient semi supervised training method parameter estimation feature selection conditional random field crfs real world application activity recognition unlabeled sensor trace relatively easy obtain whereas labeled example expensive tedious collect furthermore ability automatically select small subset discriminatory feature large pool advantageous term computational speed well accuracy paper introduce semi supervised virtual evidence boosting sveb algorithm training crfs semi supervised extension recently developed virtual evidence boosting veb method feature selection parameter learning semi supervised veb take advantage unlabeled data via minimum entropy regularization objective function combine unlabeled conditional entropy labeled conditional pseudo likelihood sveb algorithm reduces overall system cost well human labeling cost required training important consideration building real world inference system set experiment synthetic data real activity trace collected wearable sensor illustrate algorithm benefit use unlabeled data automatic feature selection outperforms semi supervised training approach', 'abstract missing', 'abstract missing', 'combine two thread research approximate dynamic programming random sampling state using local trajectory optimizers globally optimize policy associated value function combination allows u replace dense multidimensional grid much sparser adaptive sampling state focus finding steady state policy deterministic time invariant discrete time control problem continuous state action often found robotics paper show solve problem solve previously regular grid based approach', 'abstract missing', 'propose randomized algorithm large scale svm learning solves problem iterating random subset data crucial algorithm scalability size subset chosen context text classification show using idea random projection sample size log n used obtain solution close optimal high probability experiment done synthetic real life data set demonstrate algorithm scale svm learner without loss accuracy', 'abstract missing', 'variational method frequently used approximate bound partition likelihood function markov random field method based mean field theory guaranteed provide lower bound whereas certain type convex relaxation provide upper bound general loopy belief propagation bp provides often accurate approximation bound prove class attractive binary model value specified fixed point loopy bp always provides lower bound true likelihood empirically bound much better naive mean field bound requires work running bp establish lower bound using loop series expansion due chertkov chernyak show derived consequence tree reparameterization characterization bp fixed point', 'abstract missing', 'consider problem support vector machine transduction involves combinatorial problem exponential computational complexity number unlabeled example although several study devoted transductive svm suffer either high computation complexity solution local optimum address problem propose solving transductive svm via convex relaxation convert np hard problem semi definite programming compared sdp relaxation transductive svm proposed algorithm computationally efficient number free parameter reduced n n n number example empirical study several benchmark data set show promising performance proposed algorithm comparison state art implementation transductive svm', 'leverage learning technique build fast nearest neighbor nn retrieval data structure present general learning framework nn problem sample query used learn parameter data structure minimize retrieval time miss rate explore potential novel framework two popular nn data structure kd tree rectilinear structure employed locality sensitive hashing derive generalization theory data structure class present simple learning algorithm experimental result reveal learning often improves already strong performance data structure', 'abstract missing', 'abstract missing', 'abstract missing', 'abstract missing', 'paper proposes constraint propagation relaxation cpr probabilistic approach classical constraint propagation provides another view whole parametric family survey propagation algorithm sp ranging belief propagation pure survey propagation importantly approach elucidates implicit fundamental assumption underlying sp thus shedding light effectiveness leading application beyond k sat', 'introduce hierarchical bayesian model discovery putative regulator gene expression data hierarchy incorporates knowledge regulator regulate handful gene implemented called spike slab prior mixture gaussians different width mixing weight hierarchical bernoulli model efficient inference implemented expectation propagation running model malaria parasite data set found four gene significant homology transcription factor amoebe one rna regulator three gene unknown function top ten gene considered', 'unsupervised learning algorithm aim discover structure hidden data learn representation suitable input supervised machine raw input many unsupervised method based reconstructing input representation constraining representation certain desirable property e g low dimension sparsity etc others based approximating density stochastically reconstructing input representation describe novel efficient algorithm learn sparse representation compare theoretically experimentally similar machine trained probabilistically namely restricted boltzmann machine propose simple criterion compare select different unsupervised machine based trade reconstruction error information content representation demonstrate method extracting feature dataset handwritten numeral dataset natural image patch show stacking multiple level machine training sequentially high order dependency input variable captured', 'abstract missing', 'present novel paradigm statistical machine translation smt based joint modeling word alignment topical aspect underlying bilingual document pair via hidden markov bilingual topic admixture hm bitam new paradigm parallel sentence pair parallel document pair coupled via certain semantic flow ensure coherence topical context alignment matching word language likelihood based training topic dependent translational lexicon well topic representation language resulting trained hm bitam display topic pattern like method lda bilingual corpus also offer principled way inferring optimal translation context dependent way method integrates conventional ibm model based hmm key component state art smt system recently proposed bitam model report extensive empirical analysis many way complementary description oriented method three aspect word alignment bilingual topic representation translation', 'natural sound structured many time scale typical segment speech example contains feature span four order magnitude sentence phoneme glottal pulse formants auditory system us information time scale solve complicated task auditory scene analysis one route toward understanding auditory processing accomplishes analysis build neuroscience inspired algorithm solve similar task compare property algorithm property auditory processing however discord current machine audition algorithm largely concentrate shorter time scale structure sound longer structure ignored reason two fold firstly difficult technical problem construct algorithm utilises sort information secondly computationally demanding simultaneously process data high resolution extract short temporal information long duration extract long temporal information contribution work develop new statistical model natural sound capture structure across wide range time scale provide efficient learning inference algorithm demonstrate success approach missing data task', 'assessing similarity feature key step object recognition scene categorization task argue knowledge distribution distance generated similarity function crucial deciding whether feature similar intuitively one would expect similarity feature could arise distribution paper derive contrary report theoretical result l p norm class commonly applied distance metric one feature vector vector weibull distributed feature value correlated non identically distributed besides assumption realistic image experimentally show hold various popular feature extraction algorithm diverse range image fundamental insight open new direction assessment feature similarity projected improvement object scene recognition algorithm erratum author paper declared become convinced reasoning reference simple proof claim consequence withdraw theorem', 'several related task solving simultaneously shown effective solving individually approach called multi task learning mtl studied extensively existing approach mtl often treat task emph uniformly related relatedness task controlled globally reason existing method lead undesired solution task highly related pair related task significantly different solution paper propose novel mtl algorithm overcome problem method make use task network describes relation structure among task allows u deal intricate relation structure systematic way furthermore control relatedness task locally pair related task guaranteed similar solution apply idea support vector machine svms show optimization problem cast second order cone program convex solved efficiently usefulness approach demonstrated simulation protein super family classification ordinal regression problem', 'propose extended probabilistic model human perception argue many circumstance human observer simultaneously evaluate sensory evidence different hypothesis regarding underlying physical process might generated sensory information within context inference optimal observer weighs hypothesis according correct belief hypothesis observer commits particular hypothesis belief hypothesis converted subjective certainty subsequent perceptual behavior suboptimal conditioned chosen hypothesis demonstrate framework explain psychophysical data recently reported decision estimation experiment model well account data predicting estimation bias consequence preceding decision step power framework free parameter except degree observer uncertainty internal sensory representation parameter defined particular experiment allows u make quantitative prediction human perception two modification original experiment', 'abstract missing', 'social tag user generated keywords associated resource web case music social tag become important component web recommender system allowing user generate playlist based use dependent term chill jogging applied particular song paper propose method predicting social tag directly mp file using set boosted classifier map audio feature onto social tag collected web resulting automatic tag autotags furnish information music otherwise untagged poorly tagged allowing insertion previously unheard music social recommender avoids cold start problem common system autotags also used smooth tag space similarity recommendation made providing set comparable baseline tag track recommender system', 'abstract missing', 'automatic relevance determination ard closely related sparse bayesian learning sbl framework effective tool pruning large number irrelevant feature however popular update rule used process either prohibitively slow practice heuristic nature without proven convergence property paper furnishes alternative mean optimizing general ard cost function using auxiliary function naturally solved using series weighted l problem result efficient algorithm implemented using standard convex programming toolbox guaranteed converge stationary point unlike existing method analysis also lead additional insight behavior previous ard update well ard cost function example standard fixed point update mackay shown iteratively solving particular min max problem although guaranteed lead stationary point analysis also reveals ard exactly equivalent performing map estimation using particular feature noise dependent textit non factorial weight prior several desirable property conventional prior respect feature selection particular provides tighter approximation l quasi norm sparsity measure l norm overall result suggests alternative cost function update procedure selecting feature promoting sparse solution', 'abstract missing', 'abstract missing', 'paper show classical survival analysis involving censored data naturally cast ranking problem concordance index ci quantifies quality ranking standard performance measure model emph assessment survival analysis contrast standard approach emph learning popular proportional hazard ph model based cox partial likelihood paper devise two bound ci one emerges directly property ph model optimize emph directly experimental result suggest method perform equally well new approach giving slightly better result cox method also explain method designed maximize cox partial likelihood also end approximately maximizing ci', 'abstract missing', 'brain computer interface bcis interaction modality based physiological signal body channel e g muscular activity speech gesture prone error recognition subject intent elegant approach improve accuracy bcis consists verification procedure directly based presence error related potential errp eeg recorded right occurrence error six healthy volunteer subject prior bci experience participated new human robot interaction experiment asked mentally move cursor towards target reached within step using motor imagination experiment confirms previously reported presence new kind errp interaction errp exhibit first sharp negative peak followed positive peak second broader negative peak m feedback respectively order exploit errp need detect single trial using short window following feedback associated response classifier embedded bci achieved average recognition rate correct erroneous single trial respectively furthermore achieved average recognition rate subject intent trying mentally drive cursor result show possible simultaneously extract useful information mental control operate brain actuated device well cognitive state error potential improve quality brain computer interaction finally using well known inverse model sloreta show main focus activity occurrence errp expected pre supplementary motor area anterior cingulate cortex', 'abstract missing', 'gate new notation representing mixture model context sensitive independence factor graph factor graph provide natural representation message passing algorithm expectation propagation however message passing mixture model well captured factor graph unless entire mixture represented one factor message equation containment structure gate capture containment structure graphically allowing independence message passing equation model readily visualized different variational approximation mixture model understood different way drawing gate model present general equation expectation propagation variational message passing presence gate', 'abstract missing', 'present generative model performing sparse probabilistic projection includes sparse principal component analysis sparse canonical correlation analysis special case sparsity enforced mean automatic relevance determination imposing appropriate prior distribution generalised hyperbolic distribution derive variational expectation maximisation algorithm estimation hyperparameters show novel probabilistic approach compare favourably existing technique illustrate proposed method applied context cryptoanalysis pre processing tool construction template attack', 'abstract missing', 'age month infant make inductive inference motion physical object developmental psychologist provided verbal account knowledge support inference often account focus categorical rather probabilistic principle propose infant object perception guided part probabilistic principle like persistence thing tend remain change gradually illustrate idea develop ideal observer model includes probabilistic formulation rigidity inertia like previous researcher suggest rigid motion expected early age challenge previous claim expectation consistent inertia relatively slow develop spelke et al support argument modeling four experiment developmental literature', 'semantic hashing seek compact binary code datapoints hamming distance codewords correlate semantic similarity hinton et al used clever implementation autoencoders find code paper show problem finding best code given dataset closely related problem graph partitioning shown np hard relaxing original problem obtain spectral method whose solution simply subset thresh olded eigenvectors graph laplacian utilizing recent result convergence graph laplacian eigenvectors laplace beltrami eigen function manifold show efficiently calculate code novel datapoint taken together learning code applying novel point extremely simple experiment show code significantly outperform state art', 'address challenge assessing conservation gene expression complex non homogeneous datasets recent study demonstrated success probabilistic model studying evolution gene expression simple eukaryotic organism yeast measurement typically scalar independent model capable studying expression evolution much complex organism vertebrate particularly important given medical scientific interest specie human mouse present statistical model make number significant extension previous model enable characterization change expression among highly complex organism demonstrate efficacy method microarray dataset containing diverse tissue multiple vertebrate specie anticipate model invaluable study gene expression pattern diverse organism well worm insect', 'inverse dynamic problem robotic manipulator compute torque needed joint drive along given trajectory beneficial able learn function adaptive control given robot manipulator often need controlled holding different load end effector giving rise multi task learning problem show structure inverse dynamic problem give rise multi task gaussian process prior function inter task similarity depends underlying dynamic parameter experiment demonstrate multi task formulation generally improves performance either learning single task pooling data task', 'many popular optimization algorithm like levenberg marquardt algorithm lma use heuristic based controller modulate behavior optimizer optimization process example lma damping parameter dynamically modified based set rule developed using various heuristic argument reinforcement learning rl machine learning approach learn optimal controller example thus obvious candidate improve heuristic based controller implicit popular heavily used optimization algorithm improving performance shelf optimizers particularly important time constrained optimization problem example lma algorithm become popular many real time computer vision problem including object tracking video small amount time allocated optimizer incoming video frame show popular modern reinforcement learning technique using simply state space dramatically improve performance general purpose optimizers like lma surprisingly controller learned particular domain appear work well also different optimization domain example used rl method train new controller damping parameter lma controller trained collection classic relatively small non linear regression problem modified lma performed better standard lma problem surprisingly also dramatically outperformed standard lma difficult large scale computer vision problem trained thus controller appeared extracted control rule domain specific generalized across wide range optimization domain', 'address problem estimating ratio two probability density function k importance importance value used various succeeding task non stationarity adaptation outlier detection paper propose new importance estimation method closed form solution leave one cross validation score also computed analytically therefore proposed method computationally efficient numerically stable also elucidate theoretical property proposed method convergence rate approximation error bound numerical experiment show proposed method comparable best existing method accuracy computationally efficient competing approach', 'derive risk bound randomized classifier sample compression setting classifier specification utilizes two source information viz compression set message string extending recently proposed occam hammer principle data dependent setting derive point wise version bound stochastic sample compressed classifier also recover corresponding classical pac bayes bound show compare favorably existing result', 'polysemy problem method exploit image search engine build object category model existing unsupervised approach take word sense consideration propose new method us dictionary learn model visual word sense large collection unlabeled web data use lda discover latent sense space make model robust despite limited nature dictionary definition definition used learn distribution latent space best represents sense algorithm us text surrounding image link retrieve image high probability particular dictionary sense object classifier trained resulting sense specific image evaluate method dataset obtained searching web polysemous word category classification experiment show dictionary based approach outperforms baseline method', 'abstract missing', 'present polynomial time algorithm exact computation lowest energy state worst margin violator partition function marginals binary undirected graphical model approach provides interesting alternative well known graph cut paradigm impose submodularity constraint instead require planarity establish correspondence perfect matchings expanded dual graph maximum margin parameter estimation boundary detection task show approach ef cient effective', 'uncertainty omnipresent perceive interact environment bayesian framework provides computational method dealing mathematical model bayesian decision making typically require datastructures hard implement neural network article show even simplest experimentally best supported type synaptic plasticity hebbian learning combination sparse redundant neural code principle learn infer optimal bayesian decision present concrete hebbian learning rule operating log probability ratio modulated reward signal hebbian plasticity rule also provides new perspective understanding bayesian inference could support fast reinforcement learning brain particular show recent experimental result yang shadlen reinforcement learning probabilistic inference primate modeled way', 'consider following instance transfer learning given pair regression problem suppose regression coefficient share partially common support parameterized overlap fraction overlap two support set suggests use infty regularized linear regression recovering support set regression vector main contribution provide sharp characterization sample complexity infty relaxation exactly pinning minimal sample size n required joint support recovery function model dimension pdim support size spindex overlap overlap measurement matrix drawn standard gaussian ensemble prove joint infty regularized method undergoes phase transition characterized order parameter orpar numobs pdim spindex overlap numobs overlap log p overlap precisely probability successfully recovering support converges scaling orpar converges scaling orpar implication threshold use infty regularization lead gain sample complexity overlap parameter large enough overlap performs worse naive approach overlap illustrate close agreement theoretical prediction actual behavior simulation thus result illustrate benefit danger associated block infty regularization high dimensional inference', 'kernel based regression learning optimizing kernel individually useful data density curvature regression surface decision boundary magnitude output noise e heteroscedasticity varies spatially unfortunately present complex computational problem danger overfitting high individual optimization every kernel learning system may overly expensive due introduction many open learning parameter previous work suggested gradient descent technique complex statistical hypothesis method local kernel shaping typically requiring amount manual tuning meta parameter paper focus nonparametric regression introduce bayesian formulation help variational approximation result em like algorithm simultaneous estimation regression kernel parameter algorithm computationally efficient suitable large data set requires sampling automatically reject outlier one prior specified used nonparametric regression local polynomial novel method achieve nonstationary regression gaussian process method particularly useful learning control reliable estimation local tangent plane essential adaptive controller reinforcement learning evaluate method several synthetic data set actual robot learns task level control law', 'abstract missing', 'mixture gaussian process model extended single gaussian process ability modeling multi modal data reduction training complexity previous inference algorithm model mostly based gibbs sampling slow particularly large scale data set present new generative mixture expert model expert still gaussian process reformulated linear model break dependency among training output enables u use much faster variational bayesian algorithm training gating network flexible previous generative approach input expert modeled gaussian mixture model number expert number gaussian component expert inferred automatically variety test show advantage method', 'embeddings random variable reproducing kernel hilbert space rkhss may used conduct statistical inference based higher order moment sufficiently rich characteristic rkhss probability distribution unique embedding allowing statistical property distribution taken consideration necessary sufficient condition rkhs characteristic exist r n present work condition established rkhs characteristic group semigroups illustrative example provided including characteristic kernel periodic domain rotation matrix r n', 'setting partially observable markov decision process continuous state observation action space decision based particle filter estimating belief state given past observation consider policy gradient approach parameterized policy optimization purpose investigate sensitivity analysis performance measure respect parameter policy focusing finite difference fd technique show naive fd subject variance explosion non smoothness resampling procedure propose sophisticated fd method overcomes problem establish consistency', 'develop name stm nonparametric bayesian model parsed document shortname generates word thematically syntactically constrained combine semantic insight topic model syntactic information available parse tree word sentence generated distribution combine document specific topic weight parse tree specific syntactic transition word assumed generated order respect parse tree derive approximate posterior inference method based variational method hierarchical dirichlet process report qualitative quantitative result synthetic data hand parsed document', 'learning graphical model hidden variable offer semantic insight complex data lead salient structured predictor without relying expensive sometime unattainable fully annotated training data likelihood based method extensively explored knowledge learning structured prediction model latent variable based max margin principle remains largely open problem paper present partially observed maximum entropy discrimination markov network pomen model attempt combine advantage bayesian margin based paradigm learning markov network partially labeled data pomen lead averaging prediction rule resembles bayes predictor robust overfitting also built desirable discriminative law resemble n develop em style algorithm utilizing existing convex optimization algorithm n subroutine demonstrate competent performance pomen existing method real world web data extraction task', 'abstract missing', 'abstract missing', 'show empirical minimizer stochastic strongly convex objective stochastic component linear converges population minimizer rate n result applies particular svm objective thus get rate n convergence svm objective infinite data limit demonstrate essential obtaining tight oracle inequality svms result extend also strong convexity respect ellnorm p norm also objective regularized using norm', 'undiscounted reinforcement learning markov decision process mdps consider total regret learning algorithm respect optimal policy order describe transition structure mdp propose new parameter mdp diameter pair state policy move step average present reinforcement learning algorithm total regret dsat step unknown mdp state action per state diameter bound hold high probability also present corresponding lower bound omega dsat total regret learning algorithm bound demonstrate utility diameter structural parameter mdp', 'paper study global ranking problem learning rank method conventional learning rank method usually designed local ranking sense ranking model defined single object example document information retrieval many application loose approximation relation always exist object better define ranking model function object ranked e relation also included paper refers problem global ranking proposes employing continuous conditional random field crf conducting learning task continuous crf model defined conditional probability distribution ranking score object conditioned object naturally represent content information object well relation information object necessary global ranking taking two specific information retrieval task example paper show continuous crf method perform global ranking better baseline', 'learning real time application e g online approximation inverse dynamic model model based robot control requires fast online regression technique inspired local learning propose method speed standard gaussian process regression gpr local gp model lgp training data partitioned local region individual gp model trained prediction query point performed weighted estimation using nearby local model unlike gp approximation mixture expert use distance based measure partitioning data weighted prediction proposed method achieves online learning prediction real time comparison nonparametric regression method show lgp higher accuracy lwpr close performance standard gpr nu svr', 'paper devoted thoroughly investigating bootstrap roc curve widely used visual tool evaluating accuracy test scoring statistic bipartite setup issue confidence band roc curve considered resampling procedure based smooth version empirical distribution called smoothed bootstrap introduced theoretical argument simulation result presented show smoothed bootstrap preferable naive bootstrap order construct accurate confidence band', 'abstract missing', 'accurate efficient inference evolutionary tree central problem computational biology realistic model require tracking insertion deletion along phylogenetic tree making inference challenging propose new sampling technique speed inference improve quality sample compare method previous approach show performance improvement metric evaluating multiple sequence alignment reconstruction ancestral sequence', 'study problem domain transfer supervised classification task mrna splicing consider number recent domain transfer method machine learning including novel evaluate genomic sequence data model organism varying evolutionary distance find case organism closely related use domain adaptation method help improve classification performance', 'one extract unknown stereotypical event linearly superimposed within signal variable latency variable amplitude one could think using template matching matching pursuit find arbitrarily shifted linear component however traditional matching approach require template known priori overcome restriction use instead semi non negative matrix factorization semi nmf extend allow time shift matching template signal algorithm estimate template directly data along non negative amplitude resulting method thought adaptive template matching procedure demonstrate procedure task extracting spike single channel extracellular recording data algorithm essentially performs spike detection unsupervised spike clustering result simulated data extracellular recording indicate method performs well signal noise ratio db higher spike template recovered accurately provided sufficiently different', 'covariance estimation high dimensional vector classically difficult problem statistical analysis machine learning due limited sample size paper propose new approach covariance estimation based constrained maximum likelihood ml estimation covariance specifically covariance constrained eigen decomposition represented sparse matrix transform smt smt formed product pairwise coordinate rotation known given rotation using framework covariance efficiently estimated using greedy minimization log likelihood function number given rotation efficiently computed using cross validation procedure estimator obtained using method always positive definite well conditioned even limited sample size experiment hyperspectral data show smt covariance estimation result consistently better estimate covariance variety different class sample size compared traditional shrinkage estimator', 'abstract missing', 'present gaussian process density sampler gpds exchangeable generative model use nonparametric bayesian density estimation sample drawn gpds consistent exact independent sample fixed density function transformation function drawn gaussian process prior formulation allows u infer unknown density data using markov chain monte carlo give sample posterior distribution density function predictive distribution data space also infer hyperparameters gaussian process compare density modeling technique several existing technique toy problem skull reconstruction task', 'present characterization useful class skill based graphical representation agent interaction environment characterization us betweenness measure centrality graph may used directly form set skill suitable given environment importantly serf useful guide developing online incremental skill discovery algorithm rely knowing representing environment graph entirety', 'detecting underlying cluster large scale data play central role machine learning research paper attempt tackle clustering problem complex data multiple distribution large multi scale end develop algorithm named zeta l link zell consists two part zeta merging similarity graph initial set small cluster derived local l link graph specifically propose structurize cluster using cycle associated subgraph mathematical tool zeta function graph introduced integration cycle leading structural descriptor cluster determinantal form popularity character cluster conceptualized global fusion variation structural descriptor mean leave one strategy cluster zeta merging proceeds agglomerative fashion according maximum incremental popularity among pairwise cluster experiment toy data real imagery data real sensory data show promising performance zell accuracy sense normalized mutual information obtained frgc face data sample facial cluster matlab code zell made publicly available peer evaluation', 'query expansion long studied approach improving retrieval effectiveness enhancing user original query additional related term current algorithm automatic query expansion shown consistently improve retrieval accuracy average highly unstable bad worst case performance individual query introduce novel risk framework formulates query model estimation constrained metric labeling problem graph term relation themodel combine assignment cost based baseline feedback algorithm edge weight based term similarity simple constraint enforce aspect balance aspect coverage term centrality result across multiple standard test collection show consistent dramatic reduction number magnitude expansion failure retaining strong positive gain baseline algorithm', 'sampling function gaussian process gp model challenging highly correlated posterior distribution describe efficient markov chain monte carlo algorithm sampling posterior process gp model algorithm us control variable auxiliary function value provide low dimensional representation function iteration algorithm proposes new value control variable generates function conditional gp prior control variable input location found continuously minimizing objective function demonstrate algorithm regression classification problem use estimate parameter differential equation model gene regulation', 'propose novel bound single variable marginal probability distribution factor graph discrete variable bound obtained propagating bound convex set probability distribution subtree factor graph rooted variable interest construction method bound exact marginal probability distribution variable also approximate belief propagation marginal belief thus apart providing practical mean calculate bound marginals contribution also lie providing better understanding error made belief propagation show bound outperforms state art inference problem arising medical diagnosis', 'multi level hierarchical model provide attractive framework incorporating correlation induced response variable organized hierarchy model fitting challenging especially hierarchy large number node provide novel algorithm based multi scale kalman filter scalable easy implement non gaussian response quadratic approximation log likelihood result biased estimate suggest bootstrap strategy correct bias method illustrated simulation study analysis real world data set health care online advertising', 'analyze estimation information theoretic measure continuous random variable differential entropy mutual information kullback leibler divergence objective paper two fold first prove information theoretic measure estimate using k nearest neighbor density estimation fixed k converge almost surely even though k nearest neighbor density estimation fixed k converge true measure second show information theoretic measure estimate converge k growing linearly number sample nevertheless nonconvergent estimate used solving two sample problem assessing two random variable independent show two sample independence test based nonconvergent estimate compare favorably maximum mean discrepancy test hilbert schmidt independence criterion respectively', 'supervised unsupervised learning positive definite kernel allow use large potentially infinite dimensional feature space computational cost depends number observation usually done penalization predictor function euclidean hilbertian norm paper explore penalizing sparsity inducing norm l norm block l norm assume kernel decomposes large sum individual basis kernel embedded directed acyclic graph show possible perform kernel selection hierarchical multiple kernel learning framework polynomial time number selected kernel framework naturally applied non linear variable selection extensive simulation synthetic datasets datasets uci repository show efficiently exploring large feature space sparsity inducing norm lead state art predictive performance', 'abstract missing', 'abstract missing', 'many machine learning algorithm require summation gaussian kernel function expensive operation implemented straightforwardly several method proposed reduce computational complexity evaluating sum including tree analysis based method achieve varying speedup depending bandwidth dimension prescribed error making choice method difficult machine learning task provide algorithm combine tree method improved fast gauss transform ifgt originally proposed ifgt suffers two problem taylor series expansion perform well low bandwidth parameter selection trivial drastically affect performance ease use address first problem employing tree data structure resulting four evaluation method whose performance varies based distribution source target input parameter desired accuracy bandwidth solve second problem present online tuning approach result black box method automatically chooses evaluation method parameter yield best performance input data desired accuracy bandwidth addition new ifgt parameter selection approach allows tighter error bound approach chooses fastest method negligible additional cost superior performance comparison previous approach', 'propose novel application formal concept analysis fca neural decoding instead trying figure stimulus presented demonstrate explore semantic relationship neural representation large set stimulus fca provides way displaying interpreting relationship via concept lattice explore effect neural code sparsity lattice analyze neurophysiological data high level visual cortical area stsa using exact bayesian approach construct formal context needed fca prominent feature resulting concept lattice discussed including indication product expert code real neuron', 'abstract missing', 'define metric measuring behavior similarity state markov decision process mdp action similarity taken account show kernel metric corresponds exactly class state defined mdp homomorphism ravindran barto prove difference optimal value function different state upper bounded value metric bound tighter provided bisimulation metric fern et al result hold discrete continuous action provide algorithm constructing approximate homomorphism using metric identify state grouped together well action matched previous research topic based mainly heuristic', 'paper describes recursive estimation procedure multivariate binary density using orthogonal expansion covariates basis coefficient estimate render conventional approach computationally prohibitive large however wide class density satisfy certain sparsity condition estimator run probabilistic polynomial time adapts unknown sparsity underlying density two key way attains near minimax mean squared error computational complexity lower sparser density method also allows flexible control trade mean squared error computational complexity', 'provide statistical performance guarantee recently introduced kernel classifier optimizes l integrated squared error ise difference density classifier similar support vector machine svm solution quadratic program yield sparse classifier unlike svms however l kernel classifier involve regularization parameter prove distribution free concentration inequality cross validation based estimate ise apply result deduce oracle inequality consistency classifier sense ise probability error result also specialized give performance guarantee existing method l kernel density estimation', 'propose efficient sequential monte carlo inference scheme recently proposed coalescent clustering model teh et al algorithm quadratic runtime teh et al cubic experiment surprised find addition efficient also better sequential monte carlo sampler best teh et al measured term variance estimated likelihood effective sample size', 'many supervised learning problem posse prior knowledge feature yield similar information target variable predicting topic document might know two word synonym performing image recognition know pixel adjacent synonymous neighboring feature near duplicate therefore expected similar weight good model present framework regularized learning setting one prior knowledge feature expected similar dissimilar weight prior knowledge encoded graph whose vertex represent feature whose edge represent similarity dissimilarity learning feature weight penalized amount differs average weight neighbor text classification regularization using graph word co occurrence outperforms manifold learning compare favorably recently proposed semi supervised learning method sentiment analysis feature graph constructed declarative human knowledge well auxiliary task learning significantly improve prediction accuracy', 'formulate problem bipartite graph inference supervised learning problem propose new method solve viewpoint distance metric learning method involves learning two mapping heterogeneous object unified euclidean space representing network topology bipartite graph graph easy infer algorithm formulated optimization problem reproducing kernel hilbert space report encouraging result problem compound protein interaction network reconstruction chemical structure data genomic sequence data', 'motor primitive motion template become important concept modeling human motor control well generating robot behavior using imitation learning recent impressive result range humanoid robot movement generation timing model human motion automatic generation skill library containing multiple motion template important step robot learning skill learning system need cluster similar movement together represent resulting motion template generative model subsequently used execution behavior robot system paper show human trajectory captured multidimensional time series clustered using bayesian mixture linear gaussian state space model based similarity dynamic appropriate number template automatically determined enforcing parsimonious parametrization resulting model intractable introduce novel approximation method based variational bayes especially designed enable use efficient inference algorithm recorded human balero movement method capable finding reasonable motion template also yield generative model work well execution complex task simulated anthropomorphic sarcos arm', 'abstract missing', 'introduce new interpretation multiscale random field msrfs admits efficient optimization framework regular single level random field rf based new operator called append combine set random variable rv single rv assume msrf decomposed disjoint tree link rv different pyramid level append operator applied map rv tree structure single rv demonstrate usefulness proposed approach challenging task involving grouping contour target shape image msrfs provide natural representation multiscale contour model needed order cope unstable contour decomposition append operator allows u find optimal image label using classical framework relaxation labeling alternative method like markov chain monte carlo mcmc could also used', 'shown problem ell penalized least square regression commonly referred lasso basis pursuit denoising lead solution sparse therefore achieves model selection propose paper algorithm solve lasso online observation introduce optimization problem allows u compute homotopy current solution solution observing new data point compare method lars present application compressed sensing sequential observation approach also easily extended compute homotopy current solution solution removing data point lead efficient algorithm leave one cross validation', 'abstract missing', 'subspace based learning problem involve data whose element linear subspace vector space handle data structure grassmann kernel proposed used previously paper analyze relationship grassmann kernel probabilistic similarity measure firstly show kl distance limit yield projection kernel grassmann manifold whereas bhattacharyya kernel becomes trivial limit suboptimal subspace based problem secondly based analysis kl distance propose extension projection kernel extended set affine well scaled subspace demonstrate advantage extended kernel classification recognition task support vector machine kernel discriminant analysis using synthetic real image database', 'describe application probabilistic modeling inference technology problem analyzing sensor data setting intensive care unit icu particular consider arterial line blood pressure sensor subject frequent data artifact cause false alarm icu make raw data almost useless automated decision making problem complicated fact sensor data acquired fixed interval whereas event causing data artifact may occur time duration may significantly shorter data collection interval show careful modeling sensor combined general technique detecting sub interval event estimating duration enables effective detection artifact accurate estimation underlying blood pressure value', 'develop statistical framework simultaneous unsupervised segmentation discovery visual object category image database examining large set manually segmented scene use chi square test show object frequency segment size follow power law distribution well modeled pitman yor py process nonparametric prior distribution lead learning algorithm discover unknown set object segmentation method automatically adapt resolution image generalizing previous application py process use gaussian process discover spatially contiguous segment respect image boundary using novel family variational approximation approach produce segmentation compare favorably state art method simultaneously discovering category shared among natural scene', 'abstract missing', 'roc curve known golden standard measuring performance test scoring statistic regarding capacity discrimination two population wide variety application ranging anomaly detection signal processing information retrieval medical diagnosis practical performance measure used scoring application auc local auc p norm push dcg others seen summary roc curve paper highlight fact many empirical criterion expressed conditional linear rank statistic investigate property empirical maximizers performance criterion provide preliminary result concentration property novel class random variable call linear rank process', 'clustering stability increasingly popular family method performing model selection data clustering basic idea chosen model stable perturbation resampling data despite reasonably effective practice method well understood theoretically present difficulty particular data assumed sampled underlying distribution solution returned clustering algorithm usually become stable sample size increase raise potentially serious practical difficulty method mean might hard compute sample size beyond clustering stability estimator break become unreliable detecting stable model namely model relatively stable difference stability measure depending mostly random meaningless sampling artifact paper provide set general sufficient condition ensure reliability clustering stability estimator large sample regime contrast previous work concentrated specific toy distribution specific idealized clustering framework make assumption exemplify condition apply several important family clustering algorithm maximum likelihood clustering certain type kernel clustering centroid based clustering bregman divergence addition explicitly derive non trivial asymptotic behavior estimator framework satisfying condition help u understand considered stable model estimator least large enough sample', 'visual auditory map alignment superior colliculus sc barn owl important accurate localization prey behavior prism learning blindness may interfere alignment cause loss capability accurate prey however juvenile barn owl could recover sensory map alignment shifting auditory map adaptation map alignment believed based activity dependent axon developing inferior colliculus ic model built explore mechanism model axon growing process instructed inhibitory network sc strength inhibition adjusted spike timing dependent plasticity stdp test analyze mechanism application neural structure involved spatial localization robotic system', 'abstract missing', 'many machine learning algorithm formulated framework statistical independence hilbert schmidt independence criterion paper extend criterion deal structured interdependent observation achieved modeling structure using undirected graphical model comparing hilbert space embeddings distribution apply new criterion independent component analysis sequence clustering', 'present new family linear time algorithm based sufficient statistic string comparison mismatch string kernel framework algorithm improve theoretical complexity bound existing approach scaling well respect sequence alphabet size number allowed mismatch size dataset particular large alphabet loose mismatch constraint algorithm several order magnitude faster existing algorithm string comparison mismatch similarity measure evaluate algorithm synthetic data real application music genre classification protein remote homology detection protein fold prediction scalability algorithm allows u consider complex sequence transformation modeled using longer string feature larger number mismatch leading state art performance significantly reduced running time', 'recently supervised dimensionality reduction gaining attention owing realization data label often available strongly suggest important underlying structure data paper present novel convex supervised dimensionality reduction approach based exponential family pca provide simple novel form project new testing data embedded space convex approach successfully avoids local optimum em learning moreover introducing sample based multinomial approximation exponential family model avoids limitation prevailing gaussian assumption standard pca produce kernelized formulation nonlinear supervised dimensionality reduction training algorithm devised based subgradient bundle method whose scalability gained coordinate descent procedure advantage global optimization approach demonstrated empirical result synthetic real data', 'abstract missing', 'paper present two transductive bound risk majority vote estimated partially labeled training set first bound tight additional unlabeled training data used case voted classifier make error low margin observation error associated gibbs classifier accurately estimated semi supervised learning considering margin indicator confidence constitutes working hypothesis algorithm search decision boundary low density region case propose second bound joint probability voted classifier make error example margin fixed threshold application interested self learning algorithm assign iteratively pseudo label unlabeled training example margin threshold obtained bound empirical result different datasets show effectiveness approach compared algorithm tsvm threshold fixed manually', 'paper consider approximate policy iteration based reinforcement learning algorithm order implement flexible function approximation scheme propose use non parametric method regularization providing convenient way control complexity function approximator propose two novel regularized policy iteration algorithm adding l regularization two widely used policy evaluation method bellman residual minimization brm least square temporal difference learning lstd derive efficient implementation algorithm approximate value function belong reproducing kernel hilbert space also provide finite sample performance bound algorithm show able achieve optimal rate convergence studied condition', 'metric learning algorithm provide useful distance function variety domain recent work shown good accuracy problem learner access distance constraint however many real application constraint available incrementally thus necessitating method perform online update learned metric existing online algorithm offer bound worst case performance typically perform well practice compared offline counterpart present new online metric learning algorithm update learned mahalanobis metric based logdet regularization gradient descent prove theoretical worst case performance bound empirically compare proposed method existing online metric learning algorithm boost practicality approach develop online locality sensitive hashing scheme lead efficient update approximate similarity search data structure demonstrate algorithm multiple datasets show outperforms relevant baseline', 'recent research suggests neural system employ sparse coding however limited theoretical understanding fundamental resolution limit sparse coding paper considers general sparse estimation problem detecting sparsity pattern k sparse vector r n random noisy measurement main result provide necessary sufficient condition problem dimension n k signal noise ratio snr asymptotically reliable detection show necessary condition perfect recovery given snr algorithm regardless complexity omega k log n k measurement considerably stronger previous necessary condition also show scaling omega k log n k measurement sufficient trivial maximum correlation estimator succeed hence scaling optimal require lasso matching pursuit sophisticated method optimal scaling thus biologically plausible', 'well established sparse signal model well suited restoration task effectively learned audio image video data recent research aimed learning discriminative sparse model instead purely reconstructive one paper proposes new step direction novel sparse representation signal belonging different class term shared dictionary multiple decision function shown linear variant model admits simple probabilistic interpretation general variant also admits simple interpretation term kernel optimization framework learning component proposed model presented along experiment standard handwritten digit texture classification task', 'offline handwriting recognition transcription image handwritten text interesting task combine computer vision sequence learning system two element handled separately sophisticated preprocessing technique used extract image feature sequential model hmms used provide transcription combining two recent innovation neural network multidimensional recurrent neural network connectionist temporal classification paper introduces globally trained offline handwriting recogniser take raw pixel data input unlike competing system require alphabet specific preprocessing therefore used unchanged language evidence generality power provided data recent international arabic recognition competition outperformed entry accuracy compared competition winner despite fact neither author understands word arabic', 'abstract missing', 'large margin structured estimation method work minimizing convex upper bound loss function allow efficient optimization algorithm convex formulation tight sacrifice ability accurately model true loss present tighter non convex bound based generalizing notion ramp loss binary classification structured estimation show small modification existing optimization algorithm suffices solve modified problem structured prediction task protein sequence alignment web page ranking algorithm lead improved accuracy', 'consider multi armed bandit problem number arm larger possible number experiment make stochastic assumption mean reward new selected arm characterizes probability near optimal arm assumption weaker previous work describe algorithm based upper confidence bound applied restricted set randomly selected arm provide upper bound resulting expected regret also derive lower bound match logarithmic factor upper bound case', 'present novel method inducing synchronous context free grammar scfgs corpus parallel string pair scfgs model equivalence string term substitution insertion deletion reordering sub string develop non parametric bayesian model apply machine translation task using prior replace various heuristic commonly used field using variational bayes training procedure learn latent structure translation equivalence induction synchronous grammar category phrasal translation showing improvement translation performance previously proposed maximum likelihood model', 'tackle computational problem query conditioned search given machine learned scoring rule query distribution build predictive index precomputing list potential result sorted based expected score result future query predictive index datastructure support anytime algorithm approximate retrieval top element general approach applicable webpage ranking internet advertisement approximate nearest neighbor search particularly effective setting standard technique e g inverted index intractable experimentally find substantial improvement existing method internet advertisement approximate nearest neighbor', 'hierarchical probabilistic modeling discrete data emerged powerful tool text analysis posterior inference model intractable practitioner rely approximate posterior inference method variational inference gibbs sampling much research designing better approximation yet little theoretical understanding available technique appropriate data analysis setting paper provide beginning understanding analyze improvement recently proposed collapsed variational inference cvb provides mean field variational inference vb latent dirichlet allocation prove difference tightness bound likelihood document decrease k log k number topic model number word document consequence advantage cvb vb lost long document increase number topic demonstrate empirically theory hold using simulated text data two text corpus provide practical guideline choosing approximation', 'investigate topic interface machine learning cognitive science human active learning learner actively query world information contrasted passive learning random example furthermore compare human active learning performance prediction statistical learning theory conduct series human category learning experiment inspired machine learning task active passive learning error bound well understood dramatically distinct result indicate human capable actively selecting informative query learn better faster given random training data predicted learning theory however improvement passive learning dramatic achieved machine active learning algorithm best knowledge first quantitative study comparing human category learning active versus passive setting', 'paper examines generalization property online convex programming algorithm loss function lipschitz strongly convex main result sharp bound hold high probability excess risk output online algorithm term average regret allows one use recent algorithm logarithmic cumulative regret guarantee achieve fast convergence rate excess risk high probability bound also solves open problem regarding convergence rate pegasos recently proposed method solving svm optimization problem', 'psychophysical experiment show human better perceiving rotation expansion translation finding inconsistent standard model motion integration predict best performance translation explain discrepancy theory formulates motion perception two level inference first perform model selection competing model e g translation rotation expansion estimate velocity using selected model define novel prior model smooth rotation expansion using technique similar slow smooth model e g green function differential operator theory give good agreement trend observed human experiment', 'partially observable world many agent nested belief formed agent simultaneously reason unknown state world belief agent multi agent filtering problem efficiently represent update belief time agent act world paper formally define infinite sequence nested belief state world current time present filtering algorithm maintains finite representation used generate belief case representation updated exactly constant time also present simple approximation scheme compact belief become complex experiment demonstrate efficient filtering range multi agent domain', 'abstract missing', 'regularized least square rls algorithm ability avoid fitting problem express solution kernel expansion however observe current rls algorithm cannot provide satisfactory interpretation even constant function hand kernel based algorithm developed tendency almost learning algorithm kernelized kernelized basic fact often ignored learned function data kernel fit data well may consistent kernel based consideration intuition good kernel based inductive function consistent data kernel novel learning scheme proposed advantage scheme lie corresponding representer theorem strong interpretation ability kind function penalized promising accuracy improvement shown number experiment furthermore provide detailed technical description heat kernel serf example reader apply similar technique kernel work provides preliminary step new direction explore varying consistency inductive function kernel various distribution', 'crucial part developing mathematical model brain work quantification success one widely used metric yield percentage variance data explained model unfortunately metric biased due intrinsic variability data variability principle unexplainable model derive simple analytical modification traditional formula significantly improves accuracy measured bias similar better precision measured mean square error estimating true underlying variance explained model class estimator advance previous work accounting uncertainty noise estimate b accounting overfitting due free model parameter mitigating need separate validation data set c adding conditioning term apply new estimator binocular disparity tuning curve set macaque v neuron find population level almost variance unexplained gabor function attributable noise', 'kernel supervised learning method unified utilizing tool regularization theory duality regularization prior lead interpreting regularization method term maximum posteriori estimation motivated bayesian interpretation kernel method paper pursue bayesian interpretation sparsity kernel setting making use mixture point mass distribution prior refer silverman g prior provide theoretical analysis posterior consistency bayesian model choice procedure based prior also establish asymptotic relationship procedure bayesian information criterion', 'abstract missing', 'model near rigid shape matching typically based distance related feature order infer match consistent isometric assumption however real shape image datasets even expected related almost isometric transformation actually subject noise also limited degree variation appearance scale paper introduce graphical model parameterises appearance distance angle feature learn involved parameter via structured prediction outcome model near rigid shape matching robust sense able capture possibly limited still important scale appearance variation experimental result reveal substantial improvement upon recent successful model maintaining similar running time', 'cognitive motor task speed accuracy tradeoff observed individual respond slowly accurately quickly yet prone error control mechanism governing initiation behavioral response sensitive task instruction stimulus processed also recent stimulus history stimulus characterized easy hard dimension e g word frequency naming task item preceded easy trial responded quickly error item preceded hard trial propose rationally motivated mathematical model sequential adaptation control based diffusion model decision process difficulty corresponds drift rate correct response model assumes responding based posterior distribution response correct conditioned accumulated evidence derive posterior function drift rate show higher estimate drift rate lead normatively faster responding trial trial tracking difficulty thus lead sequential effect speed accuracy simulation show model explains variety phenomenon human speeded decision making argue passive statistical mechanism provides elegant parsimonious account extant theory based elaborate control structure', 'paper lower upper bound number support vector derived support vector machine svms based epsilon insensitive loss function turn bound asymptotically tight mild assumption data generating distribution finally briefly discus trade epsilon sparsity accuracy svm used estimate conditional median', 'abstract missing', 'abstract missing', 'roc curve one widely used display evaluate performance scoring function paper propose statistical method directly optimizing roc curve target known regression function increasing transformation boil recovering level set latter propose use classifier obtained empirical risk minimization weighted classification error construct scoring rule overlaying classifier show consistency rate convergence optimal roc curve procedure term supremum norm also byproduct analysis derive empirical estimate optimal roc curve', 'abstract missing', 'introduce novel framework estimating vector field using sparse basis field expansion flex notion basis field extension scalar basis function arises naturally framework rotational invariance requirement consider regression setting well inverse problem variant discussed lead second order cone programming formulation framework generally applicable type vector field focus paper applying solving eeg meg inverse problem shown significantly precise neurophysiologically plausible location shape estimate cerebral current source eeg meg measurement become possible method comparing state art', 'abstract missing', 'one original goal computer vision fully understand natural scene requires solving several problem simultaneously including object detection labeling meaningful region reconstruction great progress made tackling problem isolation recently researcher considering difficult task assembling various method mutual benefit consider learning set classification model way solve problem help develop framework known cascaded classification model ccm repeated instantiation classifier coupled input output variable cascade improves performance level method requires limited black box interface model allowing u use sophisticated state art classifier without look hood demonstrate effectiveness method large set natural image combining subtasks scene categorization object detection multiclass image segmentation scene reconstruction', 'singular value decomposition key operation many machine learning method computational cost however make unscalable impractical massive sized datasets becoming common application present new method quic svd fast approximation full svd automatic sample size minimization empirical relative error control previous monte carlo approach addressed full svd benefited efficiency automatic empirically driven sample sizing empirical test show speedup several order magnitude exact svd scalability enable quic svd meet need wide array method application', 'cognitive control refers flexible deployment memory attention response task demand current goal control often studied experimentally presenting sequence stimulus demanding response others modulating stimulus response mapping task participant must maintain information current stimulus response mapping working memory prominent theory cognitive control use recurrent neural net implement working memory optimize memory utilization via reinforcement learning present novel perspective cognitive control working memory representation intrinsically probabilistic control operation maintain update working memory dynamically determined via probabilistic inference show model provides parsimonious account behavioral neuroimaging data suggest offer elegant conceptualization control behavior cast optimal subject limitation learning rate information processing moreover model provides insight task instruction directly translated appropriate behavior efficiently refined subsequent task experience', 'current line learning algorithm predicting labelling graph important limitation case large diameter graph number mistake made algorithm may proportional square root number vertex even tackling simple problem overcome problem efficient algorithm achieves logarithmic mistake bound furthermore current algorithm optimised data exhibit cluster structure give additional algorithm performs well locally presence cluster structure large diameter graph', 'information theoretic perspective noisy transmission system visual brain computer interface bci speller could benefit use error correcting code however optimizing code solely according maximal minimum hamming distance criterion tends lead overall increase target frequency target stimulus hence significantly reduced average target target interval tti leading difficulty classifying individual event related potential erps due overlap refractory effect clearly change stimulus setup must also respect possible psychophysiological consequence report new eeg data experiment explore stimulus type codebooks within subject design finding interaction two factor data demonstrate traditional row column code particular spatial property lead better performance one would expect ttis hamming distance alone nonetheless error correcting code improve performance provided right stimulus type used', 'provide new analysis efficient margin based algorithm selective sampling classification problem using called tsybakov low noise condition parametrize instance distribution show bound convergence rate bayes risk fully supervised selective sampling version basic algorithm analysis reveals excluding logarithmic factor average risk selective sampler converges bayes risk rate n alpha alpha label sampled rate n denotes sample size alpha exponent low noise condition compare convergence rate rate n alpha alpha achieved fully supervised algorithm using label experiment textual data reveal simple variant proposed selective sampler perform much better popular similarly efficient competitor', 'novel center based clustering algorithm proposed paper first formulate clustering np hard linear integer program use linear programming duality theory derive solution optimization problem lead efficient general algorithm work dual domain cluster data based arbitrary set distance despite generality independent initialization unlike em like method k mean guaranteed convergence also provide online optimality bound quality estimated clustering solution deal critical issue center based clustering algorithm selection cluster center also introduce notion stability cluster center well defined lp based quantity play key role algorithm success furthermore also introduce call margin another key ingredient algorithm roughly thought dual counterpart stability allow u obtain computationally efficient approximation latter promising experimental result demonstrate potential method', 'propose multiplicative approximation scheme ma inference problem graphical model applied various inference algorithm method us epsilon decomposition decompose function used throughout inference procedure function smaller set variable known error epsilon ma translates local approximation bound accuracy result show optimize epsilon decomposition provide fast closed form solution l approximation applying ma variable elimination inference algorithm introduce algorithm call dynadecomp extremely fast practice provides guaranteed error bound result superior accuracy efficiency dynadecomp demonstrated', 'abstract missing', 'spectral clustering useful wide ranging set application area biological data analysis image processing data mining however computational communication resource required method processing large scale data set often prohibitively high practitioner often required perturb original data various way quantization downsampling etc invoking spectral algorithm paper use stochastic perturbation theory study effect data perturbation performance spectral clustering show error perturbation spectral clustering closely related perturbation eigenvectors laplacian matrix result derive approximate upper bound clustering error show bound tight empirically across wide range problem suggesting used practical setting determine amount data reduction allowed order meet specification permitted loss clustering performance', 'propose novel hierarchical nonlinear model predicts brain activity area v evoked natural image study reported brain activity measured mean functional magnetic resonance imaging fmri noninvasive technique provides indirect measure neural activity pooled small volume mm cube brain tissue model call spam v model based reasonable assumption fmri measurement reflect possibly nonlinearly pooled rectified output large population simple complex cell v hierarchical filtering stage consists three layer model simple cell model complex cell third layer complex cell linearly pooled called pooled complex cell pooling stage obtains measured fmri signal sparse additive model spam sparse nonparametric nonlinear combination model complex cell model pooled complex cell output summed result show spam v model predicts fmri response evoked natural image better benchmark model provides linear pooling model complex cell furthermore spatial receptive field frequency tuning orientation tuning curve spam v model estimated voxel appears consistent known property v previous analysis data set visualization procedure applied spam v model show nonlinear pooling consists simple compressive saturating nonlinearities', 'describe way learning matrix representation object relationship goal learning allow multiplication matrix represent symbolic relationship object symbolic relationship relationship main novelty method demonstrate lead excellent generalization two different domain modular arithmetic family relationship show system learn first order proposition member christopher penelope member wife higher order proposition member plus member inverse husband wife higher oppsex demonstrate system understands higher order proposition related first order one showing correctly answer question first order proposition involving relation wife even though trained first order example involving relation', 'present new co clustering problem image visual feature problem involves set non object image addition set object image feature co clustered co clustering performed way maximising discrimination object image non object image thus emphasizing discriminative feature provides way obtaining perceptual joint cluster object image feature tackle problem simultaneously boosting multiple strong classifier compete image expertise boosting classifier aggregation weak learner e simple visual feature obtained classifier useful multi category multi view object detection task experiment set pedestrian image face data set demonstrate method yield intuitive image cluster associated feature much superior conventional boosting classifier object detection task', 'describe primal dual framework design analysis online strongly convex optimization algorithm framework yield tightest known logarithmic regret bound follow leader gradient descent algorithm proposed hazankakaag show one interpolate two extreme case particular derive new algorithm share computational simplicity gradient descent achieves lower regret many practical situation finally extend framework generalized strongly convex function', 'bartlett et al recently proved ground condition convex surrogate classification calibration tie minimization surrogate classification risk left important problem algorithmic question minimization surrogate paper propose algorithm provably minimizes classification calibrated surrogate strictly convex differentiable set whose loss span exponential logistic squared loss boosting type guaranteed convergence rate weak learning assumption particular subclass surrogate call balanced convex surrogate key rationale tie maximum likelihood estimation zero sum game set loss satisfy common requirement loss supervised learning report experiment readily available domain flavor algorithm shed light new surrogate potential data dependent strategy tune surrogate', 'paper address important tradeoff privacy learnability designing algorithm learning private database first apply idea dwork et al design specific privacy preserving machine learning algorithm logistic regression involves bounding sensitivity logistic regression perturbing learned classifier noise proportional sensitivity noting approach dwork et al limitation applied machine learning algorithm present another privacy preserving logistic regression algorithm algorithm based solving perturbed objective depend sensitivity prove algorithm preserve privacy model due dwork et al provide learning performance guarantee work also reveals interesting connection regularization privacy', 'compressive sensing c combine sampling compression single sub nyquist linear measurement process sparse compressible signal paper extend theory c include signal concisely represented term graphical model particular use markov random field mrfs represent sparse signal whose nonzero coefficient clustered new model based reconstruction algorithm dubbed lattice matching pursuit lamp stably recovers mrf modeled signal using many fewer measurement computation current state art algorithm', 'cluster assumption exploited semi supervised learning ssl method however unlabeled data merely weakly related target class becomes questionable whether driving decision boundary low density region unlabeled data help classification case cluster assumption may valid consequently leverage type unlabeled data enhance classification accuracy becomes challenge introduce semi supervised learning weakly related unlabeled data sslw inductive method build upon maximum margin approach towards better usage weakly related unlabeled information although sslw could improve wide range classification task paper focus text categorization small training pool key assumption behind work even different topic word usage pattern across different corpus tends consistent end sslw estimate optimal word correlation matrix consistent co occurrence information derived weakly related unlabeled document labeled document empirical evaluation present direct comparison number state art method inductive semi supervised learning text categorization show sslw result significant improvement categorization accuracy equipped small training set unlabeled resource weakly related test bed', 'paper present first data dependent generalization bound non setting based notion rademacher complexity bound extend non case existing rademacher complexity bound derived setting bound provide strict generalization one found case also used within standard scenario apply standard scenario beta mixing stationary sequence examined many previous study non setting benefit form crucial advantage rademacher complexity measure complexity hypothesis class particular data dependent measure complexity class hypothesis based training sample empirical rademacher complexity estimated finite sample lead tighter bound', 'abstract missing', 'paper address question kind knowledge generally transferable unlabeled text suggest analyze semantic correlation word generally transferable structure language propose new method learn structure using appropriately chosen latent variable model semantic correlation contains structural information language space used control joint shrinkage model parameter specific task space regularization empirical study construct different text classification task real world benchmark unlabeled document mixture task test ability various algorithm use mixed unlabeled text enhance classification task empirical result show proposed approach reliable scalable method semi supervised learning regardless source unlabeled data specific task enhanced prediction model used', 'aiming towards development general clustering theory discus abstract axiomatization clustering respect follow work kelinberg kleinberg showed impossibility result axiomatization argue impossibility result inherent feature clustering rather large extent artifact specific formalism used kleinberg opposed previous work focusing clustering function propose address clustering quality measure primitive object axiomatized show principle like formulated kleinberg axiom readily expressed latter framework without leading inconsistency clustering quality measure function given data set partition cluster return non negative real number representing strong conclusive clustering analyze clustering quality measure look like introduce set requirement axiom express requirement extend translation kleinberg axiom framework propose several natural clustering quality measure satisfying proposed axiom addition show proposed clustering quality computed polynomial time', 'abstract missing', 'existing approach nonrigid structure motion assume instantaneous shape deforming object linear combination basis shape estimated anew video sequence contrast propose evolving structure described linear combination basis trajectory principal advantage lateral approach need estimate basis vector computation instead show generic base trajectory discrete cosine transform dct base used effectively describe real motion result significant reduction unknown corresponding stability estimation report empirical performance quantitatively using motion capture data qualitatively several video sequence exhibiting nonrigid motion including piece wise rigid motion articulated motion partially nonrigid motion facial expression highly nonrigid motion person dancing', 'consider problem extracting smooth low dimensional neural trajectory summarize activity recorded simultaneously ten hundred neuron individual experimental trial beyond benefit visualizing high dimensional noisy spiking activity compact denoised form trajectory offer insight dynamic neural circuitry underlying recorded activity current method extracting neural trajectory involve two stage process data first denoised smoothing time static dimensionality reduction technique applied first describe extension two stage method allow degree smoothing chosen principled way account spiking variability may vary across neuron across time present novel method extracting neural trajectory gaussian process factor analysis gpfa unifies smoothing dimensionality reduction operation common probabilistic framework applied method activity neuron recorded simultaneously macaque premotor motor cortex reach planning execution adopting goodness fit metric measure well activity neuron predicted recorded neuron found gpfa provided better characterization population activity two stage method extracted single trial neural trajectory directly observed convergence neural state motor planning effect suggestive attractor dynamic shown indirectly previous study', 'randomized neural network immortalized ai koan day sussman novice minsky came sat hacking pdp asked minsky training randomly wired neural net play tic tac toe sussman replied net wired randomly asked minsky sussman replied want preconception play minsky shut eye close eye sussman asked teacher room empty replied minsky moment sussman enlightened analyze shallow random network help concentration measure inequality specifically consider architecture compute weighted sum input passing bank arbitrary randomized nonlinearities identify condition network exhibit good classification performance bound test error term size dataset number random nonlinearities', 'abstract missing', 'identification comparison nonlinear dynamical system using noisy sparse experimental data vital task many field however current method computationally expensive prone error due part nonlinear nature likelihood surface induced present accelerated sampling procedure enables bayesian inference parameter nonlinear ordinary delay differential equation via novel use gaussian process gp method involves gp regression time series data resulting derivative time delay estimate make parameter inference possible without solving dynamical system explicitly resulting dramatic saving computational time demonstrate speed statistical accuracy approach using example ordinary delay differential equation provide comprehensive comparison current state art method', 'metal binding important structural functional characterization protein previous prediction effort focused bonding state e deciding protein residue act metal ligand binding site identifying geometry metal binding site e deciding residue jointly involved coordination metal ion new prediction problem never attempted protein sequence alone paper formulate framework learning structured output solution relies fact graph theoretical perspective metal binding algebraic property matroid enabling application greedy algorithm learning structured output data set non redundant metalloproteins obtained precision recall level correct ligand ion assignment improves setting metal binding state known', 'multi task learning several related task considered simultaneously hope appropriate sharing information across task task may benefit others context learning linear function supervised classification regression achieved including priori information weight vector associated task expected related paper assume task clustered group unknown beforehand task within group similar weight vector design new spectral norm encodes priori assumption without prior knowledge partition task group resulting new convex optimization formulation multi task learning show simulation synthetic example iedb mhc binding dataset approach outperforms well known convex method multi task learning well related non convex method dedicated problem', 'abstract missing', 'abstract missing', 'paper introduce meannn approach estimation main information theoretic measure differential entropy mutual information divergence opposed nonparametric approach meannn result smooth differentiable function data sample clear geometrical interpretation apply proposed estimator ica problem obtain smooth expression mutual information analytically optimized gradient descent method improved performance proposed ica algorithm demonstrated standard test comparison state art technique', 'recently fitted q iteration fqi based method become popular due increased sample efficiency stable learning process higher quality resulting policy however method remain hard use continuous action space frequently occur real world task e g robotics technical application greedy action selection commonly used policy improvement step particularly problematic expensive continuous action cause unstable learning process introduces optimization bias result highly non smooth policy unsuitable real world system paper show using soft greedy action selection policy improvement step used fqi simplified inexpensive advantage weighted regression result able derive new computationally efficient fqi algorithm even deal high dimensional action space', 'ranking heart many information retrieval application unlike standard regression classification predict output independently ranking interested predicting structured output misranking one object significantly affect whether correctly rank object practice problem ranking involves large number object ranked either approximate structured prediction method required assumption independence object score must made order make problem tractable present probabilistic method learning rank using graphical modelling framework cumulative distribution network cdns take account structure inherent problem ranking modelling joint cumulative distribution function cdfs multiple pairwise preference apply framework problem document retrieval case ohsumed benchmark dataset show ranknet listnet listmle probabilistic model viewed particular instance cdns proposed framework allows exploration broad class flexible structured loss functionals ranking learning', 'present novel mathematical formalism idea local model model potentially complex dynamical system make certain prediction certain situation result restricted responsibility local model may far simpler complete model system show one might combine several local model produce detailed model demonstrate ability learn collection local model large scale example preliminary empirical comparison learning collection local model model learning method', 'markov decision process mdps extensively studied used context planning decision making many method exist find optimal policy problem modelled mdps although finding optimal policy sufficient many domain certain application decision support system policy executed human rather machine finding possible near optimal policy might useful provides flexibility person executing policy paper introduce new concept non deterministic mdp policy address question finding near optimal non deterministic policy propose two solution problem one based mixed integer program one based search algorithm include experimental result obtained applying framework optimize treatment choice context medical decision support system', 'eeg connectivity measure could provide new type feature space inferring subject intention brain computer interface bcis however little known eeg connectivity pattern bcis study eeg connectivity motor imagery mi left right investigated broad frequency range across whole scalp combining beamforming transfer entropy taking account possible volume conduction effect observed connectivity pattern indicate modulation intentionally induced mi strongest gamma band e hz furthermore modulation mi rest found pronounced mi different hand contrast result mi obtained bandpower feature might provide explanation far moderate success connectivity feature bcis concluded future study connectivity based bcis focus high frequency band consider experimental paradigm maximally vary cognitive demand condition', 'present approach low level vision combine two main idea use convolutional network image processing architecture unsupervised learning procedure synthesizes training sample specific noise model demonstrate approach challenging problem natural image denoising using test set hundred natural image find convolutional network provide comparable case superior performance state art wavelet markov random field mrf method moreover find convolutional network offer similar performance blind denoising setting compared technique non blind setting also show convolutional network mathematically related mrf approach presenting mean field theory mrf specially designed image denoising although approach related convolutional network avoid computational difficulty mrf approach arise probabilistic learning inference make possible learn image processing architecture high degree representational power train model parameter whose computational expense significantly le associated inference mrf approach even hundred parameter', 'compared invasive brain computer interface bci non invasive bci system based electroencephalogram eeg signal applied successfully complex control task present study however demonstrate possible report interaction human subject complex real device pinball machine first result single subject study clearly show fast well timed control well beyond chance level possible even though environment extremely rich requires complex predictive behavior using machine learning method mental state decoding bci based pinball control possible within first session without necessity employ lengthy subject training current study still anecdotal nature clearly show compelling control excellent timing dynamic possible non invasive bci', 'working memory central topic cognitive neuroscience critical solving real world problem information multiple temporally distant source must combined generate appropriate behavior however often neglected fact learning use working memory effectively difficult problem gating framework collection psychological model show dopamine train basal ganglion prefrontal cortex form useful working memory representation certain type problem bring together gating idea machine learning using finite memory system general problem thus present normative gating model learns online temporal difference method use working memory maximize discounted future reward general partially observable setting model successfully solves benchmark working memory problem exhibit limitation similar observed human experiment moreover model introduces concise normative definition high level cognitive concept working memory cognitive control term maximizing discounted future reward', 'abstract missing', 'abstract missing', 'provide sharp bound rademacher gaussian complexity constrained linear class bound make short work providing number corollary including risk bound linear prediction including setting weight vector constrained either l l constraint margin bound including l l margin along general notion based relative entropy proof pac bayes theorem l covering number l p norm constraint relative entropy constraint addition providing unified analysis result herein provide sharpest risk margin bound improving upon number previous result interestingly result show uniform convergence rate empirical risk minimization algorithm tightly match regret bound online learning algorithm linear prediction constant factor', 'policy gradient pg reinforcement learning algorithm strong local convergence guarantee learning performance typically limited large variance estimate gradient paper formulate variance reduction problem describing signal noise ratio snr policy gradient algorithm evaluate snr carefully popular weight perturbation wp algorithm confirm snr good predictor long term learning performance episodic formulation cost go function indeed optimal baseline propose two modification traditional model free policy gradient algorithm order optimize snr first examine wp using anisotropic sampling distribution introduces bias update increase snr bias interpretted following natural gradient cost function second show non gaussian distribution also increase snr argue optimal isotropic distribution shell distribution constant magnitude uniform distribution direction demonstrate modification produce substantial improvement learning performance challenging policy gradient experiment', 'abstract missing', 'one major role primary visual cortex v vision encoding orientation line contour role local recurrent network computation however still matter debate address issue analyze intracellular recording data cat v combine measuring tuning range neuronal property precise localization recording site orientation preference map analysis consider network model hodgkin huxley type neuron arranged according biologically plausible two dimensional topographic orientation preference map systematically vary strength recurrent excitation inhibition relative strength afferent input parametrization give rise different model instance tuning model neuron different location orientation map compared experimentally measured orientation tuning membrane potential spike output excitatory inhibitory conductance quantitative analysis show data provides strong evidence network model afferent input dominated strong balanced contribution recurrent excitation inhibition recurrent regime close regime instability strong self sustained activity network occurs firing rate neuron best fitting network particularly sensitive small modulation model parameter could one functional benefit network operating particular regime', 'present cutoff averaging technique converting conservative online learning algorithm batch learning algorithm online batch conversion technique work well certain type online learning algorithm others whereas cutoff averaging explicitly try adapt characteristic online algorithm converted attractive property technique preserve efficiency original online algorithm making approporiate large scale learning problem provide statistical analysis technique back theoretical claim experimental result', 'address problem learning classifier several related task may differ joint distribution input output variable task small possibly even empty labeled sample large unlabeled sample available unlabeled sample reflect target distribution labeled sample may biased derive solution produce resampling weight match pool example target distribution given task work motivated problem predicting sociodemographic feature user web portal based content accessed questionnaire offered small portion portal user produce biased sample transfer learning enables u make prediction even new portal training data improves overall prediction accuracy', 'selective attention intensively studied psychological phenomenon rife theoretical suggestion schism critical idea limited capacity allocation produced half century worth conflict phenomenon early late selection influential resolution debate based notion perceptual load lavie tic suggests low load easy task underuse total capacity attention mandatorily lead processing stimulus irrelevant current attentional set whereas high load difficult task grab resource leaving distractors high dry argue theory present challenge bayesian theory attention suggest alternative statistical account key supporting data', 'actor critic algorithm reinforcement learning achieving renewed popularity due good convergence property situation approach often fail e g function approximation involved interestingly growing evidence actor critic approach based phasic dopamine signal play key role biological learning cortical basal ganglion derive temporal difference based actor critic learning algorithm convergence proved without assuming separate time scale actor critic approach demonstrated applying network spiking neuron established relation phasic dopamine temporal difference signal lends support biological relevance algorithm', 'introduces new probability distribution potentially infinite number binary markov chain call markov indian buffet process process extends ibp allow temporal dependency hidden variable use stochastic process build nonparametric extension factorial hidden markov model working inference scheme combine slice sampling dynamic programming demonstrate infinite factorial hidden markov model used blind source separation', 'variety behavioral task subject exhibit automatic apparently sub optimal sequential effect respond rapidly accurately stimulus reinforces local pattern stimulus history string repetition alternation compared violates pattern often case even local trend arise chance context randomized design stimulus history predictive power work use normative bayesian framework examine hypothesis idiosyncrasy may reflect inadvertent engagement fundamental mechanism critical adapting changing statistic natural environment show prior belief non stationarity induce experimentally observed sequential effect otherwise bayes optimal algorithm bayesian algorithm shown well approximated linear exponential filtering past observation feature also apparent behavioral data derive explicit relationship parameter computation exact bayesian algorithm approximate linear exponential filter since latter equivalent leaky integration process commonly used model neuronal dynamic underlying perceptual decision making trial trial dependency model provides principled account dynamic useful also show near optimal tuning leaky integration process possible using stochastic gradient descent based noisy binary input proof concept neuron implement near optimal prediction based standard neuronal dynamic also learn tune processing parameter without explicitly representing probability', 'abstract missing', 'consider problem multiple kernel learning mkl formulated convex concave problem past two efficient method e semi infinite linear programming silp subgradient descent sd proposed large scale multiple kernel learning despite success method shortcoming sd method utilizes gradient current solution b silp method regularize approximate solution obtained cutting plane model work extend level method originally designed optimizing non smooth objective function convex concave optimization apply multiple kernel learning extended level method overcomes drawback silp sd exploiting gradient computed past iteration regularizing solution via projection level set empirical study eight uci datasets show extended level method significantly improve efficiency saving average computational time silp method sd method', 'consider problem efficiently encoding signal transforming new representation whose component statistically independent widely studied linear solution independent component analysis ica exists case signal generated linear transformation independent non gaussian source examine complementary case source non gaussian elliptically symmetric case linear transform suffices properly decompose signal independent component show simple nonlinear transformation call radial gaussianization rg able remove dependency demonstrate methodology context natural signal statistic first show joint distribution bandpass filter response sound image better described elliptical linearly transformed independent source consistent demonstrate reduction dependency achieved applying rg either pair block bandpass filter response significantly greater achieved pca ica', 'abstract missing', 'algorithm solving markov decision process rely discount factor ensures convergence fact often used problem intrinsic motivation paper show used approximate dynamic programming artificially low discount factor may significantly improve performance problem tetri propose two explanation phenomenon first justification follows directly standard approximation error bound using lower discount factor may decrease approximation error bound however also show bound loose thus decrease entirely justify better practical performance thus propose another justification reward received sporadically case tetri derive tighter bound support significant performance increase decrease discount factor', 'distributed learning problem fundamental interest machine learning cognitive science paper present asynchronous distributed learning algorithm two well known unsupervised learning framework latent dirichlet allocation lda hierarchical dirichlet process hdp proposed approach data distributed across p processor processor independently perform gibbs sampling local data communicate information local asynchronous manner processor demonstrate asynchronous algorithm able learn global topic model statistically accurate learned standard lda hdp sampler significant improvement computation time memory show speedup result million word text corpus using processor provide perplexity result virtual processor stepping stone development asynchronous hdp parallel hdp sampler also introduced', 'causal structure discovery technique usually assume cause one variable observed called causal sufficiency assumption practice untestable often violated paper present efficient causal structure learning algorithm suited causally insufficient data similar algorithm ic fci proposed approach drop causal sufficiency assumption learns structure indicates potential latent cause pair observed variable assuming constant local density data generating graph algorithm make quadratic number conditional independence test w r number variable show experiment algorithm comparable state art fci algorithm accuracy several order magnitude faster large problem conclude mbcs make new range causally insufficient problem computationally tractable', 'study learning formulation non convex regularizaton natural sparse linear model two approach problem heuristic method gradient descent find local minimum drawback approach lack theoretical guarantee showing local minimum give good solution convex relaxation l regularization solves problem condition however often lead sub optimal sparsity reality paper try remedy gap theory practice particular investigate multi stage convex relaxation scheme solving problem non convex regularization theoretically analyze behavior resulting two stage relaxation scheme capped l regularization performance bound show procedure superior standard l convex relaxation learning sparse target experiment confirm effectiveness method simulation real data', 'present new massively parallel architecture accelerating machine learning algorithm based array variable resolution arithmetic vector processing element vpe group vpes operate simd single instruction multiple data mode group connected independent memory bank way memory bandwidth scale number vpe main data flow local keeping power dissipation low vpes implemented two fpga field programmable gate array chip obtain sustained speed gmacs billion multiply accumulate per sec svm training gmacs svm classification performance order magnitude higher fpga implementation reported far speed one fpga similar fastest speed published graphic processor mnist problem despite clock rate fpga six time lower high performance low clock rate make massively parallel architecture particularly attractive embedded application low power dissipation critical test convolutional neural network learning algorithm way', 'continuous attractor neural network canns emerging promising model describing encoding continuous stimulus neural system due translational invariance neuronal interaction canns hold continuous family neutrally stable state study systematically explore neutral stability cann facilitates tracking performance capacity believed wide application brain function develop perturbative approach utilizes dominant movement network stationary state state space quantify distortion bump shape tracking study effect tracking performance result obtained maximum speed moving stimulus trackable reaction time catch abrupt change stimulus', 'account people learn functional relationship continuous variable tended focus two possibility people estimating explicit function simply performing associative learning supported similarity provide rational analysis function learning drawing work regression machine learning statistic using equivalence bayesian linear regression gaussian process show learning explicit rule using similarity seen two view one solution problem use insight define gaussian process model human function learning combine strength approach', 'abstract missing', 'bandpass filtering orientation selectivity contrast gain control prominent feature sensory coding level v simple cell effect bandpass filtering orientation selectivity assessed within linear model contrast gain control inherently nonlinear computation employ class l p elliptically contoured distribution investigate extent two feature orientation selectivity contrast gain control suited model statistic natural image within framework find contrast gain control play significant role removal redundancy natural image orientation selectivity contrast limited potential redundancy reduction', 'visual attention system respond placidly common stimulus presented time keep alert anomalous visual input paper dynamic visual attention model based rarity feature proposed introduce incremental coding length icl measure perspective entropy gain feature objective model maximize entropy sampled visual feature order optimize energy consumption limit amount energy system distributed amongst feature according incremental coding length selecting feature large coding length increment computational system achieve attention selectivity static dynamic scene demonstrate proposed model achieves superior accuracy comparison mainstream approach static saliency map generation moreover also show model capture several le reported dynamic visual search behavior attentional swing inhibition return', 'principal component analysis pca become established one key tool dimensionality reduction dealing real valued data approach exponential family pca non negative matrix factorisation successfully extended pca non gaussian data type technique fail take advantage bayesian inference suffer problem overfitting poor generalisation paper present fully probabilistic approach pca generalised exponential family based hybrid monte carlo sampling describe model based factorisation observed data matrix show performance model synthetic real data', 'integrating semantic syntactic analysis essential document analysis using analogous reasoning present approach combine bag word spatial model perform semantic syntactic analysis recognition object based internal appearance context argue object recognition requires modeling relative spatial location image feature within object bag word sufficient representing context learning model weakly labeled data involves labeling feature two class foreground object informative background context labeling present shape aware model utilizes contour information efficient accurate labeling feature image approach iterates mcmc based labeling contour based labeling feature integrate co occurrence feature shape similarity', 'classification problem support vector machine maximize margin separation two class paradigm successful solution obtained svms dominated direction large data spread biased separate class cutting along large spread direction article proposes novel formulation overcome sensitivity maximizes margin relative spread data proposed formulation efficiently solved experiment digit datasets show drastic performance improvement svms', 'abstract missing', 'present mixture model whose component restricted boltzmann machine rbms possibility considered computing partition function rbm intractable appears make learning mixture rbms intractable well surprisingly formulated third order boltzmann machine mixture model learned tractably using contrastive divergence energy function model capture three way interaction among visible unit hidden unit single hidden multinomial unit represents cluster label distinguishing feature model unlike mixture model mixing proportion explicitly parameterized instead defined implicitly via energy function depend parameter model present result mnist norb datasets showing implicit mixture rbms learns cluster reflect class structure data', 'propose new class consistency constraint linear programming lp relaxation finding probable map configuration graphical model usual cluster based lp relaxation enforce joint consistency belief cluster variable computational cost increasing exponentially size cluster partitioning state space cluster enforcing consistency across partition obtain class constraint although le tight computationally feasible large cluster show solve cluster selection partitioning problem monotonically dual lp using current belief guide choice obtain dual message passing algorithm apply protein design problem variable large state space usual cluster based relaxation costly', 'abstract missing', 'propose new fast gaussian summation algorithm high dimensional datasets high accuracy first extend original fast multipole type method use approximation scheme hard probabilistic error second utilize new data structure called subspace tree map data point node lower dimensional mapping determined linear dimension reduction method pca new data structure suitable reducing cost pairwise distance computation dominant cost many kernel method algorithm guarantee probabilistic relative error kernel sum applied high dimensional gaussian summation ubiquitous inside many kernel method key computational bottleneck provide empirical speedup result low high dimensional datasets dimension', 'abstract missing', 'abstract missing', 'paper focus training deep neural network visual recognition task one challenge lack informative regularization network parameter imply meaningful control computed function propose training strategy take advantage kernel method existing kernel function represents useful prior knowledge learning task interest derive efficient algorithm using stochastic gradient descent demonstrate positive result wide range visual recognition task', 'paper introduces new approach constructing meaningful lower dimensional representation set data point argue constraining mapping high low dimensional space diffeomorphism natural way ensuring pairwise distance approximately preserved accordingly develop algorithm diffeomorphically map data near lower dimensional subspace project onto subspace problem solving mapping transformed one solving eulerian flow field compute using idea kernel method demonstrate efficacy approach various real world data set', 'many interesting problem including bayesian network structure search cast term finding optimum value function space graph however function often expensive compute exactly present method derived study reproducing kernel hilbert space take advantage regular structure space graph fixed number node obtain approximation desired function quickly reasonable accuracy test method small testing set real world bayesian network result suggest method reasonably accurate bde score varies quadratically space graph', 'abstract missing', 'many motor skill humanoid robotics learned using parametrized motor primitive done imitation learning however interesting motor learning problem high dimensional reinforcement learning problem often beyond reach current method paper extend previous work policy learning immediate reward case episodic reinforcement learning show result general common framework also connected policy gradient method yielding novel algorithm policy learning assuming form exploration particularly well suited dynamic motor primitive resulting algorithm em inspired algorithm applicable complex motor learning task compare algorithm alternative parametrized policy search method show outperforms previous method apply context motor learning show learn complex ball cup task using real barrett wam robot arm', 'many nonlinear dynamical phenomenon effectively modeled system switch among set conditionally linear dynamical mode consider two model switching linear dynamical system slds switching vector autoregressive var process paper present nonparametric approach learning unknown number persistent smooth dynamical mode utilizing hierarchical dirichlet process prior develop sampling algorithm combine truncated approximation dirichlet process efficient joint sampling mode state sequence utility flexibility model demonstrated synthetic data sequence dancing honey bee ibovespa stock index', 'research animal learning behavioral neuroscience distinguished two form action control habit based form relies stored action value goal directed form forecast compare action outcome based model environment habit based control subject extensive computational research computational principle underlying goal directed control animal far received le attention present paper advance computational framework goal directed control animal human take three empirically motivated point founding premise neuron dorsolateral prefrontal cortex represent action policy neuron orbitofrontal cortex represent reward neural computation across domain appropriately understood performing structured probabilistic inference purely computational level resulting account relates closely previous work using bayesian inference solve markov decision problem extends work introducing new algorithm provably converges optimal plan cognitive neuroscientific level theory provides unifying framework several different form goal directed action selection placing emphasis novel form within orbitofrontal reward representation directly drive policy selection', 'discovery causal relationship set observed variable fundamental problem science continuous valued data linear acyclic causal model often used model well understood well known method fit data reality course many causal relationship le nonlinear raising doubt applicability usefulness purely linear method contribution show fact basic linear framework generalized nonlinear model additive noise extended framework nonlinearities data generating process fact blessing rather curse typically provide information underlying causal system allow aspect true data generating mechanism identified addition theoretical result show simulation simple real data experiment illustrating identification power provided nonlinearities', 'given n vertex weighted tree structural diameter subset vertex present technique compute corresponding time gram matrix pseudoinverse graph laplacian n time discus application technique fast label prediction generic graph approximate graph spanning tree predict kernel perceptron address approximation graph either minimum spanning tree shortest path tree fast computation pseudoinverse enables u address prediction problem large graph end present experiment two web spam classification task one includes graph node edge result indicate accuracy technique competitive previous method using full graph information', 'abstract missing', 'paper present theoretical analysis problem adaptation multiple source source domain distribution input point well hypothesis error epsilon given problem consists combining hypothesis derive hypothesis small error respect target domain present several theoretical result relating problem particular prove standard convex combination source hypothesis may fact perform poorly instead combination weighted source distribution benefit favorable theoretical guarantee main result show remarkably fixed target function exists distribution weighted combining rule loss epsilon respect target mixture source distribution generalize setting single target function multiple consistent target function show existence combining rule error epsilon finally report empirical result multiple source adaptation problem real world dataset', 'empirical evidence show favorable situation semi supervised learning ssl algorithm capitalize abundancy unlabeled training data improve performance learning task sense fewer labeled training data needed achieve target error bound however situation unlabeled data seem help recent attempt theoretically characterizing situation unlabeled data help met little success sometimes appear conflict intuition paper attempt bridge gap practice theory semi supervised learning develop rigorous framework analyzing situation unlabeled data help quantify improvement possible using finite sample error bound show large class problem ssl significantly outperform supervised learning finite sample regime sometimes also term error convergence rate', 'correlation spike count often used analyze neural coding noise typically assumed gaussian yet assumption often inappropriate especially low spike count study present copula alternative approach copula possible use arbitrary marginal distribution poisson negative binomial better suited modeling noise distribution spike count furthermore copula place wide range dependence structure disposal used analyze higher order interaction develop framework analyze spike count data mean copula method parameter inference based maximum likelihood estimate computation shannon entropy provided apply method data recorded macaque prefrontal cortex data analysis lead three significant finding copula based distribution provide better fit discretized multivariate normal distribution negative binomial margin fit data better poisson margin dependence model includes pairwise interaction overestimate information entropy least compared model higher order interaction', 'present sparse approximation approach dependent output gaussian process gp employing latent function framework apply convolution process formalism establish dependency output variable latent function represented gp based latent function establish approximation scheme using conditional independence assumption output process leading approximation full covariance determined location latent function evaluated show result proposed methodology synthetic data real world application pollution prediction sensor network', 'confidence weighted cw learning online learning method linear classifier maintains gaussian distribution weight vector covariance matrix represents uncertainty weight correlation confidence constraint ensure weight vector drawn hypothesis distribution correctly classifies example specified probability within framework derive new convex form constraint analyze mistake bound model empirical evaluation synthetic text data show version cw learning achieves lower cumulative sample error commonly used first order second order online method', 'odor transduction process large time constant susceptible various type noise therefore olfactory code sensor receptor level general slow highly variable indicator input odor natural artificial situation insect overcome problem using neuronal device antennal lobe al transforms identity code olfactory receptor spatio temporal code transformation improves decision mushroom body mb subsequent classifier speed accuracy propose rate model based two intrinsic mechanism insect al namely integration inhibition present mb classifier model resembles sparse random structure insect mb local hebbian learning procedure governs plasticity model formulation help understand signal conditioning classification method insect olfactory system also leveraged synthetic problem among consider discrimination odor mixture pure odor show set record metal oxide gas sensor cascade two new model facilitates fast accurate discrimination even highly imbalanced mixture pure odor', 'introduce kernel based method change point analysis within sequence temporal observation change point analysis unlabelled sample observation consists first testing whether change distribution occurs within sample second change occurs estimating change point instant distribution observation switch one distribution another different distribution propose test statistic based upon maximum kernel fisher discriminant ratio measure homogeneity segment derive limiting distribution null hypothesis change occurs establish consistency alternative hypothesis change occurs allows build statistical hypothesis testing procedure testing presence change point prescribed false alarm probability detection probability tending one large sample setting change actually occurs test statistic also yield estimator change point location promising experimental result temporal segmentation mental task bci data pop song indexation presented', 'essence exploration acting try decrease uncertainty propose new methodology representing uncertainty continuous state control problem approach multi resolution exploration mre us hierarchical mapping identify region state space would benefit additional sample demonstrate mre broad utility using speed learning prototypical model based value based reinforcement learning method empirical result show mre improves upon state art exploration approach', 'show improved sequence magnetic resonance imaging found automated optimization bayesian design score combining recent advance approximate bayesian inference natural image statistic high performance numerical computation propose first scalable bayesian experimental design framework problem high relevance clinical brain research solution requires approximate inference dense non gaussian model scale seldom addressed propose novel scalable variational inference algorithm show powerful method numerical mathematics modified compute primitive framework approach evaluated realistic setup raw data mr scanner', 'abstract missing', 'abstract missing', 'describe new content publishing system selects article serve user choosing editorially programmed pool frequently refreshed deployed major internet portal selects article serve hundred million user visit per day significantly increasing number user click original manual approach editor periodically selected article display challenge face include dynamic content pool short article lifetime non stationary click rate extremely high traffic volume fundamental problem must solve quickly identify item popular perhaps within different user segment exploit remain current must also explore underlying pool constantly identify promising alternative quickly discarding poor performer approach based tracking per article performance near real time online model describe characteristic constraint application setting discus design choice show importance effectiveness coupling online model simple randomization procedure discus challenge encountered production online content publishing environment highlight issue deserve careful attention analysis application also suggests number future research avenue', 'paper discus non parametric regression riemannian manifold learning problem arises frequently many application area ranging signal processing computer vision robotics computer graphic present new algorithmic scheme solution general learning problem based regularized empirical risk minimization regularization functional take account geometry input output manifold show implement prior particularly natural moreover demonstrate algorithm performs well difficult surface registration problem', 'attempting simultaneously partition row example column feature data matrix co clustering algorithm often demonstrate surpris ingly impressive performance improvement traditional one sided row clustering technique good clustering feature may seen combinatorial transformation data matrix effectively enforcing form regularization may lead better clustering example vice versa many application partial supervision form row label well column label may available potentially assist co clustering paper develop two novel semi supervised multi class classification algorithm motivated respectively spectral bipartite graph partitioning matrix approximation e g non negative matrix factorization formulation co clustering algorithm support dual supervision form label example feature ii provide principled predictive capability sample test data iii arise naturally classical representer theorem applied regularization problem posed collection reproducing kernel hilbert space empirical result demonstrate effectiveness utility algorithm', 'abstract missing', 'propose using correlated bigram lsa unsupervised lm adaptation automatic speech recognition model trained using efficient variational em smoothed using proposed fractional kneser ney smoothing handle fractional count approach scalable large training corpus via bootstrapping bigram lsa unigram lsa lm adaptation unigram bigram lsa integrated background n gram lm via marginal adaptation linear interpolation respectively experimental result show applying unigram bigram lsa together yield relative perplexity reduction absolute character error rate cer reduction compared applying unigram lsa mandarin rt test set comparing unadapted baseline approach reduces absolute cer', 'present discriminative part based approach human action recognition video sequence using motion feature model based recently proposed hidden conditional random field hcrf object recognition similar hcrf object recognition model human action flexible constellation part conditioned image observation different object recognition model combine large scale global feature local patch feature distinguish various action experimental result show model comparable state art approach action recognition particular experimental result demonstrate combining large scale global feature local patch feature performs significantly better directly applying hcrf local patch alone', 'kernel principal component analysis kpca popular generalization linear pca allows non linear feature extraction kpca data input space mapped higher usually dimensional feature space data linearly modeled feature space typically induced implicitly kernel function linear pca feature space performed via kernel trick however due implicitness feature space extension pca robust pca cannot directly generalized kpca paper present technique overcome problem extends unified framework treating noise missing data outlier kpca method based novel cost function perform inference kpca extensive experiment synthetic real data show algorithm outperforms existing method', 'temporal restricted boltzmann machine trbm probabilistic model sequence able successfully model e generate nice looking sample several high dimensional sequence motion capture data pixel low resolution video ball bouncing box major disadvantage trbm exact inference extremely hard since even computing gibbs update single variable posterior exponentially expensive difficulty necessitated use heuristic inference procedure nonetheless accurate enough successful learning paper introduce recurrent trbm slight modification trbm exact inference easy exact gradient learning almost tractable demonstrate rtrbm better analogous trbm generating motion capture video bouncing ball', 'increased availability data complex domain desirable learn bayesian network structure sufficiently expressive generalization also allowing tractable inference method thin junction tree principle used purpose fully greedy nature make prone overfitting particularly data scarce work present novel method learning bayesian network bounded treewidth employ global structure modification polynomial size graph treewidth bound heart method triangulated graph dynamically update way facilitates addition chain structure increase bound model treewidth one demonstrate effectiveness treewidth friendly method several real life datasets importantly also show using global operator able achieve better generalization even learning bayesian network unbounded treewidth', 'present algorithm solving broad class online resource allocation problem online algorithm applied environment abstract job arrive one time one complete job investing time number abstract activity according schedule assume fraction job completed schedule monotone submodular function set pair v time invested activity v assumption online algorithm performs near optimally according two natural metric fraction job completed within time fixed deadline ii average time required complete job evaluate algorithm experimentally using learn online schedule allocating cpu time among solver entered sat solver competition', 'abstract missing', 'report compact realization short term depression std vlsi stochastic synapse behavior circuit based subtractive single release model std experimental result agree well simulation exhibit expected std behavior transmitted spike train negative autocorrelation lower power spectral density low frequency remove redundancy input spike train mean transmission probability inversely proportional input spike rate suggested automatic gain control mechanism neural system dynamic stochastic synapse could potentially powerful addition existing deterministic vlsi spiking neural system', 'principled mechanism identifying conditional dependency time series data provided structure learning dynamic bayesian network dbns important assumption dbn structure learning data generated stationary process assumption true many important setting paper introduce new class graphical model called non stationary dynamic bayesian network conditional dependence structure underlying data generation process permitted change time non stationary dynamic bayesian network represent new framework studying problem structure network evolving time define non stationary dbn model present mcmc sampling algorithm learning structure model time series data different assumption demonstrate effectiveness algorithm simulated biological data', 'conditional random sampling cr originally proposed efficiently computing pairwise l l distance static large scale sparse data set text web data previously presented using heuristic argument study extends cr handle dynamic streaming data much better reflect real world situation assuming static data compared known sketching algorithm dimension reduction stable random projection cr exhibit significant advantage one sketch particular demonstrate cr applied efficiently compute l p distance hilbertian metric popular machine learning although fully rigorous analysis cr difficult prove simple modification cr rigorous least important application computing hamming norm generic estimator approximate variance formula provided tested various application computing hamming norm hamming distance chi distance', 'language comprehension human significantly constrained memory yet rapid highly incremental capable utilizing wide range contextual information resolve ambiguity form expectation future input contrast leading psycholinguistic model fielded algorithm natural language parsing non incremental run time superlinear input length enforce structural locality constraint probabilistic dependency event present new limited memory model sentence comprehension involves adaptation particle filter sequential monte carlo method problem incremental parsing show model reproduce classic result online sentence comprehension naturally provides first rational account outstanding problem psycholinguistics preferred alternative syntactic ambiguity seems grow attractive time even absence strong disambiguating information', 'present multi label multiple kernel learning mkl formulation data embedded low dimensional space directed instance label correlation encoded hypergraph formulate problem kernel induced feature space propose learn kernel matrix linear combination given collection kernel matrix mkl framework proposed learning formulation lead non smooth min max problem cast semi infinite linear program silp propose approximate formulation guaranteed error bound involves unconstrained convex optimization problem addition show objective function approximate formulation continuously differentiable lipschitz gradient hence existing method employed compute optimal solution efficiently apply proposed formulation automated annotation drosophila gene expression pattern image promising result reported comparison representative algorithm', 'analogy pca setting sparse pca problem often solved iteratively alternating two subtasks cardinality constrained rank one variance maximization matrix deflation former received great deal attention literature latter seldom analyzed typically borrowed without justification pca context work demonstrate standard pca deflation procedure seldom appropriate sparse pca setting rectify situation first develop several heuristic deflation alternative desirable property reformulate sparse pca optimization problem explicitly reflect maximum additional variance objective round result generalized deflation procedure typically outperforms standard technique real world datasets', 'contour established biological computer vision literature compact yet descriptive representation object shape individual contour provide structure lack large spatial support region segment lack internal structure present method grouping contour image using relationship contour second related image stereo motion similarity provide cue aid task contour similar transformation relating matching contour second image likely belong single group find match contour rely shape applies directly three modality without modification constrant specialized approach developed independently visually salient contour extracted image along set candidate transformation aligning subset transformation group contour matching shape across two image identified provide context evaluating match individual contour point across image resulting context contour used perform final grouping contour original image simultaneously finding match related image shape matching demonstrate grouping result image pair consisting stereo motion similar image method also produce qualitatively better result baseline method use inferred context', 'abstract missing', 'observation consisting measurement relationship pair object arise many setting protein interaction gene regulatory network collection author recipient email social network analyzing data probabilisic model delicate simple exchangeability assumption underlying many boilerplate model longer hold paper describe class latent variable model data called mixed membership stochastic blockmodels model extends blockmodels relational data one capture mixed membership latent relational structure thus providing object specific low dimensional representation develop general variational inference algorithm fast approximate posterior inference explore application social network protein interaction network', 'young child demonstrate ability make inference preference agent based choice however exists overarching account child learn preference use knowledge use rational model preference learning drawing idea economics computer science explain behavior child several recent experiment specifically show simple econometric model extended capture two four year old use statistical information inferring preference generalization preference', 'abstract missing', 'formulate study new variant k armed bandit problem motivated e commerce application model arm stochastic lifetime expire setting algorithm need continuously explore new arm contrast standard k armed bandit model arm available indefinitely exploration reduced optimal arm identified near certainty main motivation setting online advertising ad limited lifetime due example nature content campaign budget algorithm need choose among large collection ad fully explored within ad lifetime present optimal algorithm state aware deterministic reward function case build technique obtain algorithm state oblivious stochastic reward function case empirical study various reward distribution including one derived real world ad serving application show proposed algorithm significantly outperform standard multi armed bandit approach applied setting', 'unexpected stimulus challenge machine learning algorithm identify distinct type unexpected event focusing incongruent event general level specific level classifier give conflicting prediction define formal framework representation processing incongruent event starting notion label hierarchy show partial order label deduced hierarchy event compute probability different way based adjacent level according partial order label hierarchy incongruent event event probability computed based specific level accordance partial order much smaller probability computed based general level leading conflicting prediction derive algorithm detect incongruent event different type hierarchy corresponding class membership part membership respectively show promising result real data two specific problem vocabulary word speech recognition identification new sub class e g face new individual audio visual facial object recognition', 'information decoded brain one difficult important question neuroscience whether neural correlation important decoding neural activity special interest developed general framework investigating far decoding process brain simplified first hierarchically construct simplified probabilistic model neural response ignore k th order correlation using maximum entropy principle compute much information lost information decoded using simplified model e mismatched decoder introduce information theoretically correct quantity evaluating information obtained mismatched decoder applied proposed framework spike data vertebrate retina used m natural movie stimulus computed information contained neural activity movie found information loss negligibly small population activity ganglion cell even order correlation ignored decoding also found assume stationarity long duration information analysis dynamically changing stimulus like natural movie pseudo correlation seem carry large portion information', 'neural probabilistic language model nplms shown competitive occasionally superior widely used n gram language model main drawback nplms extremely long training testing time morin bengio proposed hierarchical language model built around binary tree word two order magnitude faster non hierarchical language model based however performed considerably worse non hierarchical counterpart spite using word tree created using expert knowledge introduce fast hierarchical language model along simple feature based algorithm automatic construction word tree data show resulting model outperform non hierarchical model achieve state art performance', 'present simple new monte carlo algorithm evaluating probability observation complex latent variable model deep belief network method based markov chain estimate based short run formally unbiased expectation log probability test set underestimated could form basis probabilistic bound method much cheaper gold standard annealing based method slightly expensive cheapest monte carlo method give example new method substantially improving simple variational bound modest extra cost', 'propose general method called truncated gradient induce sparsity weight online learning algorithm convex loss method several essential property first degree sparsity continuous parameter control rate sparsification sparsification total sparsification second approach theoretically motivated instance regarded online counterpart popular l regularization method batch setting prove small rate sparsification result small additional regret respect typical online learning guarantee finally approach work well empirically apply several datasets find datasets large number feature substantial sparsity discoverable', 'consider linear prediction model target function sparse linear combination set basis function interested problem identifying basis function non zero coefficient reconstructing target function noisy observation two heuristic widely used practice forward backward greedy algorithm first show neither idea adequate second propose novel combination based forward greedy algorithm take backward step adaptively whenever beneficial prove strong theoretical result showing procedure effective learning sparse representation experimental result support theory', 'adaptation visually guided reaching movement novel visuomotor environment e g wearing prism goggles comprises motor adaptation also substantial sensory adaptation corresponding shift perceived spatial location visual proprioceptive cue previous computational model sensory component visuomotor adaptation assumed driven purely discrepancy introduced visual proprioceptive estimate hand position independent motor component adaptation instead propose unified model sensory motor adaptation jointly driven optimal bayesian estimation sensory motor contribution perceived error model able account pattern performance error visuomotor adaptation well subsequent perceptual aftereffect unified model also make surprising prediction force field adaptation elicit similar perceptual shift even though never discrepancy visual proprioceptive observation confirm prediction experiment', 'many human interaction involve piece information passed one person another raising question process information transmission affected capacity agent involved sir frederic bartlett explored influence memory bias serial reproduction information one person reconstruction stimulus memory becomes stimulus seen next person experiment done using relatively uncontrolled stimulus picture story suggested serial reproduction would transform information way reflected bias inherent memory formally analyze serial reproduction using bayesian model reconstruction memory giving general result characterizing effect memory bias information transmission test prediction account two experiment using simple one dimensional stimulus result provide theoretical empirical justification idea serial reproduction reflects memory bias', 'classical game theoretic approach make strong rationality assumption difficulty modeling observed behaviour economic game human subject investigate role finite level iterated reasoning non selfish utility function partially observable markov decision process model incorporates game theoretic notion interactivity generative model capture broad class characteristic behaviour multi round investment game invert generative process recognition model used classify subject playing investor trustee game randomly matched opponent', 'abstract missing', 'continuously adaptive discretization message passing cad mp new message passing algorithm employing adaptive discretization previous message passing algorithm approximated arbitrary continuous probability distribution using either family continuous distribution exponential family particle set discrete sample fixed uniform discretization contrast cad mp us discretization non uniform ii adaptive non uniformity allows cad mp localize interesting feature sharp peak marginal belief distribution time complexity scale logarithmically precision opposed uniform discretization scale best linearly give principled method altering non uniform discretization according information based measure cad mp shown experiment simulated data estimate marginal belief much precisely competing approach computational expense', 'machine learning problem classifier design studied perspective probability elicitation statistic show standard approach proceeding specification loss minimization conditional risk overly restrictive shown better alternative start specification functional form minimum conditional risk derive loss function various consequence practical interest showing widely adopted practice relying convex loss function unnecessary many new loss derived classification problem point illustrated derivation new loss convex compromise computational tractability classifier design robust contamination data outlier new boosting algorithm savageboost derived minimization loss experimental result show indeed le sensitive outlier conventional method ada real logitboost converges fewer iteration', 'introduce family unsupervised algorithm numerical taxonomy clustering simultaneously cluster data learn taxonomy encodes relationship cluster algorithm work maximizing dependence taxonomy original data resulting taxonomy informative visualization complex data simple clustering addition taking account relation different cluster shown substantially improve quality clustering compared state art algorithm literature spectral clustering previous dependence maximization approach demonstrate algorithm image text data', 'coding information neural population depends critically statistical dependency neuronal response however simple model combine observation marginal distribution single neuron spike count often approximately poisson joint distribution response multiple neuron often strongly dependent show marginal joint property neural response captured using poisson copula model copula joint distribution allow random variable arbitrary marginals combined incorporating arbitrary dependency different copula capture different kind dependency allowing richer detailed description dependency traditional summary statistic correlation coefficient explore variety poisson copula model joint neural response distribution derive efficient maximum likelihood procedure estimating apply model neuronal data collected macaque motor cortex quantify improvement coding accuracy afforded incorporating dependency structure pair neuron', 'consider problem binary classification classifier may abstain instead classifying observation bayes decision rule setup known chow rule defined two threshold posterior probability simple desideratum namely consistency sparsity classifier derive double hinge loss function focus estimating conditional probability vicinity threshold point optimal decision rule show suitable kernel machine approach universally consistent cast problem minimizing double hinge loss quadratic program akin standard svm optimization problem propose active set method solve efficiently finally provide preliminary experimental result illustrating interest constructive approach devising loss function', 'developed localized sliced inverse regression supervised dimension reduction advantage preventing degeneracy increasing estimation accuracy automatic subclass discovery classification problem semisupervised version proposed use unlabeled data utility illustrated simulated well real data set', 'consider robust least square regression feature wise disturbance show formulation lead tractable convex optimization problem exhibit particular uncertainty set robust problem equivalent ell regularized regression lasso provides interpretation lasso robust optimization perspective generalize robust formulation consider general uncertainty set lead tractable convex optimization problem therefore provide new methodology designing regression algorithm generalize known formulation advantage robustness disturbance physical property exploited addition obtaining new formulation use directly show sparsity property lasso well prove general consistency result robust regression problem including lasso unified robustness perspective', 'application multi class classification document categorization often appear cost sensitive setting recent work significantly improved state art moving beyond flat classification incorporation class hierarchy cai hoffman present novel algorithm go beyond hierarchical classification estimate latent semantic space underlies class hierarchy space class represented prototype classification done simple nearest neighbor rule optimization semantic space incorporates large margin constraint ensure instance correct class prototype closer show optimization convex solved efficiently large data set experiment ohsumed medical journal data base yield state art result topic categorization', 'introduce framework actively learning visual category mixture weakly strongly labeled image example propose allow category learner strategically choose annotation receives based expected reduction uncertainty well relative cost obtaining annotation construct multiple instance discriminative classifier based initial training data remaining unlabeled weakly labeled example surveyed actively determine annotation ought requested next request current classifier incrementally updated unlike previous work approach account fact optimal use manual annotation may call combination label multiple level granularity e g full segmentation image present absent flag others result possible learn accurate category model lower total expenditure manual annotation effort', 'probabilistic topic model extension become popular model latent structure collection text document image model usually treated generative model trained using maximum likelihood estimation approach may suboptimal context overall classification problem paper describe disclda discriminative learning framework model latent dirichlet allocation lda setting dimensionality reduction supervised side information disclda class dependent linear transformation introduced topic mixture proportion parameter estimated maximizing conditional likelihood using monte carlo em using transformed topic mixture proportion new representation document obtain supervised dimensionality reduction algorithm uncovers latent structure document collection preserving predictive power task classification compare predictive power latent structure disclda unsupervised lda newsgroup ocument classification task', 'abstract missing', 'abstract missing', 'study profit maximization problem monopolistic market maker set two sided price asset market sequential decision problem hard solve state space function demonstrate belief state well approximated gaussian distribution prove key monotonicity property gaussian state update make problem tractable yielding first optimal sequential market making algorithm established model algorithm lead surprising insight optimal monopolist provide liquidity perfectly competitive market maker period extreme uncertainty monopolist willing absorb initial loss order learn new valuation rapidly extract higher profit later', 'abstract missing', 'solving complex visual learning task adopting multiple descriptor precisely characterize data feasible way improving performance representation typically high dimensional assume diverse form thus finding way transform unified space lower dimension generally facilitates underlying task object recognition clustering describe approach incorporates multiple kernel learning dimensionality reduction mkl dr proposed framework flexible simultaneously tackling data various feature representation formulation general established upon graph embedding follows dimensionality reduction technique explainable graph embedding generalized method consider data multiple feature representation', 'statistical evolutionary model provide important mechanism describing understanding escape response viral population particular therapy present new hierarchical model incorporates spatially varying mutation recombination rate nucleotide level also maintains sep arate parameter treatment control group allows u estimate treatment effect explicitly use model investigate sequence evolu tion hiv population exposed recently developed antisense gene therapy well conventional drug therapy detection biologically rele vant plausible signal therapy study demonstrates effectiveness method', 'many domain data distributed among datasets share variable recorded variable may occur one dataset several asymptotically correct informative algorithm search causal information given single dataset even missing value hidden variable however reliable procedure distributed data overlapping variable single heuristic procedure structural em paper describes asymptotically correct procedure ion provides information structure obtainable marginal independence relation using simulated real data accuracy ion compared structural em inference complete unified data', 'consider generalization stochastic bandit problem set arm x allowed generic topological space constraint mean payoff function dissimilarity function x way general lipschitz construct arm selection policy whose regret improves upon previous result large class problem particular result imply x unit hypercube euclidean space mean payoff function finite number global maximum around behavior function locally h lder known exponent expected regret bounded logarithmic factor n e rate growth regret independent dimension space moreover prove minimax optimality algorithm class mean payoff function consider', 'paper propose new incremental spike sorting model automatically eliminates refractory period violation account action potential waveform drift handle appearance disappearance neuron approach augment known time varying dirichlet process tie together sequence infinite gaussian mixture model one per action potential waveform observation interspike interval dependent likelihood prohibits refractory period violation demonstrate model showing result sorting two publicly available neural data recording partial ground truth labeling known', 'using machine learning algorithm decode intended behavior neural activity serf dual purpose first tool used allow patient interact environment brain machine interface bmi second analysis characteristic method reveal significance various feature neural activity stimulus response encoding decoding task study adapted implemented tested machine learning method called kernel auto regressive moving average karma task inferring movement neural activity primary motor cortex version algorithm used line learning setting updated feedback last inferred sequence become available first used track real hand movement executed monkey standard motor control task applied closed loop bmi setting infer intended movement arm restrained allowing monkey perform task using bmi alone karma recurrent method learns nonlinear model output dynamic us similarity function termed kernel compare input kernel structured incorporate domain knowledge method compare karma various state art method evaluating tracking performance present result karma based bmi experiment', 'object matching fundamental operation data analysis typically requires definition similarity measure class object matched instead develop approach able perform matching requiring similarity measure within class achieved maximizing dependency matched pair observation mean hilbert schmidt independence criterion problem cast one maximizing quadratic assignment problem special structure present simple algorithm finding locally optimal solution', 'synchronous brain activity measured via meg eeg interpreted arising collection possibly large current dipole source located throughout cortex estimating number location orientation source remains challenging task one significantly compounded effect source correlation presence interference spontaneous brain activity sensor noise artifact paper derives empirical bayesian method addressing issue principled fashion resulting algorithm guarantee descent cost function uniquely designed handle unknown orientation arbitrary correlation robust interference suppression also easily incorporated restricted setting proposed method shown theoretically zero bias estimating location orientation multi component dipole even presence correlation unlike variety existing bayesian localization method common signal processing technique beamforming sloreta empirical result simulated real data set verify efficacy approach', 'abstract missing', 'cell assembly exhibiting episode recurrent coherent activity observed several brain region including striatum hippocampus ca address question coherent dynamically switching assembly appear large network biologically realistic spiking neuron interacting deterministically show numerical simulation large asymmetric inhibitory network fixed external excitatory drive network intermediate sparse connectivity individual cell vicinity bifurcation quiescent firing state network inhibition varies slowly spiking timescale cell form assembly whose member show strong positive correlation member different assembly show strong negative correlation show cell assembly switch firing quiescent state time duration consistent power law result good qualitative agreement experimental study deterministic dynamical behaviour related winner le competition shown small closed loop inhibitory network heteroclinic cycle connecting saddle point', 'work consider problem learning positive semidefinite matrix critical issue preserve positive semidefiniteness course learning algorithm mainly inspired lpboost general greedy convex optimization framework zhang demonstrate essence algorithm termed psdboost positive semidefinite boosting focusing different application machine learning proposed psdboost algorithm extends traditional boosting algorithm parameter positive semidefinite matrix trace one instead classifier psdboost based observation trace one positive semidefinitematrix decomposed linear convex combination trace one rank one matrix serve base learner psdboost numerical experiment presented', 'analyse matching pursuit kernel principal component analysis proving sparse subspace produce sample compression scheme show bound tighter kpca bound shawe taylor et al swck highly predictive size subspace needed capture variance data analyse second matching pursuit algorithm called kernel matching pursuit kmp correspond sample compression scheme however give novel bound view choice subspace kmp algorithm compression scheme hence provide vc bound upper bound future loss finally describe bound applied matching pursuit related algorithm', 'develop series correction expectation propagation ep one popular method approximate probabilistic inference correction lead improvement inference approximation serve sanity check indicating ep yield unrealiable result', 'stochastic approximation method behind solution many important actively studied problem machine learning despite far reaching application almost work applying stochastic approximation learning problem constraint reason hypothesize robust widely applicable stochastic approximation method exists handling problem propose interior point method natural solution establish stability stochastic interior point approximation method analytically empirically demonstrate utility deriving line learning algorithm also performs feature selection via l regularization', 'use graphical model structure learning explore people learn policy sequential decision making task study sequential decision making human frequently find suboptimal performance relative ideal actor know graph model generates reward environment argue learning problem human face also involves learning graph structure reward generation environment formulate structure learning problem using mixture reward model solve optimal action selection problem using bayesian reinforcement learning show structure learning one two armed bandit problem produce many qualitative behavior deemed suboptimal previous study argument supported result experiment demonstrate human rapidly learn exploit new reward structure', 'propose new family model algorithm high dimensional nonparametric learning joint sparsity constraint approach based regularization method enforces common sparsity pattern across different function component nonparametric additive model algorithm employ coordinate descent approach based functional soft thresholding operator framework yield several new model including multi task sparse additive model multi response sparse additive model sparse additive multi category logistic regression method illustrated experiment synthetic data gene microarray data', 'develop new technique time series classification based hierarchical bayesian generative model called mixed effect model fisher kernel derived key advantage new formulation one compute fisher information matrix despite varying sequence length sampling time therefore avoid ad hoc replacement fisher information matrix identity matrix commonly used literature destroys geometrical grounding kernel construction contrast construction retains proper geometric structure resulting kernel properly invariant change coordinate model parameter space experiment detecting cognitive decline show classifier based proposed kernel perform based generative model feature extraction routine', 'consider problem obtaining approximate maximum posteriori estimate discrete random field characterized pairwise potential form truncated convex model problem propose improved st mincut based move making algorithm unlike previous move making approach either provide loose bound bound quality solution term corresponding gibbs energy algorithm achieves guarantee standard linear programming lp relaxation compared previous approach based lp relaxation e g interior point algorithm tree reweighted message passing trw method faster us efficient st mincut algorithm design furthermore directly provides u primal solution unlike trw related method attempt solve dual lp demonstrate effectiveness proposed approach synthetic standard real data problem analysis also open interesting question regarding relationship move making algorithm alpha expansion algorithm presented paper randomized rounding scheme used convex relaxation believe exploration direction would help design efficient algorithm complex relaxation', 'present new reinforcement learning model role hippocampus classical conditioning focusing difference trace delay conditioning model stimulus represented unindividuated whole series temporal element varying delay two stimulus representation interact producing different pattern learning trace delay conditioning model proposes hippocampal lesion eliminate long latency temporal element preserve short latency temporal element trace conditioning contiguity stimulus reward long latency temporal element vital learning adaptively timed response delay conditioning contrast continued presence stimulus support conditioned responding short latency element suppress responding early stimulus accord empirical data simulated hippocampal damage impairs trace conditioning delay conditioning medium length interval longer interval learning impaired procedure shorter interval neither addition model make novel prediction response topography extended stimulus post training lesion result demonstrate temporal contiguity delay conditioning change timing problem faced animal rendering easier le susceptible disruption hippocampal lesion', 'abstract missing', 'extensive labeled data image annotation system learn assign class label image region difficult obtain explore hybrid model framework utilizing partially labeled data integrates generative topic model image appearance discriminative label prediction propose three alternative formulation imposing spatial smoothness prior image label test new model baseline approach two real image datasets demonstrate effectiveness incorporating latent structure', 'almost successful machine learning algorithm cognitive model require powerful representation capturing feature relevant particular problem draw recent work nonparametric bayesian statistic define rational model human feature learning form featural representation raw sensory data without pre specifying number feature comparing human perceptual system rational model use distributional category information infer feature representation seek identify force govern process people separate combine sensory primitive form feature', 'describe novel stochastic process used construct multidimensional generalization stick breaking process related classic stick breaking process described sethuraman one dimension describe process applied relational data modeling using de finetti representation infinitely partially exchangeable array', 'recent work long servedio l short presented martingale boosting algorithm work constructing branching program weak classifier simple analysis based elementary property random walk l short showed martingale booster tolerate random classification noise run noise tolerant weak learner however drawback algorithm adaptive e cannot effectively take advantage variation quality weak classifier receives paper present variant original martingale boosting algorithm prove adaptive adaptiveness achieved modifying original algorithm random walk arise analysis different step size depending quality weak learner stage new algorithm inherits desirable property original l short algorithm random classification noise tolerance several advantage besides adaptiveness requires polynomially fewer call weak learner original algorithm used confidence rated weak hypothesis output real value rather boolean prediction', 'apply robust bayesian decision theory improve generative discriminative learner bias class proportion labeled training data true class proportion unknown generative case derive entropy based weighting maximizes expected log likelihood worst case true class proportion discriminative case derive multinomial logistic model minimizes worst case conditional log loss apply theory modeling specie geographic distribution presence data extreme case label bias since absence data benchmark dataset find entropy based weighting offer improvement constant estimate class proportion consistently reducing log loss unbiased test data', 'stochastic relational model provide rich family choice learning predicting dyadic data two set entity generalizes matrix factorization supervised learning problem utilizes attribute object hierarchical bayesian framework previously empirical bayesian inference applied however scalable size either object set becomes ten thousand paper introduce markov chain monte carlo mcmc algorithm scale model large scale dyadic data superior scalability predictive accuracy demonstrated collaborative filtering problem involves ten thousand user half million item', 'introduce first temporal difference learning algorithm stable linear function approximation policy training finite markov decision process target policy exciting behavior policy whose complexity scale linearly number parameter consider policy evaluation setting data need come policy experience gradient temporal difference gtd algorithm estimate expected update vector td algorithm performs stochastic gradient descent l norm analysis prof expected update direction gradient assuring convergence usual stochastic approximation condition least square solution found lstd without quadratic computational complexity gtd online incremental involve multiplying product likelihood ratio importance sampling method', 'abstract missing', 'introduce new family positive definite kernel function mimic computation large multilayer neural net kernel function used shallow architecture support vector machine svms deep kernel based architecture call multilayer kernel machine mkms evaluate svms mkms kernel function problem designed illustrate advantage deep architecture several problem obtain better result previous leading benchmark svms gaussian kernel well deep belief net', 'many advance already made topic hierarchical classi cation learning take step back examine hierarchical classi ca tion problem formally de ned pay particular attention fact many arbitrary decision go design label taxonomy provided training data taxonomy often unbalanced correct problem using data distribution calibrate hierarchical classi cation loss function distribution based correction must done care avoid introducing unmanagable statstical dependency learning problem lead u beaten path binomial type estimation uncharted water geometric type estimation present new calibrated de nition statistical risk hierarchical classi cation unbiased geometric estimator risk new algorithmic reduction hierarchical classi cation cost sensitive classi cation', 'abstract missing', 'dependent dirichlet process dp dependent set random measure marginally dirichlet process distributed used bayesian nonparametric model usual exchangebility assumption hold propose simple general framework construct dependent dp marginalizing normalizing single gamma process extended space result set dp located point space neighboring dp dependent describe markov chain monte carlo inference involving typical gibbs sampling three different metropolis hastings proposal speed convergence report empirical study convergence speed synthetic dataset demonstrate application model topic modeling time', 'relative merit different population coding scheme mostly analyzed framework stimulus reconstruction using fisher information consider case stimulus discrimination two alternative forced choice paradigm compute neurometric function term minimal discrimination error jensen shannon information study neural population code first explore relationship minimum discrimination error jensen shannon information fisher information show discrimination framework informative coding accuracy fisher information defines error pair possible stimulus particular includes fisher information special case second use framework study population code angular variable specifically ass impact different noise correlation structure coding accuracy long versus short decoding time window long time window use common gaussian noise approximation address case short time window analyze ising model identical noise correlation structure way provide new rigorous framework assessing functional consequence noise correlation structure representational accuracy neural population code particular applicable short time population coding', 'propose new methodology detect anomaly discrete time process taking value set method based inference functionals whose evaluation successive state visited process low autocorrelations deviation behavior used flag anomaly candidate functionals estimated subset reproducing kernel hilbert space associated set process take value provide experimental result show technique compare favorably algorithm', 'advent internet possible collect hundred million image image come varying degree label information clean label manually obtained small fraction noisy label may extracted automatically surrounding text image label semi supervised learning principled framework combining different label source however scale polynomially number image making impractical use gigantic collection hundred million image thousand class paper show utilize recent result machine learning obtain highly efficient approximation semi supervised learning linear number image specifically use convergence eigenvectors normalized graph laplacian eigenfunctions weighted laplace beltrami operator combine label sharing framework obtained wordnet propagate label information class lacking manual annotation algorithm enables u apply semi supervised learning database million image thousand class', 'extensive game often used model interaction multiple agent within environment much recent work focused increasing size extensive game feasibly solved despite improvement many interesting game still large technique common approach computing strategy large game first employ abstraction technique reduce original game abstract game manageable size abstract game solved resulting strategy used original game top program recent aaai computer poker competition use approach trend competition strategy found larger abstract game tend beat strategy found smaller abstract game larger abstract game expressive strategy space therefore contain better strategy paper present new method computing strategy large game method allows u compute expressive strategy without increasing size abstract game required solve demonstrate power approach experimentally small large game also providing theoretical justification resulting improvement', 'replica method non rigorous widely used technique statistical physic used asymptotic analysis many large random nonlinear problem paper applies replica method non gaussian map estimation shown large random linear measurement gaussian noise asymptotic behavior map estimate n dimensional vector decouples n scalar map estimator result counterpart guo verdus replica analysis mmse estimation replica map analysis readily applied many estimator used compressed sensing including basis pursuit lasso linear estimation thresholding zero norm estimation case lasso estimation scalar estimator reduces soft thresholding operator zero norm estimation reduces hard threshold among benefit replica method provides computationally tractable method exactly computing various performance metric including mse sparsity recovery', 'study encoding decoding mechanism accounting relative spike timing signal propagating peripheral nerve fiber second order somatosensory neuron cuneate nucleus cn cn modeled population spiking neuron receiving input spatiotemporal response real mechanoreceptors obtained via microneurography recording human efficiency haptic discrimination process quantified novel definition entropy take full account metrical property spike train space measure prof suitable decoding scheme generalizing classical shannon entropy spike based neural code permit assessment neurotransmission presence large output space e hundred spike train m temporal precision shown cn population code performs complete discrimination distinct stimulus already within m first afferent spike whereas partial discrimination maximum information transmission possible rapidly m study suggests cn may constitute mere synaptic relay along somatosensory pathway rather may convey optimal contextual account term fast reliable information transfer peripheral tactile input downstream structure central nervous system', 'present sequence unsupervised nonparametric bayesian model clustering complex linguistic object approach consider potentially infinite number feature categorical outcome evaluate model task within cross document event coreference two corpus model investigated show significant improvement compared existing baseline task', 'indian buffet process ibp exchangeable distribution binary matrix used bayesian nonparametric featural model paper propose three parameter generalization ibp exhibiting power law behavior achieve generalizing beta process de finetti measure ibp emph stable beta process deriving ibp corresponding find interesting relationship stable beta process pitman yor process another stochastic process used bayesian nonparametric model interesting power law property show power law ibp good model word occurrence document improved performance normal ibp', 'paper tackle problem selecting among several linear estimator non parametric regression includes model selection linear regression choice regularization parameter kernel ridge regression spline smoothing choice kernel multiple kernel learning propose new algorithm first estimate consistently variance noise based upon concept minimal penalty previously introduced context model selection plugging variance estimate mallow c l penalty proved lead algorithm satisfying oracle inequality simulation experiment kernel ridge regression multiple kernel learning show proposed algorithm often improves significantly existing calibration procedure fold cross validation generalized cross validation', 'abstract missing', 'interesting real world datasets often exhibit nonlinear noisy continuous valued state unexplorable poorly described first principle partially observable partial observability overcome constraint suggest use model based reinforcement learning experiment manifold embeddings reconstructed observable state space line model based reinforcement learning approach control demonstrate embedding system change result learning best performing embeddings well represent dynamic uncontrolled adaptively controlled system apply approach simulation learn neurostimulation policy efficient treating epilepsy conventional policy demonstrate learned policy completely suppressing seizure real world neurostimulation experiment actual animal brain slice', 'human brain described containing number functional region given task region well connection play key role information processing brain however existing multi voxel pattern analysis approach either treat multiple functional region one large uniform region several independent region ignoring connection region paper propose model connection hidden conditional random field hcrf framework classifier one region interest roi make prediction based voxels also classifier prediction roi connects furthermore propose structural learning method hcrf framework automatically uncover connection roi experiment fmri data acquired human subject viewing image natural scene show model improve top level classifier combining information roi roi level prediction accuracy well uncover meaningful connection roi', 'introduce new family distribution called l p em nested symmetric distribution whose density access data exclusively hierarchical cascade l p norm class generalizes family spherically l p spherically symmetric distribution recently successfully used natural image modeling similar distribution allows nonlinear mechanism reduce dependency variable suitable choice parameter norm family also includes independent subspace analysis isa model proposed mean deriving filter mimic complex cell found mammalian primary visual cortex l p nested distribution easy estimate allow u explore variety model isa l p spherically symmetric model main finding without preprocessing step contrast gain control independent subspace isa fact dependent individual filter coefficient within subspace contrast gain control isa find one subspace filter response almost independent anyway', 'develop bayesian sequential model category learning sequential model update two category parameter mean variance time define conjugate temporal prior enable closed form solution obtained model easily extended supervised unsupervised learning involving multiple category model spacing effect introduce generic prior temporal updating stage capture learning preference namely le change repetition change variation finally show approach generalized efficiently performmodel selection decide whether observation one multiple category', 'modern machine learning based approach computer vision require large database labeled image contemporary vision system already require order million image training e g omron face detector collection large database becoming bottleneck new internet based service allow labelers around world easily hired managed provide promising solution however using service label large database brings new theoretical practical challenge labelers may wide ranging level expertise unknown priori case may adversarial image may vary level difficulty multiple label image must combined provide estimate actual label image probabilistic approach provide principled way approach problem paper present probabilistic model use simultaneously infer label image expertise labeler difficulty image simulated real data demonstrate model outperforms commonly used majority vote heuristic inferring image label robust adversarial noisy labelers', 'imaging technique optical imaging intrinsic signal photon calcium imaging voltage sensitive dye imaging used measure functional organization visual cortex across different spatial scale present bayesian method based gaussian process extracting topographic map functional imaging data particular focus estimation orientation preference map opms intrinsic signal imaging data model underlying map bivariate gaussian process prior covariance function reflects known property opms noise covariance adjusted data posterior mean interpreted optimally smoothed estimate map used model based interpolation map sparse measurement sampling posterior distribution get error bar statistical property preferred orientation pinwheel location count finally use explicit probabilistic model facilitates interpretation parameter provides basis decoding study demonstrate model simulated data intrinsic signaling data ferret visual cortex', 'concave convex procedure cccp majorization minimization algorithm solves c difference convex function program sequence convex program machine learning cccp extensively used many learning algorithm like sparse support vector machine svms transductive svms sparse principal component analysis etc though widely used many application convergence behavior cccp gotten lot specific attention yuille rangarajan analyzed convergence original paper however believe analysis complete although convergence cccp derived convergence c algorithm dca proof specialized technical actually required specific case cccp paper follow different reasoning show zangwill global convergence theory iterative algorithm provides natural framework prove convergence cccp allowing elegant simple proof underline zangwill theory powerful general framework deal convergence issue iterative algorithm also used prove convergence algorithm like expectation maximization generalized alternating minimization etc paper provide rigorous analysis convergence cccp addressing question cccp find local minimum stationary point c program consideration ii sequence generated cccp converge also present open problem issue local convergence cccp', 'use context critical scene understanding computer vision recognition object driven local appearance object relationship element scene context current approach rely modeling relationship object category source context paper seek move beyond category provide richer appearance based model context present exemplar based model object relationship visual memex encodes local appearance spatial context object instance evaluate model torralbas proposed context challenge baseline category based system experiment suggest moving beyond category context modeling appears quite beneficial may critical missing ingredient scene understanding system', 'paper considers sensitivity analysis hidden markov model continuous state observation space propose infinitesimal perturbation analysis ipa filtering distribution respect parameter model describe methodology using algorithm estimate filtering density sequential monte carlo method design algorithm estimate gradient resulting ipa estimator proven asymptotically unbiased consistent computational complexity linear number particle consider application analysis problem identifying unknown parameter model given sequence observation derive ipa estimator gradient log likelihood may used gradient method purpose likelihood maximization illustrate method several numerical experiment', 'motivated recent development manifold valued regression propose family nonparametric kernel smoothing estimator metric space valued output including robust median type estimator classical frechet mean depending choice output space chosen metric estimator reduces partially well known procedure multi class classification multivariate regression euclidean space regression manifold valued output even case structured output learning paper focus case regression manifold valued input output show pointwise bayes consistency estimator family case manifold valued output illustrate robustness property estimator experiment', 'abstract missing', 'consider problem zero shot learning goal learn classifier f x rightarrow must predict novel value omitted training set achieve define notion semantic output code classifier soc utilizes knowledge base semantic property extrapolate novel class provide formalism type classifier study theoretical property pac framework showing condition classifier accurately predict novel class case study build soc classifier neural decoding task show often predict word people thinking functional magnetic resonance image fmri neural activity even without training example word', 'recent advance neuroimaging technique provide great potential effective diagnosis alzheimer disease ad common form dementia previous study shown ad closely related alternation functional brain network e functional connectivity among different brain region paper consider problem learning functional brain connectivity neuroimaging hold great promise identifying image based marker used distinguish normal control nc patient mild cognitive impairment mci patient ad specifically study sparse inverse covariance estimation sice also known exploratory gaussian graphical model brain connectivity modeling particular apply sice learn analyze functional brain connectivity pattern different subject group based key property sice called monotone property established paper experimental result neuroimaging pet data ad mci nc subject reveal several interesting connectivity pattern consistent literature finding also new pattern help knowledge discovery ad', 'study behavior popular laplacian regularization method semi supervised learning regime fixed number labeled point large number unlabeled point show r geq method actually well posed number unlabeled point increase solution degenerate noninformative function also contrast method laplacian eigenvector method discus smoothness assumption associated alternate method', 'clear distinction induction training time diagnosis time active information acquisition active learning induction focus acquiring data promise provide best classification model goal diagnosis time focus completely next feature observe test case hand order make better prediction case introduce model inferential method break distinction method used extend case library budget fundamentally provide framework guiding agent collect data scarce resource focused diagnostic challenge extension active learning lead new class policy real time diagnosis recommended information gathering sequence include action simultaneously seek new data case hand case training set', 'discriminatively trained undirected graphical model wide empirical success increasing interest toolkits ease application complex relational data power relational model repeated structure tied parameter issue define structure powerful flexible way rather using declarative language sql first order logic advocate using imperative language express various aspect model structure inference learning combining traditional declarative statistical semantics factor graph imperative definition construction operation allow user mix declarative procedural domain knowledge also gain significant efficiency implemented imperatively defined factor graph system call factorie software library object oriented strongly typed functional language experimental comparison markov logic network joint segmentation coreference find approach time faster reducing error achieving new state art', 'non parametric bayesian model proposed processing multiple image analysis employ image feature present word associated accompanying annotation model cluster image class image segmented set object also allowing opportunity assign word object localized labeling object assumed represented heterogeneous mix component realized via mixture model linking image feature object type number image class number object type characteristic object feature mixture model inferred non parametrically constitute spatially contiguous object new logistic stick breaking process developed inference performed efficiently via variational bayesian analysis example result presented two image database', 'control neuroprosthetic device activity motor cortex neuron benefit learning effect function neuron adapted control task recently shown tuning property neuron monkey motor cortex adapted selectively order compensate erroneous interpretation activity particular shown tuning curve neuron whose preferred direction misinterpreted changed neuron article show experimentally observed self tuning property system explained basis simple learning rule learning rule utilizes neuronal noise exploration performs hebbian weight update modulated global reward signal contrast previously proposed reward modulated hebbian learning rule rule require extraneous knowledge noise signal learning rule able optimize performance model system within biologically realistic period time high noise level neuronal noise fitted experimental data model produce learning effect similar found monkey experiment', 'propose dirichlet bernoulli alignment dba generative model corpus pattern e g document contains set instance e g paragraph document belongs multiple class casting predefined class latent dirichlet variable e instance level label modeling multi label pattern bernoulli variable conditioned weighted empirical average topic assignment dba automatically aligns latent topic discovered data human defined class dba useful pattern classification instance disambiguation tested text classification named entity disambiguation web search query respectively', 'learning appropriate distance metric critical problem classification work propose boosting based technique termed boostmetric learning mahalanobis distance metric one primary difficulty learning metric ensure mahalanobis matrix remains positive semidefinite semidefinite programming sometimes used enforce constraint scale well boostmetric instead based key observation positive semidefinite matrix decomposed linear positive combination trace one rank one matrix boostmetric thus us rank one positive semidefinite matrix weak learner within efficient scalable boosting based learning process resulting method easy implement require tuning accommodate various type constraint experiment various datasets show proposed algorithm compare favorably state art method term classification accuracy running time', 'many category better described providing relational information listing characteristic feature present hierarchical generative model help explain relational category learned used model learns abstract schema specify relational similarity shared member category emphasis abstraction departs previous theoretical proposal focus instead comparison concrete instance first experiment suggests abstraction based account address task previously used support comparison based approach second experiment focus one shot schema learning problem raise challenge comparison based approach handled naturally abstraction based account', 'abstract missing', 'schizophrenia complex psychiatric disorder eluded characterization term local abnormality brain activity hypothesized affect collective emergent working brain propose novel data driven approach capture emergent feature using functional brain network eguiluzet al extracted fmri data demonstrate advantage traditional region interest roi local task specific linear activation analyzes result suggest schizophrenia indeed associated disruption global emergent brain property related functioning network cannot explained alteration local activation pattern moreover exploitation interaction sparse markov random field classifier show clear gain linear method gaussian naive bayes svm allowing reach accuracy baseline random guess quite remarkable given based single fmri experiment using simple auditory task', 'recent introduction indefinite svm lu daspremont effectively demonstrated svm classification non positive semi definite kernel indefinite kernel paper study property objective function introduced particular show objective function continuously differentiable gradient explicitly computed indeed show gradient lipschitz continuous main idea behind analysis objective function smoothed penalty term saddle min max representation measuring distance indefinite kernel matrix proxy positive semi definite one elementary result greatly facilitates application gradient based algorithm based analysis develop nesterovs smooth optimization approach indefinite svm optimal convergence rate smooth problem experiment various benchmark datasets validate analysis demonstrate efficiency proposed algorithm', 'nested chinese restaurant process ncrp powerful nonparametric bayesian model learning tree based hierarchy data since posterior distribution intractable current inference method relied mcmc sampling paper develop alternative inference technique based variational method employ variational method derive tree based stick breaking construction ncrp mixture model novel variational algorithm efficiently explores posterior large set combinatorial structure demonstrate use approach text hand written digit modeling show adapt ncrp continuous data well', 'many domain human appear combine perceptual cue near optimal probabilistic fashion two noisy piece information tend combined linearly weight proportional precision cue present case structural information play important role presence background cue give rise possibility occlusion place soft constraint location target effect propelling forward present ideal observer model depth estimation situation structural ordinal information important fit model human data stereo matching task test whether subject truly using ordinal cue probabilistic manner vary uncertainty task find model accurately predicts shift subject behavior result indicate nervous system estimate depth ordering probabilistic fashion estimate structure visual scene depth perception', 'consider reconstruction sparse signal multiple measurement vector mmv model signal represented matrix consists set jointly sparse vector mmv extension single measurement vector smv model employed standard compressive sensing c recent theoretical study focus convex relaxation mmv problem based norm minimization extension well known norm minimization employed smv however resulting convex optimization problem mmv significantly much difficult solve one smv existing algorithm reformulate second order cone programming socp semidefinite programming sdp computationally expensive solve problem moderate size paper propose new dual reformulation convex optimization problem mmv develop efficient algorithm based prox method interestingly theoretical analysis reveals close connection proposed reformulation multiple kernel learning simulation study demonstrate scalability proposed algorithm', 'growing body experimental evidence suggest brain capable approximating optimal bayesian inference face noisy input stimulus despite progress neural underpinnings computation still poorly understood paper focus problem bayesian filtering stochastic time series particular introduce novel neural network derived line attractor architecture whose dynamic map directly onto kalman filter limit prediction error small prediction error large show network responds robustly change point way qualitatively compatible optimal bayesian model model suggests way probability distribution encoded brain make number testable experimental prediction', 'many transductive inference algorithm assume distribution training test estimate related e g providing large margin separation set use idea design transduction algorithm used without modification classification regression structured estimation heart exploit fact good learner distribution output training test set match classical two sample problem solved efficiently general form using distance measure hilbert space turn number existing heuristic viewed special case approach', 'fast retrieval method increasingly critical many large scale analysis task several recent method attempt learn hash function fast accurate nearest neighbor search paper develop algorithm learning hash function based explicitly minimizing reconstruction error original distance hamming distance corresponding binary embeddings develop scalable coordinate descent algorithm proposed hashing objective able efficiently learn hash function variety setting unlike existing method semantic hashing spectral hashing method easily kernelized require restrictive assumption underlying distribution data present result several domain demonstrate method outperforms existing state art technique', 'paper present algorithm separating mixed sound monophonic recording approach make use training data allows u learn representation type sound compose mixture contrast popular method attempt extract com pact generalizable model sound training data employ training data representation source mixture show mixture known sound described sparse com binations training data produce signi cantly better separation result compared similar system based compact statistical model', 'nonparametric bayesian model provide framework flexible probabilistic modelling complex datasets unfortunately bayesian inference method often require high dimensional average slow compute especially potentially unbounded representation associated nonparametric model address challenge scaling nonparametric bayesian inference increasingly large datasets found real world application focusing case parallelising inference indian buffet process ibp approach divide large data set multiple processor processor use message passing compute likelihood asynchronous distributed fashion propagate statistic global bayesian posterior novel mcmc sampler first parallel inference scheme ibp based model scaling datasets order magnitude larger previously possible', 'abstract missing', 'extend dyna planning architecture policy evaluation control two significant aspect first introduce multi step dyna planning project simulated state feature many step future multi step dyna based multi step model call em lambda model lambda model interpolates one step model infinite step model learned efficiently online second use dyna control dynamic multi step model able predict result sequence greedy action track optimal policy long run experimental result show dyna using multi step model evaluates policy faster using single step model dyna control algorithm using dynamic tracking model much faster model free algorithm multi step dyna control algorithm enable policy value function converge much faster optimum single step dyna algorithm', 'quest make brain computer interfacing bci usable dry electrode emerged get rid initial minute required placing electrode cap another time consuming step required individualized adaptation bci user involves another minute calibration assessing subject brain signature paper aim also remove calibration proceedure bci setup time mean machine learning particular harvest large database eeg bci motor imagination recording subject constructing library subject specific spatio temporal filter derive subject independent bci classifier offline result indicate bci na user could start real time bci use prior calibration moderate performance loss', 'many model computation recurrent network neuron assume network state move initial state fixed point attractor limit cycle represents output computation however experimental data show response sensory stimulus network state move initial state trajectory network state eventually return initial state without reaching attractor limit cycle type network response salient information external stimulus encoded characteristic trajectory continuously varying network state raise question neural system could compute code arrive example temporally stable classification external stimulus show known unsupervised learning algorithm slow feature analysis sfa could important ingredient extracting stable information network trajectory fact sensory stimulus often followed another stimulus class stimulus another class sfa approach classification capability fisher linear discriminant fld powerful algorithm supervised learning apply principle simulated cortical microcircuit show enables readout neuron learn discrimination spoken digit detection repeating firing pattern within stream spike train firing statistic without requiring supervision learning', 'canonical correlation analysis cca useful technique modeling dependency two set variable building upon recently suggested probabilistic interpretation cca propose nonparametric fully bayesian framework automatically select number correlation component effectively capture sparsity underlying projection addition given partially labeled data algorithm also used semi supervised dimensionality reduction technique applied learn useful predictive feature context learning set related task experimental result demonstrate efficacy proposed approach cca stand alone problem applied multi label prediction', 'recent year deep learning approach gained significant interest way building hierarchical representation unlabeled data however knowledge deep learning approach extensively studied auditory data paper apply convolutional deep belief network audio data empirically evaluate various audio classification task case speech data show learned feature correspond phone phoneme addition feature representation trained unlabeled audio data show good performance multiple audio classification task hope paper inspire research deep learning approach applied wide range audio recognition task', 'learning linear combination multiple kernel appealing strategy right choice feature unknown previous approach multiple kernel learning mkl promote sparse kernel combination hence support interpretability unfortunately l norm mkl hardly observed outperform trivial baseline practical application allow robust kernel mixture generalize mkl arbitrary lp norm devise new insight connection several existing mkl formulation develop two efficient interleaved optimization strategy arbitrary p empirically demonstrate interleaved optimization strategy much faster compared traditionally used wrapper approach finally apply lp norm mkl real world problem computational biology showing non sparse mkl achieves accuracy go beyond state art', 'prove strong noise tolerance property potential based boosting algorithm similar madaboost domingo watanabe smoothboost servedio analysis agnostic framework kearns schapire sellie giving polynomial time guarantee presence arbitrary noise remarkable feature algorithm implemented without reweighting example randomly relabeling instead boosting theorem give easy corollary alternative derivation two recent non trivial result computational learning theory agnostically learning decision tree gopalan et al agnostically learning halfspaces kalai et al experiment suggest algorithm performs similarly madaboost', 'propose new approach problem robust estimation multiview geometry inspired recent advance sparse recovery problem statistic estimator defined bayesian maximum posteriori multivariate laplace prior vector describing outlier lead estimator fidelity data measured l infty norm regularization done l norm proposed procedure fairly fast since outlier removal done solving one linear program lp important difference compared existing algorithm estimator necessary specify neither number proportion outlier theoretical result well numerical example reported work confirm efficiency proposed approach', 'learning distance function side information play key role many machine learning data mining application conventional approach often assume mahalanobis distance function approach limited two aspect computationally expensive even infeasible high dimensional data size metric square dimensionality ii assume fixed metric entire input space therefore unable handle heterogeneous data paper propose novel scheme learns nonlinear bregman distance function side information using non parametric approach similar support vector machine proposed scheme avoids assumption fixed metric local distance metric implicitly derived hessian matrix convex function used generate bregman distance function present efficient learning algorithm proposed scheme distance function learning extensive experiment semi supervised clustering show proposed technique outperforms state art approach distance function learning ii computationally efficient high dimensional data', 'paper address problem provably correct feature selection arbitrary domain optimal solution problem markov boundary minimal set feature make probability distribution target variable conditionally invariant state feature domain numerous algorithm problem proposed theoretical correctness practical behavior arbitrary probability distribution unclear address introducing markov boundary theorem precisely characterizes property ideal markov boundary use develop algorithm learn general boundary capture complex interaction appear value multiple feature considered together introduce two algorithm exact provably correct one well practical randomized anytime version show perform well artificial well benchmark real world data set throughout paper make minimal assumption consist general set axiom hold every probability distribution give algorithm universal applicability', 'abstract missing', 'paper proposes fast scalable alternating optimization technique detect region interest roi cluttered web image without label proposed approach discovers highly probable region object instance iteratively repeating following two function choose exemplar set e small number high ranked reference roi across dataset refine roi image respect exemplar set two subproblems formulated ranking two different similarity network roi hypothesis link analysis experiment pascal dataset show unsupervised localization performance better one state art technique comparable supervised method also test scalability approach five object flickr dataset consisting image', 'finding maximally sparse representation overcomplete feature dictionary frequently involves minimizing cost function composed likelihood data fit term prior penalty function favor sparsity typically prior factorial examine non factorial alternative number desirable property relevant sparse estimation easily implemented using efficient globally convergent reweighted ell minimization procedure first method consideration arises sparse bayesian learning sbl framework although based highly non convex underlying cost function context canonical sparse estimation problem prove uniform superiority method lasso never worse ii dictionary sparsity profile always exist case better result challenge prevailing reliance strictly convex penalty function finding sparse solution derive new non factorial variant similar property exhibit performance improvement empirical test method well traditional factorial analog demonstrate effectiveness reweighted ell norm algorithm handling general sparse estimation problem involving classification group feature selection non negativity constraint byproduct development rigorous reformulation sparse bayesian classification e g relevance vector machine derived unlike original involves approximation step descends well defined objective function', 'since development loopy belief propagation considerable work advancing state art approximate inference distribution defined discrete random variable improvement include guarantee convergence approximation provably accurate bound result exact inference however extending method continuous valued system lagged behind several method developed use belief propagation system continuous value yet incorporated recent advance discrete variable context extend recently proposed particle based belief propagation algorithm provide general framework adapting discrete message passing algorithm perform inference continuous system resulting algorithm behave similarly purely discrete counterpart extending benefit advanced inference technique continuous domain', 'introduce skill chaining skill discovery method reinforcement learning agent continuous domain build chain skill leading end task reward demonstrate experimentally creates skill result performance benefit challenging continuous domain', 'paper study manifold regularization sliced inverse regression sir manifold regularization improves standard sir two aspect encodes local geometry sir enables sir deal transductive semi supervised learning problem prove proposed graph laplacian based regularization convergent rate root n projection direction regularized sir optimized using conjugate gradient method grassmann manifold experimental result support theory', 'propose bayesian nonparametric approach relating multiple time series via set latent dynamical behavior using beta process prior allow data driven selection size set well pattern behavior shared among time series via indian buffet process representation beta process predictive distribution develop exact markov chain monte carlo inference method particular approach us sum product algorithm efficiently compute metropolis hastings acceptance probability explores new dynamical behavior via birth death proposal validate sampling algorithm using several synthetic datasets also demonstrate promising unsupervised segmentation visual motion capture data', 'used guide decision linear regression analysis typically involves estimation regression coefficient via ordinary least square subsequent use make decision multiple response variable feature perfectly capture relationship beneficial account decision objective computing regression coefficient empirical optimization sacrifice performance feature well chosen training data insufficient propose directed regression efficient algorithm combine merit ordinary least square empirical optimization demonstrate computational study directed regression generate significant performance gain either alternative also develop theory motivates algorithm', 'dynamic bayesian network applied widely reconstruct structure regulatory process time series data standard approach based assumption homogeneous markov chain valid many real world scenario recent research effort addressing shortcoming considered undirected graph directed graph discretized data flexible model lack information sharing time series segment present article propose non stationary dynamic bayesian network continuous data parameter allowed vary segment common network structure provides essential information sharing across segment model based bayesian change point process apply variant allocation sampler nobile fearnside infer number location change point', 'paper us information theoretic technique determine minimax rate estimating nonparametric sparse additive regression model high dimensional scaling assume additive decomposition form f x ldots x p sum j h j x j component function h j lie hilbert space hilb subset ldots pdim unknown subset cardinality given numobs observation f x corrupted white gaussian noise covariate vector x x x x pdim drawn component distribution mp determine tight lower bound minimax rate estimating regression function respect squared ltp error main result show minimax rate max big frac log pdim n lowerratesq big first term reflects difficulty performing emph subset selection independent hilbert space hilb second term lowerratesq emph dimensional estimation term depending low dimension ambient dimension pdim capture difficulty estimating sum univariate function hilbert space hilb special case hilb corresponds th order sobolev space sobm function time differentiable dimensional estimation term take form lowerratesq asymp n minimax rate compared rate achieved ell penalty based approach shown certain ell based approach achieves minimax optimal rate', 'despite large amount literature upper bound complexity convex analysis surprisingly little known fundamental hardness problem extensive use convex optimization machine learning statistic make understanding critical understand fundamental computational limit learning estimation paper study complexity stochastic convex optimization oracle model computation improve upon known result obtain tight minimax complexity estimate function class also discus implication result understanding inherent complexity large scale learning estimation problem', 'abstract missing', 'address problem learning classifier observation multiple view may observed example assume existence view generating function may complete missing view approximate way situation corresponds example learning text classifier multilingual collection document available language case machine translation mt system may used translate document missing language derive generalization error bound classifier learned example multiple artificially created view result uncovers trade size training set number view quality view generating function consequence identify situation interesting use multiple view learning instead classical single view learning extension framework natural way leverage unlabeled multi view data semi supervised learning experimental result subset reuters rcv rcv collection support finding showing additional view obtained mt may significantly improve classification performance case identified trade', 'bag word document representation often used text image video processing relatively easy determine suitable word dictionary text document simple mapping raw image video dictionary term classical approach build dictionary using vector quantization large set useful visual descriptor extracted training set us nearest neighbor algorithm count number occurrence dictionary word document encoded robust approach proposed recently represent visual descriptor sparse weighted combination dictionary word favoring sparse representation level visual descriptor method however ensure image sparse representation work use mixed norm regularization achieve sparsity image level well small overall dictionary approach also used encourage using dictionary word image class providing discriminative signal construction image representation experimental result benchmark image classification dataset show compact image dictionary representation needed computational efficiency proposed approach yield better mean average precision classification', 'paper study general problem learning kernel based polynomial combination base kernel analyzes problem case regression kernel ridge regression algorithm examines corresponding learning kernel optimization problem show minimax problem reduced simpler minimization problem prof global solution problem always lie boundary give projection based gradient descent algorithm solving optimization problem shown empirically converge iteration finally report result extensive experiment algorithm using several publicly available datasets demonstrating effectiveness technique', 'many type regularization scheme employed statistical learning one motivated assumption problem domain paper present unified asymptotic analysis smooth regularizers allows u see validity assumption impact success particular regularizer addition analysis motivates algorithm optimizing regularization parameter turn analyzed within framework apply analysis several example including hybrid generative discriminative learning multi task learning', 'present new empirical risk minimization framework approximating function training sample low dimensional regression application lattice look table stored interpolated run time efficient hardware implementation rather evaluating fitted function lattice node without regard fact sample interpolated proposed lattice regression approach estimate lattice minimize interpolation error given training sample experiment show lattice regression reduce mean test error compared gaussian process regression digital color management printer application linearly interpolating look table lut standard simulation confirm lattice regression performs consistently better naive approach learning lattice particularly density training sample low', 'studying signal noise property recorded neural data critical developing efficient algorithm recover encoded information important issue exist research including variant spectrum span neural spike make difficult choose global optimal bandpass filter also multiple source produce aggregated noise deviate conventional white gaussian noise work spectrum variability spike addressed based concept adaptive bandpass filter fit spectrum individual spike proposed multiple noise source studied analytical model well empirical measurement dominant noise source identified neuron noise followed interface noise electrode suggests major effort reduce noise electronics well spent measured noise vivo experiment show family f x x pm spectrum reduced using noise shaping technique summary method adaptive bandpass filtering noise shaping together result several db signal noise ratio snr enhancement', 'adding spatial regularization kernel standard loss function formulation boosting problem develop framework spatially informed boosting regularized loss framework derive efficient boosting algorithm us additional weight prior base classifier prove proposed algorithm exhibit grouping effect encourages selection spatially local discriminative base classifier algorithm primary advantage application trained classifier used identify spatial pattern discriminative information e g voxel selection problem fmri demonstrate algorithm performance various data set', 'given n noisy sample p dimension n p show multi stage thresholding procedure accurately estimate sparse vector beta r p linear model restricted eigenvalue condition bickel ritov tsybakov thus condition model selection consistency considerably weaker achieved previous work importantly method allows significant value number non zero element true parameter beta example work case ordinary lasso would failed finally show x obeys uniform uncertainty principle true parameter sufficiently sparse gauss dantzig selector cand e tao achieves ell loss within logarithmic factor ideal mean square error one would achieve oracle would supply perfect information coordinate non zero noise level selecting sufficiently sparse model', 'consider problem learning k input data regression function function space high dimension n using projection onto random subspace lower dimension linear approximation algorithm using empirical risk minimization possibly penalized provide bound excess risk estimate computed projected subspace compressed domain term excess risk estimate built high dimensional space initial domain apply analysis ordinary least square regression show choosing sqrt k estimation error quadratic loss compressed least square regression sqrt k logarithmic factor also discus numerical complexity several algorithm initial compressed domain function n k', 'recently proposed emph additive noise model advantage previous structure learning algorithm attempting recover true data generating mechanism since assume linearity gaussianity ii recover unique dag rather equivalence class however original extension multivariate case required enumerating possible dag special distribution e g linear gaussian model invertible thus cannot used structure learning present new approach combine pc style search using recent advance kernel measure conditional dependence local search additive noise model substructure equivalence class result computationally efficient approach useful arbitrary distribution even additive noise model invertible experiment synthetic real data show method accurate previous method data nonlinear non gaussian', 'abstract missing', 'abstract missing', 'abstract missing', 'study unsupervised learning probabilistic generative model occlusion model us two type latent variable one indicates object present image ordered depth depth order determines position appearance object present specified model parameter combine form image show object parameter learnt unlabelled set image object occlude one another exact maximum likelihood learning intractable however show tractable approximation expectation maximization em found training image contain small number object average numerical experiment shown approximation recover correct set object parameter experiment novel version bar test using colored bar experiment realistic data show algorithm performs well extracting generating cause experiment based standard bar benchmark test object learning show algorithm performs well comparison recent component extraction approach model learning algorithm thus connect research occlusion research field multiple cause component extraction method', 'established second order stochastic gradient descent sgd method potentially achieve generalization performance well empirical optimum single pas e epoch training example however sgd requires computing inverse hessian matrix loss function prohibitively expensive paper present periodic step size adaptation psa approximates jacobian matrix mapping function explores linear relation jacobian hessian approximate hessian periodically achieve near optimal result experiment wide variety model task', 'paper examine generalization error regularized distance metric learning show appropriate constraint generalization error regularized distance metric learning could independent dimensionality making suitable handling high dimensional data addition present efficient online learning algorithm regularized distance metric learning empirical study data classification face recognition show proposed algorithm effective distance metric learning compared state art method ii efficient robust high dimensional data', 'principal component analysis fundamental operation computational data analysis myriad application ranging web search bioinformatics computer vision image analysis however performance applicability real scenario limited lack robustness outlying corrupted observation paper considers idealized robust principal component analysis problem recovering low rank matrix corrupted observation e error entry e arbitrarily large modeling grossly corrupted observation common visual bioinformatic data assumed sparse prove matrix efficiently exactly recovered error sign support pattern solving simple convex program result hold even rank grows nearly proportionally logarithmic factor dimensionality observation space number error e grows proportion total number entry matrix product analysis first proportional growth result related problem completing low rank matrix small fraction entry simulation real data example corroborate theoretical result suggest potential application computer vision', 'learning measure similarity pair object fundamental problem machine learning stand core classification method like kernel machine particularly useful application like searching image similar given image finding video relevant given video task user look object visually similar also semantically related given object unfortunately current approach learning similarity may scale large datasets high dimensionality especially imposing metric constraint learned similarity describe oasis method learning pairwise similarity fast scale linearly number object number non zero feature scalability achieved online learning bilinear model sparse representation using large margin criterion efficient hinge loss cost oasis accurate wide range scale standard benchmark thousand image precise state art method faster order magnitude million image collected web oasis trained within day single cpu non metric similarity learned oasis transformed metric similarity achieving higher precision similarity learned metric first place suggests approach learning metric data larger order magnitude handled', 'multitask learning addressed problem learning related task whose information shared traditional problem usually deal homogeneous task regression classification individually paper consider problem learning multiple related task task consist continuous discrete output common set input variable lie high dimensional space task related sense share set relevant input variable amount influence input different output may vary formulate problem combination linear regression logistic regression model joint sparsity l linf l l norm model parameter among several possible application approach address important open problem genetic association mapping interested discovering genetic marker influence multiple correlated trait jointly experiment demonstrate method scenario association mapping using simulated asthma data show algorithm effectively recover relevant input respect task', 'heavy tailed distribution gradient natural scene proven effective prior range problem denoising deblurring super resolution however use sparse distribution make problem non convex impractically slow solve multi megapixel image paper describe deconvolution approach several order magnitude faster existing technique use hyper laplacian prior adopt alternating minimization scheme one two phase non convex problem separable pixel per pixel sub problem may solved lookup table lut alternatively two specific value analytic solution found finding root cubic quartic polynomial respectively approach using either luts analytic formula able deconvolve megapixel image le second achieving comparable quality existing method iteratively reweighted least square irls take minute furthermore method quite general easily extended related image processing problem beyond deconvolution application demonstrated', 'learning rank become important research topic machine learning learning rank method learn ranking function minimizing loss function ranking measure ndcg map used evaluate performance learned ranking function work reveal relationship ranking measure loss function learning rank method ranking svm rankboost ranknet listmle show loss function upper bound measure based ranking error result minimization loss function lead maximization ranking measure key obtaining result model ranking sequence classification task define called essential loss weighted sum classification error individual task sequence proved essential loss upper bound measure based ranking error lower bound loss function aforementioned method proof technique also suggests way modify existing loss function make tighter bound measure based ranking error experimental result benchmark datasets show modification lead better ranking performance demonstrating correctness analysis', 'kernel learning powerful framework nonlinear data modeling using kernel trick number problem formulated semidefinite program sdps include maximum variance unfolding mvu weinberger et al nonlinear dimensionality reduction pairwise constraint propagation pcp li et al constrained clustering although theory sdps efficiently solved high computational complexity incurred numerically processing huge linear matrix inequality constraint rendered sdp approach unscalable paper show large class kernel learning problem reformulated semidefinite quadratic linear program sqlps contain simple positive semidefinite constraint second order cone constraint number linear constraint constraint much easier process numerically gain speedup previous approach least order matrix dimension experimental result also presented show superb computational efficiency approach', 'abstract missing', 'pruning massively accelerate computation feature expectation large model however single pruning mask introduce bias present novel approach employ randomized sequence pruning mask formally apply auxiliary variable mcmc sampling generate sequence mask thereby gaining theoretical guarantee convergence mask generally able skip large portion underlying dynamic program approach particularly compelling high degree algorithm empirically demonstrate method bilingual parsing showing decreasing bias mask incorporated outperforming fixed tic tac toe pruning', 'many perceptual cognitive phenomenon well described term bayesian inference necessary computation intractable scale real world task remains unclear human mind approximates bayesian inference algorithmically explore proposal task human use form markov chain monte carlo approximate posterior distribution hidden variable case study show several phenomenon perceptual multistability explained mcmc inference simple graphical model low level vision', 'show sequentially optimize magnetic resonance imaging measurement design stack neighbouring image slice performing convex variational inference large scale non gaussian linear dynamical system tracking dominating direction posterior covariance without imposing factorization constraint approach scaled high resolution image reduction numerical mathematics primitive parallelization several level first study design found improve significantly others chosen independently slice drawn random', 'sequential decision making multiple agent imperfect information commonly modeled extensive game one efficient method computing nash equilibrium large zero sum imperfect information game counterfactual regret minimization cfr domain poker cfr proven effective particularly using domain specific augmentation involving chance outcome sampling paper describe general family domain independent cfr sample based algorithm called monte carlo counterfactual regret minimization mccfr original poker specific version special case start showing mccfr performs regret update cfr expectation introduce two sampling scheme outcome sampling external sampling showing bounded overall regret high probability thus compute approximate equilibrium using self play finally prove new tighter bound regret original cfr algorithm relate new bound mccfrs bound show empirically although sample based algorithm require iteration lower cost per iteration lead dramatically faster convergence various game', 'hypergraph clustering refers process extracting maximally coherent group set object using high order rather pairwise similarity traditional approach problem based idea partitioning input data user defined number class thereby obtaining cluster product partitioning process paper provide radically different perspective problem contrast classical approach attempt provide meaningful formalization notion cluster show game theory offer attractive unexplored perspective serf well purpose specifically show hypergraph clustering problem naturally cast non cooperative multi player clustering game whereby notion cluster equivalent classical game theoretic equilibrium concept computational viewpoint show problem finding equilibrium clustering game equivalent locally optimizing polynomial function standard simplex provide discrete time dynamic perform optimization experiment presented show superiority approach state art hypergraph clustering technique', 'develop structured output model object category detection explicitly account alignment multiple aspect partial truncation training inference model formulated large margin learning latent variable slack rescaling training inference computationally efficient make following contribution note extending structured output regression formulation blaschko lampert eccv include bias term significantly improves performance ii alignment account small rotation anisotropic scaling included latent variable efficiently determined implemented iii latent variable extends multiple aspect e g left facing right facing front formulation iv significantly performance truncated truncated instance included training inference explicit truncation mask demonstrate method training testing pascal voc data set training includes truncated example testing object instance detected multiple scale alignment significant truncation', 'directed graphical model bayesian network favored formalism model dependency structure complex multivariate system encountered biology neural science system undergoing dynamic transformation often temporally rewiring network needed capturing dynamic causal influence covariates paper propose time varying dynamic bayesian network tv dbn modeling structurally varying directed dependency structure underlying non stationary biological neural time series challenging problem due non stationarity sample scarcity time series present kernel reweighted ell regularized auto regressive procedure learning tv dbn model method enjoys nice property computational efficiency provable asymptotic consistency applying tv dbn time series measurement yeast cell cycle brain response visual stimulus reveals interesting dynamic underlying respective biological system', 'markov random field mrfs undirected graphical model provide powerful framework modeling complex dependency among random variable maximum likelihood learning mrfs hard due presence global normalizing constant paper consider class stochastic approximation algorithm robbins monro type us markov chain monte carlo approximate maximum likelihood learning show using mcmc operator based tempered transition enables stochastic approximation algorithm better explore highly multimodal distribution considerably improves parameter estimate large densely connected mrfs result mnist norb datasets demonstrate successfully learn good generative model high dimensional richly structured data perform well digit object recognition task', 'paper investigate similar image sharing global description help unsupervised scene segmentation image contrast recent work semantic alignment scene allow input image explained partial match similar scene allows better explanation input scene perform mrf based segmentation optimizes match respecting boundary information recovered segment used query large database image retrieve better match target region show improved performance detecting occluding boundary previous method data gathered labelme database', 'ad display sponsored search order maximize revenue dynamically rank information source maximize value information application exhibit strong diminishing return selection redundant ad information source decrease marginal utility show problem formalized repeatedly selecting assignment item position maximize sequence monotone submodular function arrive one one present efficient algorithm general problem analyze regret model algorithm equipped strong theoretical guarantee performance ratio converges optimal constant e empirically evaluate algorithm two real world online optimization problem web ad allocation submodular utility dynamically ranking blog detect information cascade', 'abstract missing', 'develop probabilistic model human memory performance free recall experiment experiment subject first study list word try recall model data draw previous psychological research statistical topic model text document assume memory formed assimilating semantic meaning studied word represented distribution topic slowly changing latent context represented space recall context reinstated used cue retrieving studied word conceptualizing memory retrieval dynamic latent variable model able use bayesian inference represent uncertainty reason cognitive process underlying memory present particle filter algorithm performing approximate posterior inference evaluate model prediction recalled word experimental data specifying model hierarchically also able capture inter subject variability', 'paper address problem noisy generalized binary search gb gb well known greedy algorithm determining binary valued hypothesis sequence strategically selected query step query selected evenly split hypothesis consideration two disjoint subset natural generalization idea underlying classic binary search gb used many application including fault testing machine diagnostics disease diagnosis job scheduling image processing computer vision active learning case response query noisy past work provided partial characterization gb existing noise tolerant version gb suboptimal term sample complexity paper present first optimal algorithm noisy gb demonstrates application learning multidimensional threshold function', 'paper introduce new algorithm updating parameter heuristic evaluation function updating heuristic towards value computed alpha beta search algorithm differs previous approach learning search samuel checker player td leaf algorithm two key way first update node search tree rather single node second use outcome deep search instead outcome subsequent search training signal evaluation function implemented algorithm chess program meep using linear heuristic function initialising weight vector small random value meep able learn high quality weight self play alone tested online human opponent meep played master level best performance chess program heuristic learned entirely self play', 'propose novel non parametric adaptive anomaly detection algorithm high dimensional data based score function derived nearest neighbor graph n point nominal data anomaly declared whenever score test sample fall q supposed desired false alarm level resulting anomaly detector shown asymptotically optimal uniformly powerful specified false alarm level q case anomaly density mixture nominal known density algorithm computationally efficient linear dimension quadratic data size require choosing complicated tuning parameter function approximation class adapt local structure local change dimensionality demonstrate algorithm artificial real data set high dimensional feature space', 'present novel feature selection algorithm k mean clustering problem algorithm randomized assuming accuracy parameter epsilon selects appropriately rescales unsupervised manner theta k log k epsilon epsilon feature dataset arbitrary dimension prove run gamma approximate k mean algorithm gamma geq feature selected using method find epsilon gamma approximate partition high probability', 'situation people opposing prior belief observe evidence strengthen existing belief frequently offered evidence human irrationality phenomenon termed belief polarization typically assumed non normative demonstrate however variety case belief polarization consistent bayesian approach belief revision simulation result indicate belief polarization possible relatively common within class bayesian model consider', 'extend concept phase tuning ubiquitous mechanism sensory neuron including motion disparity detection neuron motion contrast detection demonstrate motion contrast detected phase shift motion neuronal response different spatial region constructing differential motion opponency response motion two different spatial region varying motion contrast detected similar motion detected zero phase shift difference motion non zero phase shift model exhibit either enhancement suppression response either different similar motion surrounding primary advantage model response selective relative motion instead absolute motion could model neuron found neurophysiological experiment responsible motion pop detection', 'individual independently recollect event retrieve fact memory aggregate retrieved memory reconstruct actual set event fact research report performance individual series general knowledge task goal reconstruct memory order historic event order item along physical dimension introduce two bayesian model aggregating order information based thurstonian approach mallow model model assume individual reconstruction based either random permutation unobserved ground truth pure guessing strategy apply mcmc make inference underlying truth strategy employed individual model demonstrate wisdom crowd effect aggregated ordering closer true ordering ordering best individual', 'alignment time series important problem solve many scientific discipline particular temporal alignment two subject performing similar activity challenging problem due large temporal scale difference human action well inter intra subject variability paper present canonical time warping ctw extension canonical correlation analysis cca spatio temporal alignment behavior two subject ctw extends previous work cca two way combine cca dynamic time warping temporal alignment ii extends cca allow local spatial deformation show ctws effectiveness three experiment alignment synthetic data alignment motion capture data two subject performing similar action alignment two people similar facial expression result demonstrate ctw provides visually qualitatively better alignment state art technique based dynamic time warping', 'present nonparametric bayesian method texture learning synthesis texture image represented hidden markov model hmm hidden state correspond cluster labeling textons transition matrix encodes spatial layout compatibility adjacent textons hmm coupled hierarchical dirichlet process hdp allows number textons complexity transition matrix grow input texture becomes irregular hdp make use dirichlet process prior favor regular texture penalizing model complexity framework hdp hmm learns texton vocabulary spatial layout jointly automatically hdp hmm result compact representation texture allows fast texture synthesis comparable rendering quality state art image based rendering method also show hdp hmm applied perform image segmentation synthesis', 'abstract missing', 'recent work led ability perform space ef cient approximate counting large vocabulary streaming context motivated existence data structure type explore computation associativity score wise known pointwise mutual information pmi streaming context give theoretical bound showing impracticality perfect online pmi compu tation detail algorithm high expected accuracy experiment news article show approach give high accuracy real world data', 'individual learn fact e g foreign language vocabulary multiple study session temporal spacing study significant impact memory retention behavioral experiment shown nonmonotonic relationship spacing retention short long interval study session yield lower cued recall accuracy intermediate interval appropriate spacing study double retention educationally relevant time scale introduce multiscale context model mcm able predict influence particular study schedule retention specific material mcms prediction based empirical data characterizing forgetting material following single study session mcm synthesis two existing memory model staddon chelaru higa raaijmakers surface model unrelated incompatible show share core feature allows integrated mcm determine study schedule maximize durability learning implication education training mcm cast either neural network input fluctuate time cascade leaky integrator mcm intriguingly similar bayesian multiscale model memory kording tenenbaum shadmehr yet mcm better able account human declarative memory', 'goal central importance study hierarchical model object recognition indeed visual cortex understanding quantitatively trade invariance selectivity invariance discrimination property contribute towards providing improved representation useful learning data work provide general group theoretic framework characterizing understanding invariance family hierarchical model show taking algebraic perspective one provide concise set condition must met establish invariance well constructive prescription meeting condition analysis specific case particular relevance computer vision text processing given yielding insight invariance achieved find minimal set transformation intrinsic hierarchical model needed support particular invariance clearly described thereby encouraging efficient computational implementation', 'although widely believed reinforcement learning suitable tool describing behavioral learning mechanism implemented network spiking neuron fully understood show different learning rule emerge policy gradient approach depending feature spike train assumed influence reward signal e depending neural code effect use framework williams derive learning rule arbitrary neural code illustration present policy gradient rule three different example code spike count code spike timing code general full spike train code test simple model problem addition classical synaptic learning derive learning rule intrinsic parameter control excitability neuron spike count learning rule structural similarity established bienenstock cooper munro rule distribution relevant spike train feature belongs natural exponential family learning rule characteristic shape raise interesting prediction problem', 'present novel highly effective approach multi body motion segmentation drawing inspiration robust statistical model fitting estimate putative subspace hypothesis data however instead ranking encapsulate hypothesis novel mercer kernel elicits potential two point trajectory emerged subspace kernel permit application well established statistical learning method effective outlier rejection automatic recovery number motion accurate segmentation point trajectory method operates well severe outlier arising spurious trajectory mistracks detailed experiment recent benchmark dataset hopkins show method superior state art approach term recovering number motion segmentation accuracy robustness gross outlier computational efficiency', 'cognitive science empirical data collected participant arbiter model selection model discrimination thus depends designing maximally informative experiment shown adaptive design optimization ado allows one discriminate model efficiently possible simulation experiment paper use ado series experiment people discriminate power exponential hyperbolic model memory retention long standing problem cognitive science providing ideal setting test application ado addressing question human cognition using optimality criterion based mutual information ado able find design maximally likely increase certainty true model upon observation experiment outcome result demonstrate usefulness ado also reveal challenge implementation', 'prove oracle inequality generic regularized empirical risk minimization algorithm learning mixing process illustrate oracle inequality use derive learning rate learning method including least square svms since proof oracle inequality us recent localization idea developed independent identically distributed process turn learning rate close optimal rate known case', 'consider general problem constructing nonparametric bayesian model infinite dimensional random object function infinite graph infinite permutation problem generated much interest machine learning treated heuristically studied full generality nonparametric bayesian statistic tends focus model probability distribution approach applies standard tool stochastic process theory construction stochastic process finite dimensional marginal distribution main contribution paper generalization classic kolmogorov extension theorem conditional probability extension allows rigorous construction nonparametric bayesian model system finite dimensional parametric bayes equation using approach show existence conjugate posterior nonparametric model guaranteed choosing conjugate finite dimensional model construction ii mapping posterior parameter nonparametric model explicitly determined iii construction conjugate model essence requires finite dimensional model exponential family application constructive framework derive model infinite permutation nonparametric bayesian analogue model recently proposed analysis rank data', 'kernel embedding probability distribution reproducing kernel hilbert space rkhs recently proposed allows comparison two probability measure p q based distance respective embeddings sufficiently rich rkhs distance zero p q coincide using distance statistic test whether two sample different distribution major difficulty arises computing significance threshold since empirical statistic null distribution p q infinite weighted sum chi random variable main result present work novel consistent estimate null distribution computed eigenspectrum gram matrix aggregate sample p q estimate may computed faster previous consistent estimate based bootstrap another prior approach compute null distribution based fitting parametric family low order moment test statistic unlike present work heuristic guarantee accurate consistent verify performance null distribution estimate artificial example high dimensional multivariate data', 'prove certain theoretical property graph regularized transductive learning objective based minimizing kullback leibler divergence based loss include showing iterative alternating minimization procedure used minimize objective converges correct solution deriving test convergence also propose graph node ordering algorithm cache cognizant lead linear speedup parallel computation ensures algorithm scale large data set making use empirical evaluation timit switchboard corpus show approach able perform state art ssl approach one instance solve problem million node graph', 'abstract missing', 'recent work statistical modeling neural response focused modulated renewal process spike rate function stimulus recent spiking history typically model incorporate spike history dependency via either conditionally poisson process rate dependent linear projection spike train history e g generalized linear model b modulated non poisson renewal process e g inhomogeneous gamma process show two approach combined resulting conditional renewal cr model neural spike train model capture real rescaled time effect fit maximum likelihood using simple application time rescaling theorem show modulated renewal process model log likelihood concave linear filter parameter certain restrictive condition renewal density ruling many popular choice e g gamma kappa neq suggesting real time history effect easier estimate non poisson renewal property moreover show goodness fit test based time rescaling theorem quantify relative time effect reliably ass accuracy spike prediction stimulus response modeling illustrate cr model application real simulated neural data', 'semi supervised regression based graph laplacian suffers fact solution biased towards constant lack extrapolating power outgoing observation propose use second order hessian energy semi supervised regression overcomes problem particular data lie close low dimensional submanifold feature space hessian energy prefers function vary linearly respect natural parameter data property make also particularly suited task semi supervised dimensionality reduction goal find natural parameter data based labeled point experimental result suggest method superior semi supervised regression using laplacian regularization standard supervised method particularly suited semi supervised dimensionality reduction', 'present class nonlinear polynomial model discriminatively trained directly map word content query document document document pair ranking score dealing polynomial model word feature computationally challenging propose low rank diagonal preserving representation polynomial model induce feasible memory computation requirement provide empirical study retrieval task based wikipedia document obtain state art performance providing realistically scalable method', 'existing method dna motif discovery consider single set sequence find represented motif contrast consider multiple set sequence group set associated motif cluster assuming set involves single motif clustering set sequence yield cluster coherent motif improving signal noise ratio enabling u identify multiple motif present probabilistic model dna motif discovery identify multiple motif searching pattern shared across multiple set sequence model infers cluster indicating latent variable learns motif simultaneously two task interact show model handle various motif discovery problem depending construct multiple set sequence experiment three different problem discovering dna motif emphasize useful behavior confirm substantial gain existing method single set sequence considered', 'principle spiking neuron contribute astounding computational power generic cortical microcircuit spike timing dependent plasticity stdp synaptic weight could generate maintain computational function unknown show stdp conjunction stochastic soft winner take wta circuit induces spiking neuron generate synaptic weight implicit internal model subclass cause high dimensional spike pattern hundred pre synaptic neuron hence neuron fire learning whenever current input best match internal model resulting computational function soft wta circuit common network motif cortical microcircuit could therefore drastic dimensionality reduction information stream together autonomous creation internal model probability distribution input pattern show autonomous generation maintenance computational function explained basis rigorous mathematical principle particular show stdp able approximate stochastic online expectation maximization em algorithm modeling input data corresponding result shown hebbian learning artificial neural network', 'abstract missing', 'minimum description length mdl principle selects model shortest code data plus model show countable class model mdl prediction close true distribution strong sense result completely general independence ergodicity stationarity identifiability assumption model class need made formally show countable class model distribution selected mdl map asymptotically predict merge true measure class total variation distance implication non domain like time series forecasting discriminative learning reinforcement learning discussed', 'everyday social interaction heavily influenced snap judgment others goal even young infant infer goal intentional agent observing interact object agent environment e g one agent helping hindering anothers attempt get hill open box propose model people infer social goal action based inverse planning multiagent markov decision problem mdps model infers goal likely driving agent behavior assuming agent act approximately rationally given environmental constraint model agent present also present behavioral evidence support model simpler perceptual cue based alternative', 'resting state activity brain activation arises absence task usually measured awake subject prolonged fmri scanning session instruction given close eye nothing recognized recent year resting state activity implicated wide variety brain function certain network brain area different level activation rest task nevertheless significant similarity activation two case suggests recording resting state activity used source unlabeled data augment discriminative regression technique semi supervised setting evaluate setting empirically yielding three main result regression tends improved use laplacian regularization even additional unlabeled data available ii resting state data may similar marginal distribution recorded execution visual processing task reinforcing hypothesis condition similar type activation iii source information broadly exploited improve robustness empirical inference fmri study inherently data poor domain', 'paper address problem designing binary code high dimensional data vector similar original space map similar binary string introduce simple distribution free encoding scheme based random projection expected hamming distance binary code two vector related value shift invariant kernel e g gaussian kernel vector present full theoretical analysis convergence property proposed scheme report favorable experimental performance compared recent state art method spectral hashing', 'abstract missing', 'abstract missing', 'introduce novel multivariate laplace mvl distribution sparsity promoting prior bayesian source localization allows specification constraint within source represent mvl distribution scale mixture induces coupling source variance instead mean approximation posterior marginals using expectation propagation shown efficient due property scale mixture representation computational bottleneck amount computing diagonal element sparse matrix inverse approach illustrated using mismatch negativity paradigm meg data structural mri acquired show spatial coupling lead source active larger cortical area compared uncoupled prior', 'investigate method selecting set labeled vertex use predicting label vertex graph specifically study method choose single batch labeled vertex e offline non sequential method setting find common graph smoothness assumption directly motivate simple label selection method interesting theoretical guarantee method bound prediction error term smoothness true label respect graph bound give new motivation previously proposed algorithm suggest new algorithm evaluate show improved performance baseline method several real world data set', 'algorithm presented online learning rotation proposed algorithm involves matrix exponentiated gradient update motivated von neumann divergence additive update skew symmetric matrix trace zero comprise lie algebra rotation group orthogonality unit determinant matrix parameter preserved using matrix logarithm exponential algorithm lends interesting interpretation term computational topology compact lie group stability computational complexity algorithm discussed', 'propose novel information theoretic approach semi supervised learning conditional random field approach defines training objective combine conditional likelihood labeled data mutual information unlabeled data different previous minimum conditional entropy semi supervised discriminative learning method approach naturally cast rate distortion theory framework information theory analyze tractability framework structured prediction present convergent variational training algorithm defy combinatorial explosion term sum label configuration experimental result show rate distortion approach outperforms standard l regularization minimum conditional entropy regularization multi class classification sequence labeling problem', 'standard assumption identically distributed training test data violated adversary exercise control generation test data prediction game learner produce predictive model adversary may alter distribution input data study single shot prediction game cost function learner adversary necessarily antagonistic identify condition prediction game unique nash equilibrium derive algorithm find equilibrial prediction model case study explore property nash equilibrial prediction model email spam filtering empirically', 'graph matching map inference essential problem computer vision machine learning introduce novel algorithm accommodate problem solve efficiently recent graph matching algorithm based general quadratic programming formulation take consideration unary second order term reflecting similarity local appearance well pairwise geometric relationship matched feature case problem np hard lot effort spent finding efficiently approximate solution relaxing constraint original problem algorithm find optimal continuous solution modified problem ignoring optimization original discrete constraint continuous solution quickly binarized end little attention put final discretization step paper argue stage discrete solution found crucial good performance propose efficient algorithm climbing convergence property optimizes discrete domain quadratic score give excellent result either starting solution returned graph matching algorithm practice outperforms state art algorithm also significantly improves performance used combination applied map inference algorithm parallel extension iterated conditional mode icm climbing convergence property make compelling alternative sequential icm experiment map inference algorithm proved effectiveness outperforming icm max product belief propagation', 'image representation based image base provides framework understanding neural representation visual perception recent fmri study shown arbitrary contrast defined visual image reconstructed fmri activity pattern using combination multi scale local image base reconstruction model mapping fmri activity pattern contrast image base learned measured fmri response visual image shape image base fixed thus may optimal reconstruction propose method build reconstruction model image base automatically extracted measured data constructed probabilistic model relates fmri activity space visual image space via set latent variable mapping latent variable visual image space regarded set image base found spatially localized multi scale image base estimated near fovea model using estimated image base able accurately reconstruct novel visual image proposed method provides mean discover novel functional mapping stimulus brain activity pattern', 'learning rank relatively new field study aiming learn ranking function set training data relevancy label ranking algorithm often evaluated using information retrieval measure normalized discounted cumulative gain mean average precision recently learning rank algorithm using loss function related mentioned evaluation measure main difficulty direct optimization measure depend rank document numerical value output ranking function propose probabilistic framework address challenge optimizing expectation ndcg possible permutation document relaxation strategy used approximate average ndcg space permutation bound optimization approach proposed make computation efficient extensive experiment show proposed algorithm outperforms state art ranking algorithm several benchmark data set', 'given corpus news item consisting image accompanied text caption want find who e associate name action verb caption face body pose person image present joint model simultaneously solving image caption correspondence learning visual appearance model face pose class occurring corpus model used recognize people action novel image without caption demonstrate experimentally joint face pose model solves correspondence problem better earlier model covering face perform recognition new uncaptioned image', 'abstract missing', 'classic debate cognitive science revolves around understanding child learn complex linguistic rule governing restriction verb alternation without negative evidence traditionally formal learnability argument used claim learning impossible without aid innate language specific knowledge however recently researcher shown statistical model capable learning complex rule positive evidence two kind learnability analysis differ assumption role distribution linguistic input generated former analysis assume learner seek identify grammatical sentence way robust distribution sentence generated analogous discriminative approach machine learning latter assume learner trying estimate generative model sentence sampled model show two learning approach differ use implicit negative evidence absence sentence learning verb alternation demonstrate human learner produce result consistent prediction approach depending context learning problem presented', 'existing value function approximation method successfully used many application often lack useful priori error bound propose approximate bilinear programming new formulation value function approximation provides strong priori guarantee particular provably find approximate value function minimizes bellman residual solving bilinear program optimally np hard unavoidable bellman residual minimization np hard therefore employ analyze common approximate algorithm bilinear program analysis show algorithm offer convergent generalization approximate policy iteration finally demonstrate proposed approach consistently minimize bellman residual simple benchmark problem', 'several key problem machine learning feature selection active learning formulated submodular set function maximization present herein novel algorithm maximizing submodular set function cardinality constraint algorithm based cutting plane method implemented iterative small scale binary integer linear programming procedure well known problem np hard approximation factor achieved greedy algorithm theoretical limit polynomial time non polynomial time exact algorithm perform reasonably practice little literature although problem quite important many application algorithm guaranteed find exact solution finite iteration converges fast practice due efficiency cutting plane mechanism moreover also provide method produce successively decreasing upper bound optimal solution algorithm provides successively increasing lower bound thus accuracy current solution estimated point algorithm stopped early desired degree tolerance met evaluate algorithm sensor placement feature selection application showing good performance', 'low rank matrix completion problem fundamental problem many important application recently candes recht keshavan et al candes tao obtained first non trivial theoretical result problem assuming observed entry sampled uniformly random unfortunately real world datasets satisfy assumption instead exhibit power law distributed sample paper propose graph theoretic approach matrix completion solves problem realistic sampling model method easier analyze previous method analysis reducing computing threshold complete cascade random graph problem independent interest analyzing graph theoretic problem show method achieves exact recovery observed entry sampled chung lu vu model generate power law distributed graph also hypothesize algorithm solves matrix completion problem optimal number entry popular preferential attachment model provide strong empirical evidence claim furthermore method easier implement substantially faster existing method demonstrate effectiveness method example low rank matrix sampled according prevalent random graph model complex network also netflix challenge dataset', 'inter subject alignment functional mri fmri data important improving statistical power fmri group analysis contrast existing anatomically based method propose novel multi subject algorithm derives functional correspondence aligning spatial pattern functional connectivity across set subject test method fmri data collected movie viewing experiment cross validating result algorithm show correspondence successfully generalizes secondary movie dataset used derive alignment', 'estimation high dimensional parametric model requires imposing structure model instance sparse matrix structured parameter low rank general approach structured parametric model estimation use regularized estimation procedure regularize loss function measure goodness fit parameter data regularization function encourages assumed structure paper aim provide unified analysis regularized estimation procedure particular report convergence rate estimator metric norm using main theorem able rederive many existing result also obtain wide range novel convergence rate result analysis also identifies key property loss regularization function restricted strong convexity decomposability ensure corresponding regularized estimator good convergence rate', 'object detection multi class image segmentation two closely related task greatly improved solved jointly feeding information one task however current state art model use separate representation task making joint inference clumsy leaving classification many part scene ambiguous work propose hierarchical region based approach joint object detection image segmentation approach reason pixel region object coherent probabilistic model importantly model give single unified description scene explain every pixel image enforce global consistency variable model run experiment challenging vision datasets show significant improvement state art object detection accuracy', 'policy gradient reinforcement learning rl algorithm received much attention seeking stochastic policy maximize average reward addition extension based concept natural gradient ng show promising learning efficiency regard metric task though two candidate metric kakades fisher information matrix fim morimuras fim rl algorithm ng followed kakades approach paper describe generalized natural gradient gng linearly interpolating two fims propose efficient implementation gng learning based theory estimating function generalized natural actor critic gnac gnac algorithm involves near optimal auxiliary function reduce variance gng estimate interestingly gnac regarded natural extension current state art nac algorithm long interpolating parameter appropriately selected numerical experiment showed proposed gnac algorithm estimate gng efficiently outperformed nac algorithm', 'introduce new perspective approximation maximum posteriori map task probabilistic graphical model based simplifying given instance tightening approximation first start structural relaxation original model infer relaxation deficiency compensate perspective allows u identify two distinct class approximation first find max product belief propagation viewed way compensate relaxation based particular idealized case exactness identify second approach compensation based refined idealized case resulting new approximation distinct property go propose new class algorithm starting relaxation iteratively yield tighter approximation', 'recently shown certain nonparametric regressors escape curse dimensionality sense convergence rate adapt intrinsic dimension data cite bl sk prove stronger result general setting particular consider regressor combining aspect tree based regression kernel regression operates general metric space yield smooth function evaluates time log n derive tight convergence rate form n assouad dimension input space', 'abstract missing', 'stochastic neighbor embedding sne shown quite promising data visualization currently popular implementation sne restricted particular student distribution embedding distribution moreover us gradient descent algorithm may require user tune parameter learning step size momentum etc finding optimum paper propose heavy tailed symmetric stochastic neighbor embedding hssne method generalization sne accommodate various heavy tailed embedding similarity function generalization presented two difficulty first select best embedding similarity among heavy tailed function second optimize objective function heave tailed function selected contribution point various heavy tailed embedding similarity characterized negative score function based finding present parameterized subset similarity function choosing best tail heaviness hssne present fixed point optimization algorithm applied heavy tailed function require user set parameter present two empirical study one unsupervised visualization showing optimization algorithm run fast good best known sne implementation semi supervised visualization showing quantitative superiority using homogeneity measure well qualitative advantage cluster separation sne', 'propose use rademacher complexity originally developed computational learning theory measure human learning capacity rademacher complexity measure learner ability fit random data used bound learner true error based observed training sample error first review definition rademacher complexity generalization bound describe learning noise procedure experimentally measure human rademacher complexity result empirical study showed human rademacher complexity successfully measured ii complexity depends domain training sample size intuitive way iii human learning respect generalization bound iv bound useful predicting danger overfitting human learning finally discus potential application human rademacher complexity cognitive science', 'one central problem neuroscience reconstructing synaptic connectivity neural circuit synapsis onto neuron probed sequentially stimulating potentially pre synaptic neuron monitoring membrane voltage post synaptic neuron reconstructing large neural circuit using brute force approach rather time consuming inefficient connectivity neural circuit sparse instead propose measure post synaptic neuron voltage stimulating simultaneously multiple randomly chosen potentially pre synaptic neuron extract weight individual synaptic connection apply decoding algorithm recently developed compressive sensing compared brute force approach method promise significant time saving grow size circuit use computer simulation find optimal stimulation parameter explore feasibility reconstruction method realistic experimental condition including noise non linear synaptic integration multiple neuron stimulation allows reconstructing synaptic connectivity spiking activity post synaptic neuron even sub threshold voltage unavailable using calcium indicator voltage sensitive dye multi electrode array one could monitor activity multiple post synaptic neuron simultaneously thus mapping synaptic input parallel potentially reconstructing complete neural circuit', 'propose probabilistic topic model analyzing extracting content related annotation noisy annotated discrete data web page stored social bookmarking service service since user attach annotation freely annotation describe semantics content thus noisy e content related extraction content related annotation used preprocessing step machine learning task text classification image recognition improve information retrieval performance proposed model generative model content annotation annotation assumed originate either topic generated content general distribution unrelated content demonstrate effectiveness proposed method using synthetic data real social annotation data text image', 'proposal cortical activity visual cortex optimized sparse neural activity one established idea computational neuroscience however direct experimental evidence optimal sparse coding remains inconclusive mostly due lack reference value judge measured sparseness analyze neural response natural movie primary visual cortex ferret different stage development rat awake different level anesthesia contrast prediction sparse coding model data show population lifetime sparseness decrease visual experience increase awake anesthetized state result suggest representation primary visual cortex actively optimized maximize sparseness', 'representing distribution permutation daunting task due fact number permutation n object scale factorially n one recent way used reduce storage complexity exploit probabilistic independence argue full independence assumption impose strong sparsity constraint distribution unsuitable modeling ranking identify novel class independence structure called riffled independence encompasses expressive family distribution retaining many property necessary performing efficient inference reducing sample complexity riffled independence one draw two permutation independently performs riffle shuffle common card game combine two permutation form single permutation ranking riffled independence corresponds ranking disjoint set object independently interleaving ranking provide formal introduction present algorithm using riffled independence within fourier theoretic framework explored number recent paper', 'human typically able infer many object environment contains recognize object encountered twice present simple statistical model help explain ability evaluate three behavioral experiment first experiment suggests human rely prior knowledge deciding whether object token previously encountered second third experiment suggest human infer many object seen learn category property even uncertain token instance object', 'given matrix low rank consider problem reconstructing noisy observation small random subset entry problem arises variety application collaborative filtering netflix problem structure motion positioning study low complexity algorithm introduced based combination spectral technique manifold optimization call optspace prove performance guarantee order optimal number circumstance', 'one crucial assumption made principal component analysis pca probabilistic pca ppca instance independent identically distributed however common assumption unreasonable relational data paper explicitly modeling covariance instance derived relational information propose novel probabilistic dimensionality reduction method called probabilistic relational pca prpca relational data analysis although assumption longer adopted prpca learning algorithm prpca still devised easily like ppca make explicit use assumption experiment real world data set show prpca effectively utilize relational information dramatically outperform pca achieve state art performance', 'propose new approach analysis loopy belief propagation lbp establishing formula connects hessian bethe free energy edge zeta function formula number theoretical implication lbp applied give sufficient condition hessian bethe free energy positive definite show non convexity graph multiple cycle formula clarifies relation local stability fixed point lbp local minimum bethe free energy also propose new approach uniqueness lbp fixed point show various condition uniqueness', 'abstract missing', 'partially observable markov decision process pomdp framework proven useful planning domain require balancing action increase agent knowledge action increase agent reward unfortunately pomdps complex structure large number parameter many realworld problem structure parameter difficult specify domain knowledge alone recent work bayesian reinforcement learning made headway learning pomdp model however work largely focused learning parameter pomdp model define infinite pomdp ipomdp model require knowledge size state space instead assumes number visited state grow agent explores world explicitly model visited state demonstrate ipomdp utility several standard problem', 'search engine today present result often oblivious recent shift intent example meaning query independence day shift early july u holiday movie around time box office release study exactly quantify magnitude intent shifting traffic study suggest news event seasonal topic pop culture etc account search query paper show signal search engine receives used determine shift intent happened well find result relevant present meta algorithm marries classifier bandit algorithm achieve regret depends logarithmically number query impression certain assumption provide strong evidence regret close best achievable finally via series experiment demonstrate algorithm outperforms prior approach particularly amount intent shifting traffic increase', 'goal perception infer hidden state hierarchical process sensory data generated human behavior consistent optimal statistical solution problem many task including cue combination orientation detection understanding neural mechanism underlying behavior particular importance since probabilistic computation notoriously challenging propose simple mechanism bayesian inference involves averaging feature detection neuron fire rate determined similarity sensory stimulus mechanism based monte carlo method known importance sampling commonly used computer science statistic moreover simple extension recursive importance sampling used perform hierarchical bayesian inference identify scheme implementing importance sampling spiking neuron show scheme account human behavior cue combination oblique effect', 'present general bayesian approach probabilistic matrix factorization subject linear constraint approach based gaussian observation model gaussian prior bilinear equality inequality constraint present efficient markov chain monte carlo inference procedure based gibbs sampling special case proposed model bayesian formulation non negative matrix factorization factor analysis method evaluated blind source separation problem demonstrate algorithm used extract meaningful interpretable feature remarkably different feature extracted using existing related matrix factorization technique', 'orthogonal matching pursuit omp widely used greedy algorithm recovering sparse vector linear measurement well known analysis tropp gilbert show omp recover k sparse n dimensional real vector k log n noise free random linear measurement probability go one n go infinity work show strengthens result showing lower number measurement k log n k fact sufficient asymptotic recovery moreover number measurement also sufficient detection sparsity pattern support vector measurement error provided signal noise ratio snr scale infinity scaling k log n k exactly match number measurement required complex lasso signal recovery', 'contrast statistic majority natural image conform weibull distribution property natural image may facilitate efficient rapid extraction scene visual gist investigate whether neural response model based weibull contrast distribution capture visual information human use rapidly identify natural scene learning phase measure eeg activity subject viewing brief flash natural scene neural measurement contrast statistic natural image stimulus derive across subject weibull response model use model predict response large set new scene estimate scene subject viewed finding best match model prediction observed eeg response almost percent case model accurately predicts observed scene moreover failed case scene mistaken observed scene visually similar observed scene result suggest weibull contrast statistic natural image contain considerable amount scene gist information warrant rapid identification natural image', 'provide insight task correlation multi task gaussian process gp regression affect generalization error learning curve analyze asymmetric two task case secondary task help learning primary task within setting give bound generalization error learning curve primary task approach admits intuitive understanding multi task gp relating single task gps case one dimensional input space optimal sampling data secondary task limitation multi task gp quantified explicitly', 'online learning algorithm weight assigned misclassified example support vector remain unchanged entire learning process clearly insufficient since new misclassified example added pool support vector generally expect affect weight existing support vector paper propose new online learning method termed double updating online learning duol short instead assigning fixed weight misclassified example received current trial proposed online learning algorithm also try update weight one existing support vector show mistake bound significantly improved proposed online learning method encouraging experimental result show proposed technique general considerably effective state art online learning algorithm', 'recent emergence graphic processing unit gpus general purpose parallel computing device provides u new opportunity develop scalable learning method massive data work consider problem parallelizing two inference method gpus latent dirichlet allocation lda model collapsed gibbs sampling cgs collapsed variational bayesian cvb address limited memory constraint gpus propose novel data partitioning scheme effectively reduces memory cost furthermore partitioning scheme balance computational cost multiprocessor enables u easily avoid memory access conflict also use data streaming handle extremely large datasets extensive experiment showed parallel inference method consistently produced lda model predictive power sequential training method x speedup cgs x speedup cvb gpu multiprocessor actually speedup almost linearly scalable number multiprocessor available proposed partitioning scheme data streaming easily ported many model machine learning', 'describe algorithm learning bilinear svms bilinear classifier discriminative variant bilinear model capture dependence data multiple factor model particularly appropriate visual data better represented matrix tensor rather vector matrix encoding allow natural regularization rank restriction example rank one scanning window classifier yield separable filter low rank model fewer parameter easier regularize faster score run time learn low rank model bilinear classifier also use bilinear classifier transfer learning sharing linear factor different classification task bilinear classifier trained biconvex program program optimized coordinate descent coordinate step requires solving convex program case use standard shelf svm solver demonstrate bilinear svms difficult problem people detection video sequence action classification video sequence achieving state art result', 'abstract missing', 'many computer vision application ideal image feature would invariant multiple confounding image property illumination viewing angle recently deep architecture trained unsupervised manner proposed automatic method extracting useful feature however outside using learning algorithm classi er sometimes dif cult evaluate paper propose number empirical test directly measure degree learned feature invariant different image transforms nd deep autoencoders become invariant increasingly complex image transformation depth justi e use deep v shallower representation performance metric agree existing measure invariance evaluation metric also used evaluate future work unsupervised deep learning thus help development future algorithm', 'describe method learning group continuous transformation operator traverse smooth nonlinear manifold method applied model natural image change time scale group continuous transform operator represented basis adapted statistic data nitesimal generator measurement orbit produced linear combination basis element illustrate method used ef ciently code time varying image describing change across time scale term learned operator', 'devise graphical model support process debugging software guiding developer code likely contain defect model trained using execution trace passing test run reflects distribution transitional pattern code position given failing test case model determines least likely transitional pattern execution trace model designed bayesian inference closed form solution evaluate bernoulli graph model data software project aspectj rhino', 'describe analyze experiment new framework empirical loss minimization regularization algorithmic framework alternate two phase iteration first perform em unconstrained gradient descent step cast solve instantaneous optimization problem trade minimization regularization term keeping close proximity result first phase yield simple yet effective algorithm batch penalized risk minimization online learning furthermore two phase approach enables sparse solution used conjunction regularization function promote sparsity ell derive concrete simple algorithm minimization loss function ell ell ell ell infty regularization also show construct efficient algorithm mixed norm ell ell q regularization extend algorithm give efficient implementation high dimensional data sparsity demonstrate potential proposed framework experiment synthetic natural datasets', 'central hypothesis early visual processing represents input coordinate system matched statistic natural scene simple version lead gabor like receptive field divisive gain modulation local surround led influential neural psychological model visual processing however account based incomplete view visual context surrounding point consider approximate model linear non linear correlation response spatially distributed gabor like receptive field trained ensemble natural scene unifies range spatial context effect full model account neural surround data primary visual cortex v provides statistical foundation perceptual phenomenon associated li hypothesis v build saliency map fit data tilt illusion', 'practice investing done assuming probabilistic model stock price return known geometric brownian motion gbm often acceptable approximation gbm model always valid empirically motivates worst case approach investing called universal portfolio management objective maximize wealth relative wealth earned best fixed portfolio hindsight paper tie two approach design investment strategy universal worst case yet capable exploiting mostly valid gbm model method based new improved regret bound online convex optimization exp concave loss function', 'several key computational bottleneck machine learning involve pairwise distance computation including nearest neighbor finding nearest neighbor point e g manifold learning kernel summation e g kernel density estimation kernel machine consider general bichromatic case problem addition scientific problem n body potential calculation paper show first time n worst case runtimes practical algorithm problem based cover tree data structure beygelzimer kakade langford', 'study present method estimating mutual information localized pattern fmri data show taking multivariate information approach voxel selection lead decoding accuracy surpasses univariate inforamtion approach standard voxel selection method furthermore extend multivariate mutual information theory measure functional connectivity distributed brain region jointly estimating information shared two set voxels reliably map connectivity human brain experiment condition validated approach way scene categorization fmri experiment multivariate information analysis able nd strong information ow ppa rsc con rms existing neuroscience study scene furthermore exploring whole brain method identifies interesting roi share information ppa rsc scene network suggesting interesting future work neuroscientist', 'multiple object class learning detection challenging problem due large number object class high visual variability specialized detector usually excel performance joint representation optimize sharing reduce inference time complex train conveniently sequential learning category cut training time transferring existing knowledge novel class cannot fully exploit richness shareability might depend ordering learning hierarchical framework issue little explored paper show different type multi class learning done within one generative hierarchical framework provide rigorous experimental analysis various object class learning strategy number class grows specifically propose evaluate compare three important type multi class learning independent training individual category joint training class sequential learning class explore compare computational behavior space time detection performance function number learned class several recognition data set', 'present novel linear program approximation dynamic programming cost go function high dimensional stochastic control problem lp approach approximate dp naturally restrict attention approximation lower bound optimal cost go function program smoothed approximate linear program relaxes restriction appropriate fashion remaining computationally tractable appears several advantage first demonstrate superior bound quality approximation optimal cost go function afforded approach second experiment approach challenging problem game tetri show approach outperforms existing lp approach previously shown competitive several adp algorithm order magnitude', 'abstract missing', 'abstract missing', 'present method learning max weight matching predictor bipartite graph method consists performing maximum posteriori estimation exponential family sufficient statistic encode permutation data feature although inference general hard show one relevant application document ranking exact inference efficient general model instance appropriate sampler readily available contrary existing max margin matching model approach statistically consistent addition experiment increasing sample size indicate superior improvement model apply method graph matching computer vision well standard benchmark dataset learning document ranking obtain state art result particular improving max margin variant drawback method respect max margin alternative runtime large graph high comparatively', 'locality information crucial datasets variable corresponds measurement manifold silhouette motion trajectory image although datasets typically sampled high dimensional often need represented low complexity statistical model comprised important probabilistic dependency datasets method attempt reduce model complexity enforcing structure sparseness however sparseness cannot describe inherent regularity structure hence paper first propose new class gaussian graphical model together sparseness imposes local constancy ell norm penalization second propose efficient algorithm decomposes strictly convex maximum likelihood estimation sequence problem closed form solution synthetic experiment evaluate closeness recovered model ground truth also test generalization performance method wide range complex real world datasets demonstrate capture useful structure rotation shrinking beating heart motion correlation body part walking functional interaction brain region method outperforms state art structure learning technique gaussian graphical model small large datasets', 'speaker comparison process finding speaker similarity two speech signal occupies central role variety application speaker verification clustering identification speaker comparison placed geometric framework casting problem model comparison process given speech signal feature vector produced used adapt gaussian mixture model gmm speaker comparison viewed process compensating finding metric space adapted model propose framework inner product discriminant function ipdfs extends many common technique speaker comparison support vector machine joint factor analysis linear scoring framework us inner product parameter vector gmm model motivated several statistical method compensation nuisance performed via linear transforms gmm parameter vector using ipdf framework show many current technique simple variation demonstrate nist speaker recognition evaluation task new scoring method using ipdfs produce excellent error rate require significantly le computation current technique', 'often interested casting classification clustering problem regression framework feasible achieve statistical property framework imposing penalty criterion paper illustrate optimal scoring originally proposed performing fisher linear discriminant analysis regression application unsupervised learning particular devise novel clustering algorithm call optimal discriminant clustering odc associate algorithm existing unsupervised learning algorithm spectral clustering discriminative clustering sparse principal component analysis thus work show optimal scoring provides new approach implementation unsupervised learning approach facilitates development new unsupervised learning algorithm', 'propose multiple incremental decremental algorithm support vector machine svm conventional single cremental decremental svm update trained model efficiently single data point added removed training set add remove multiple data point algorithm time consuming need repeatedly apply data point roposed algorithm computationally efficient multiple data point added removed simultaneously single incremental decremental algorithm built optimization technique called parametric programming extend idea introduce multi parametric programming developing proposed algorithm experimental result synthetic real data set indicate proposed algorithm significantly reduce computational cost multiple incremental decremental operation approach especially useful online svm learning need remove old data point add new data point short amount time', 'present probabilistic latent factor model used studying spatio temporal datasets spatial temporal structure modeled using gaussian process prior loading matrix factor posterior distribution approximated using variational bayesian framework high computational cost gaussian process modeling reduced using sparse approximation model used compute reconstruction global sea surface temperature historical dataset result suggest proposed model outperform state art reconstruction system', 'gaussian process regression observation model commonly assumed gaussian convenient computational perspective however drawback predictive accuracy model significantly compromised observation contaminated outlier robust observation model student distribution reduces influence outlying observation improves prediction problem however analytically intractable inference work discus property gaussian process regression model student likelihood utilize laplace approximation approximate inference compare approach variational approximation markov chain monte carlo scheme utilize commonly used scale mixture representation student distribution', 'formulate address problem discovering dynamic malicious region internet model problem one adaptively pruning known decision tree additional challenge severe space requirement since underlying decision tree billion leaf changing target function since malicious activity internet dynamic present novel algorithm address problem putting together number different expert algorithm online paging algorithm prove guarantee algorithm performance function best possible pruning similar size experiment show algorithm achieves high accuracy large real world data set significant improvement existing approach', 'existing method recognition object instance category based quantized local feature perform poorly local feature exist transparent surface glass plastic object characteristic pattern local appearance transparent object may well captured distance individual example local pattern codebook obtained vector quantization appearance transparent patch determined part refraction background pattern transparent medium energy background usually dominates patch appearance model transparent local patch appearance using additive model latent factor background factor due scene content factor capture local edge energy distribution characteristic refraction implement method using novel lda sift formulation performs lda prior vector quantization step discover latent topic characteristic particular transparent patch quantize sift space transparent visual word according latent topic dimension knowledge background scene required test time show example recognizing transparent glass domestic environment', 'introduce first temporal difference learning algorithm converge smooth value function approximators neural network conventional temporal difference td method td lambda q learning sarsa used successfully function approximation many application however well known policy sampling well nonlinear function approximation cause algorithm become unstable e parameter approximator may diverge sutton et al b solved problem policy learning linear td algorithm introducing new objective function related bellman error algorithm perform stochastic gradient descent function paper generalize work nonlinear function approximation present bellman error objective function two gradient descent td algorithm optimize prove asymptotic almost sure convergence algorithm finite markov decision process smooth value function approximator usual stochastic approximation condition computational complexity per iteration scale linearly number parameter approximator algorithm incremental guaranteed converge locally optimal solution', 'abstract missing', 'consider question computing maximum posteriori map assignment arbitrary pair wise markov random field mrf present randomized iterative algorithm based simple local update algorithm starting arbitrary initial assignment update iteration first picking random node selecting appropriately chosen random local neighborhood optimizing local neighborhood somewhat surprisingly show algorithm find near optimal assignment within n ln n iteration average high probability em n node pair wise mrf em geometry e mrf graph polynomial growth approximation error depending reasonable manner geometric growth rate graph average radius local neighborhood allows graceful tradeoff complexity algorithm approximation error extensive simulation show algorithm find extremely good approximate solution various kind mrfs geometry', 'prove linear projection distribution family fixed first second moment surjective regardless dimension extend result family respect additional constraint symmetry unimodality log concavity combining result classic univariate inequality provide new worst case analysis natural risk criterion arising different field one discovery portfolio selection worst case value risk conditional value risk criterion yield identical portfolio', 'provide clustering algorithm approximately optimizes k mean objective one pas streaming setting make assumption data algorithm light weight term memory computation setting applicable unsupervised learning massive data set resource constrained device two main ingredient theoretical work derivation extremely simple pseudo approximation batch algorithm k mean algorithm allowed output k center based recent k mean streaming clustering algorithm batch clustering algorithm performed small input fitting memory combined hierarchical manner empirical evaluation real simulated data reveal practical utility method', 'abstract missing', 'fundamental objective reinforcement learning maintenance proper balance exploration exploitation problem becomes challenging agent partially observe state environment paper propose dual policy method jointly learning agent behavior balance exploration exploitation partially observable environment method subsumes traditional exploration agent take action gather information environment active learning agent query oracle optimal action associated cost employing oracle form employed exploration dictated specific problem theoretical guarantee provided concerning optimality balancing exploration exploitation effectiveness method demonstrated experimental result benchmark problem', 'dependency among neighbouring label sequence important source information sequence labeling problem however dependency adjacent label commonly exploited practice high computational complexity typical inference algorithm longer distance dependency taken account paper show possible design efficient inference algorithm conditional random field using feature depend long consecutive label sequence high order feature long number distinct label sequence feature used small lead efficient learning algorithm conditional random field show experimentally exploiting dependency using high order feature lead substantial performance improvement problem discus condition high order feature effective', 'many researcher suggested psychological complexity concept related length representation language thought yet however concrete proposal nature language paper make one proposal language thought allows first order quantification quantification object readily second order quantification quantification feature support proposal present behavioral result concept learning study inspired work shepard hovland jenkins', 'regularized risk minimization often involves non smooth optimization either loss function e g hinge loss regularizer e g ell regularizer gradient descent method though highly scalable easy implement known converge slowly problem paper develop novel accelerated gradient method stochastic optimization still preserving computational simplicity scalability proposed algorithm called sage stochastic accelerated gradient exhibit fast convergence rate stochastic optimization convex strongly convex objective experimental result show sage faster recent sub gradient method including folos smidas scd moreover sage also extended online learning resulting simple powerful algorithm', 'study pool based active learning presence noise e agnostic setting previous work shown effectiveness agnostic active learning depends learning problem hypothesis space although many case active learning useful also easy construct example active learning algorithm advantage paper propose intuitively reasonable sufficient condition agnostic active learning algorithm strictly superior passive supervised learning show noise condition classification boundary underlying distribution smooth finite order active learning achieves polynomial improvement label complexity boundary distribution infinitely smooth improvement exponential', 'consider problem learning structure ising model pairwise binary markov random field sample several method proposed accomplish task relative merit limitation remain somewhat obscure analyzing number concrete example show low complexity algorithm systematically fail markov random field develops long range correlation precisely phenomenon appears related ising model phase transition although coincide', 'abstract missing', 'present approach learning stochastic geometric model object category single view image focus model expressible spatially contiguous assemblage block model topology learned across group image one topology linked object category e g chair fitting learned topology image used identify object class well detail geometry latter go beyond labeling object provides geometric structure particular instance learn model using joint statistical inference structure parameter camera parameter instance parameter produce image likelihood statistical imaging model use trans dimensional sampling explore topology hypothesis alternate metropolis hastings stochastic dynamic explore instance parameter experiment image furniture object table chair suggest effective approach learning model encode simple representation category geometry statistic thereof support inferring category geometry held single view image', 'show convex kl regularized objective function obtained pac bayes risk bound using convex loss function stochastic gibbs classifier upper bound standard zero one loss used weighted majority vote restricting class posterior call quasi uniform propose simple coordinate descent learning algorithm minimize proposed kl regularized cost function show standard ell p regularized objective function currently used ridge regression ell p regularized boosting obtained relaxation kl divergence quasi uniform posterior uniform prior present numerical experiment proposed learning algorithm generally outperforms ridge regression adaboost', 'develop convex relaxation maximum posteriori estimation mixture regression model although relaxation involves semidefinite matrix variable reformulate problem eliminate need general semidefinite programming particular provide two reformulations admit fast algorithm first max min spectral reformulation exploiting quasi newton descent second min min reformulation consisting fast alternating step closed form update evaluate method expectation maximization real problem motion segmentation video data', 'describe new algorithmic framework inference probabilistic model apply inference latent dirichlet allocation framework adopts methodology variational inference unlike existing variational method mean field expectation propagation restricted tractable class approximating distribution approach also viewed sequential monte carlo smc method unlike existing smc method need design artificial sequence distribution notably framework offer principled mean exchange variance importance sampling estimate bias incurred variational approximation experiment challenging inference problem population genetics demonstrate improvement stability accuracy existing method comparable cost', 'abstract missing', 'solving multi agent reinforcement learning problem proven difficult lack tractable algorithm provide first approximation algorithm solves stochastic game within epsilon relative error optimal game theoretic solution time polynomial epsilon algorithm extends murray gordon modified bellman equation determines emph set possible achievable utility provides u truly general framework multi agent learning empirically validate algorithm find computational cost order magnitude le theory predicts', 'kernel density estimation widely used practical method accurate nonparametric density estimation however long standing worst case theoretical result showing performance worsens exponentially dimension data quashed application modern high dimensional datasets decade practice recognized often data much lower dimensional intrinsic structure propose small modification kernel density estimation estimating probability density function riemannian submanifolds euclidean space using idea riemannian geometry prove consistency modified estimator show convergence rate determined intrinsic dimension submanifold conclude empirical result demonstrating behavior predicted theory', 'paper make several contribution towards accelerating approximate bayesian structural inference non decomposable ggms first contribution show efficiently compute bic laplace approximation marginal likelihood non decomposable graph using convex method precision matrix estimation optimization technique used fast scoring function inside standard stochastic local search sl generating posterior sample second contribution novel framework efficiently generating large set high quality graph topology without performing local search graph proposal method call neighborhood fusion nf sample candidate markov blanket node using sparse regression technique final contribution hybrid method combining complementary strength nf sl experimental result structural recovery prediction task demonstrate nf hybrid nf sl perform state art local search method synthetic real world datasets realistic computational limit imposed', 'multiple object tracking task commonly used investigate architecture human visual attention human participant show distinctive pattern success failure tracking experiment often attributed limit object system tracking module specialized cognitive structure use computational analysis task object tracking ask human failure arise cognitive limitation consequence inevitable perceptual uncertainty tracking task find many human performance phenomenon measured novel behavioral experiment naturally produced operation ideal observer model rao blackwelized particle filter tradeoff speed number object tracked however arise allocation flexible cognitive resource formalized either memory attention', 'paper proposes new algorithm linear least square problem unknown variable constrained finite set factor graph corresponds problem loopy fact complete graph hence applying belief propagation bp algorithm yield poor result algorithm described based optimal tree approximation gaussian density unconstrained linear system shown even though approximation directly applied exact discrete distribution applying bp algorithm modified factor graph outperforms current method term performance complexity improved performance proposed algorithm demonstrated problem mimo detection', 'abstract missing', 'score function induced generative model extract fixed dimension feature vector different length data observation subsuming process data generation projecting highly informative space called score space way standard discriminative classifier proved achieve higher performance solely generative discriminative approach paper present novel score space exploit free energy associated generative model score function function aim capturing uncertainty model learning local compliance data observation respect generative process theoretical justification convincing comparative classification result various generative model prove goodness proposed strategy', 'second order maximum entropy model recently gained much interest describing statistic binary spike train extend approach take continuous stimulus account well constraining joint second order statistic obtain joint gaussian boltzmann distribution continuous stimulus binary neural firing pattern also compute marginal conditional distribution model computational complexity pure binary model fitting data convex problem show model seen extension classical spike triggered average covariance analysis used non linear method extracting feature neural population sensitive calculating posterior distribution stimulus given observed neural response model used decode stimulus yield natural spike train metric therefore extending framework maximum entropy model continuous variable allows u gain novel insight relationship firing pattern neural ensemble stimulus processing', 'large relational factor graph structure defined first order logic language give rise notoriously difficult inference problem unrolling structure necessary represent distribution hypothesis exponential blow solution often derived mcmc however limitation design parameterization jump function sampling based method suffer local minimum system must transition lower scoring configuration arriving better map solution paper present new method explicitly selecting fruitful downward jump leveraging reinforcement learning rl rather setting parameter maximize likelihood training data parameter factor graph treated log linear function approximator learned temporal difference td map inference performed executing resulting policy held test data method allows efficient gradient update since factor neighborhood variable affected action need computed bypass need compute marginals entirely method provides dramatic empirical success producing new state art result complex joint model ontology alignment reduction error state art domain', 'indian buffet process bayesian nonparametric approach model object arising infinite number latent factor extend latent factor model framework two unbounded layer latent factor generative perspective layer defines conditional emph factorial prior distribution binary latent variable layer via noisy mechanism explore property model two empirical study one digit recognition task one music tag data experiment', 'propose new model natural image statistic instead minimizing dependency component natural image maximize simple form dependency form tree dependency learning filter tree structure best suited natural image observe resulting filter edge filter similar famous ica natural image result calculating likelihood model requires estimating squared output pair filter connected tree observe learning pair filter predominantly similar orientation different phase joint energy resembles model complex cell', 'present nonparametric hierarchical bayesian model document collection decouples sparsity smoothness component distribution e topic sparse topic model stm topic represented bank selector variable determine term appear topic thus topic associated subset vocabulary topic smoothness modeled subset develop efficient gibbs sampler stm includes general purpose method sampling dirichlet mixture combinatorial number component demonstrate stm four real world datasets compared traditional approach empirical result show stm give better predictive performance simpler inferred model', 'estimate changing structure varying coefficient varying structure vcvs model remains important open problem dynamic system modelling includes learning trajectory stock price uncovering topology evolving gene network paper investigate sparsistent learning sub family model piecewise constant vcvs model analyze two main issue problem inferring time point structural change occur estimating model structure e model selection constant segment propose two stage adaptive procedure first identifies jump point structural change identifies relevant covariates response segment provide asymptotic analysis procedure showing increasing sample size number structural change number variable true model consistently selected demonstrate performance method synthetic data apply brain computer interface dataset also consider applies structure estimation time varying probabilistic graphical model', 'method common spatio spectral pattern cssps extension common spatial pattern csps utilizing technique delay embedding alleviate adverse effect noise artifact electroencephalogram eeg classification although cssps method shown powerful csps method eeg classification method suitable two class eeg classification problem paper generalize two class cssps method multi class case end first develop novel theory multi class bayes error estimation present multi class cssps mcssps method based bayes error theoretical framework minimizing estimated closed form bayes error obtain optimal spatio spectral filter mcssps demonstrate effectiveness proposed method conduct extensive experiment data set bci competition experimental result show method significantly outperforms previous multi class csps mcsps method eeg classification', 'purpose paper explore connection multivariate homogeneity test auc optimization latter problem recently received much attention statistical learning literature elementary observation two sample problem setup null assumption corresponds situation area optimal roc curve equal propose two stage testing method based data splitting nearly optimal scoring function auc sense first learnt one two half sample data remaining half sample projected onto real line eventually ranked according scoring function computed first stage last step amount performing standard mann whitney wilcoxon test one dimensional framework show learning step procedure affect consistency test well property term power provided ranking produced accurate enough auc sense result numerical experiment eventually displayed order show efficiency method', 'linear correlation coefficient typically used characterize analyze dependency neural spike count show correlation coefficient general insufficient characterize dependency construct two neuron spike count model poisson like marginals vary dependence structure using copula end construct copula allows keep spike count uncorrelated varying dependence strength moreover employ network leaky integrate fire neuron investigate whether weakly correlated spike count strong dependency likely occur real network find entropy uncorrelated dependent spike count distribution deviate corresponding distribution independent component weakly correlated strongly dependent spike count likely occur biological network finally introduce test deciding whether dependence structure distribution poisson like marginals well characterized linear correlation coefficient verify different copula based model', 'abstract missing', 'investigate well gaussian process regression learn function defined graph using large regular random graph paradigmatic example random walk based kernel shown surprising property within standard approximation locally tree like graph structure kernel become constant e neighbouring function value become fully correlated lengthscale sigma kernel made large instead kernel attains non trivial limiting form calculate fully correlated limit reached loop become relevant estimate crossover regime occurs main subject learning curve bayes error versus training set size show qualitatively well predicted simple approximation using spectrum large tree input generically scale n v number training example per vertex also explore behaviour change kernel lengthscales large enough loop become important', 'synapsis exhibit extraordinary degree short term malleability release probability effective synaptic strength changing markedly multiple timescales perspective fixed computational operation network seems like unacceptable degree added noise suggest alternative theory according short term synaptic plasticity play normatively justifiable role theory start commonplace observation spiking neuron incomplete digital report analog quantity contains critical information namely membrane potential suggest one key task synapse solve inverse problem estimating pre synaptic membrane potential spike receives prior expectation recursive filter show short term synaptic depression canonical dynamic closely resemble required optimal estimation indeed support high quality estimation account local postsynaptic potential level synaptic resource track scaled mean variance estimated presynaptic membrane potential make experimentally testable prediction statistic subthreshold membrane potential fluctuation form spiking non linearity related property short term plasticity particular cell type', 'present theory compositionality stochastic optimal control showing task optimal controller constructed certain primitive primitive feedback controller pursuing agenda mixed proportion much progress making towards agenda compatible agenda present task resulting composite control law provably optimal problem belongs certain class class rather general yet number unique property one bellman equation made linear even non linear discrete dynamic give rise compositionality developed special case linear dynamic gaussian noise framework yield analytical solution e non linear mixture linear quadratic regulator without requiring final cost quadratic generally natural set control primitive constructed applying svd green function bellman equation illustrate theory context human arm movement idea optimality compositionality prominent field motor control yet hard reconcile work make possible', 'discus framework transductive support vector machine tsvm perspective regularization strength induced unlabeled data framework svm tsvm regarded learning machine without regularization one full regularization unlabeled data respectively therefore supplement framework regularization strength necessary introduce data dependant partial regularization end reformulate tsvm form controllable regularization strength includes svm tsvm special case furthermore introduce method adaptive regularization data dependant based smoothness assumption experiment set benchmark data set indicate promising result proposed work compared state art tsvm algorithm', 'problem approximating given probability distribution using simpler distribution play important role several area machine learning e g variational inference classification within context consider task learning mixture tree distribution although mixture tree learned minimizing kl divergence using em algorithm success depends heavily initialization propose efficient strategy obtaining good initial set tree attempt cover entire observed distribution minimizing alpha divergence alpha infty formulate problem using fractional covering framework present convergent sequential algorithm relies solving convex program iteration compared previous method approach result significantly smaller mixture tree provides similar better accuracy demonstrate usefulness approach learning pictorial structure face recognition', 'consider problem using nearest neighbor method provide conditional probability estimate p number label large label share underlying structure propose method learning error correcting output code ecocs model similarity label within nearest neighbor framework learned ecocs nearest neighbor information used provide conditional probability estimate apply estimate problem acoustic modeling speech recognition demonstrate absolute reduction word error rate wer relative reduction wer lecture recognition task state art baseline gmm model', 'availability importance relational data friendship summarized social networking website increase becomes increasingly important good model data kind latent structure considered use predicting link network relatively limited particular machine learning community focused latent class model adapting nonparametric bayesian method jointly infer many latent class learning entity belong class pursue similar approach richer kind latent variable latent feature using nonparametric bayesian technique simultaneously infer number feature time learn entity feature greater expressiveness approach allows u improve link prediction three datasets', 'paper study problem learning low dimensional sparse distance matrix propose novel metric learning model simultaneously conduct dimension reduction learn distance matrix sparse representation involves mixed norm regularization non convex show equivalently formulated convex saddle min max problem saddle representation develop efficient smooth optimization approach sparse metric learning although learning model based non differential loss function smooth optimization approach optimal convergence rate ell smooth problem ell iteration number finally run experiment validate effectiveness efficiency sparse metric learning model various datasets', 'present arow new online learning algorithm combine several property successful large margin training confidence weighting capacity handle non separable data arow performs adaptive regularization prediction function upon seeing new instance allowing perform especially well presence label noise derive mistake bound similar form second order perceptron bound assume separability also relate algorithm recent confidence weighted online learning technique empirically show arow achieves state art performance notable robustness case non separable data', 'existing model categorization typically represent classified item point multidimensional space mathematical point view infinite number basis set used represent point space choice basis set psychologically crucial people generally choose basis dimension strong preference generalize along ax dimension diagonally make choice dimension special explore idea dimension used people echo natural variation environment specifically present rational model assume dimension learns type dimensional generalization people display bias shaped exposing model many category structure hypothesized like child encounter model viewed type transformed dirichlet process mixture model learning base distribution dirichlet process allows dimensional generalization learning behaviour model capture developmental shift roughly isotropic child axis aligned generalization adult show', 'abstract missing', 'crucial technique scaling kernel method large data set reaching exceeding million instance based low rank approximation kernel matrix introduce new family algorithm based mixture nystrom approximation ensemble nystrom algorithm yield accurate low rank approximation standard nystrom method give detailed study multiple variant algorithm based simple averaging exponential weight method regression based method also present theoretical analysis algorithm including novel error bound guaranteeing better convergence rate standard nystrom method finally report result extensive experiment several data set containing point demonstrating signi cant performance improvement gained standard nystrom approximation', 'non parametric bayesian technique considered learning dictionary sparse image representation application denoising inpainting compressive sensing c beta process employed prior learning dictionary non parametric method naturally infers appropriate dictionary size dirichlet process probit stick breaking process also considered exploit structure within image proposed method learn sparse dictionary situ training image may exploited available required noise variance need known non stationary another virtue proposed method sequential inference readily employed thereby allowing scaling large image several example result presented using gibbs variational bayesian inference comparison state art approach', 'present new framework semi supervised learning sparse eigenfunction base kernel matrix turn emph cluster assumption hold high density region sufficiently separated low density valley high density area corresponds unique representative eigenvector linear combination eigenvectors precisely nystrom extension provide good candidate good classification function first choosing appropriate basis eigenvectors unlabeled data using labeled data lasso select classifier span eigenvectors obtain classifier sparse representation basis importantly sparsity appears naturally cluster assumption experimental result number real world data set show method competitive state art semi supervised learning algorithm outperforms natural base line algorithm lasso kernel pca basis', 'recent year dirichlet process associated chinese restaurant process crp found many application clustering indian buffet process ibp increasingly used describe latent feature model clustering case associate data point latent allocation variable latent variable share value induces partition data set crp prior distribution partition latent feature model associate data point potentially infinite number binary latent variable indicating possession feature ibp prior distribution associated infinite binary matrix prior distribution attractive ensure exchangeability sample propose extension model decomposable graph model appealing property easily learned using monte carlo technique', 'implementation topic model typically use symmetric dirichlet prior fixed concentration parameter implicit assumption smoothing parameter little practical effect paper explore several class structured prior topic model find asymmetric dirichlet prior document topic distribution substantial advantage symmetric prior asymmetric prior topic word distribution provides real benefit approximation prior structure simple efficient hyperparameter optimization step sufficient achieve performance gain prior structure advocate substantially increase robustness topic model variation number topic highly skewed word frequency distribution common natural language since prior structure implemented using efficient algorithm add negligible cost beyond standard inference technique recommend new standard topic modeling', 'little work done directly combine output multiple supervised unsupervised model however increase accuracy applicability ensemble method first boost diversity classification ensemble incorporating multiple clustering output provides grouping constraint joint label prediction set related object secondly ensemble supervised model limited application access raw data meta level model output paper aim calculating consolidated classification solution set object maximizing consensus among supervised prediction unsupervised grouping constraint seek global optimal label assignment target object different result traditional majority voting model combination approach cast problem optimization problem bipartite graph objective function favor smoothness conditional probability estimate graph well penalizes deviation initial labeling supervised model solve problem iterative propagation conditional probability estimate among neighboring node interpret method conducting constrained embedding transformed space well ranking graph experimental result three real application demonstrate benefit proposed method existing alternative', 'show model document bag word using family two layer undirected graphical model member family number binary hidden unit different number softmax visible unit softmax unit model family share weight binary hidden unit describe efficient inference learning procedure family member family model probability distribution document specific length product topic specific distribution rather mixture give much better generalization latent dirichlet allocation modeling log probability held document low dimensional topic vector learned undirected family also much better lda topic vector retrieving document similar query document learned topic general found lda precision achieved intersecting many general topic rather selecting single precise topic generate word', 'worst case complexity general decentralized pomdps equivalent partially observable stochastic game posgs high cooperative competitive case reduction complexity achieved exploiting independence relation model show result somewhat limited independence assumption relaxed small way complexity return general case', 'paper develop efficient moment based permutation test approach improve system efficiency approximating permutation distribution test statistic pearson distribution series approach involves calculation first four moment permutation distribution propose novel recursive method derive moment theoretically analytically without permutation experimental result using different test statistic demonstrated using simulated data real data proposed strategy take advantage nonparametric permutation test parametric pearson distribution approximation achieve accuracy efficiency', 'continuous time markov chain used model system transition state well time system spends state random many computational problem related chain solved including determining state distribution function time parameter estimation control however problem inferring likely trajectory trajectory sequence state well amount time spent state appears unsolved study three version problem initial value problem initial state given seek likely trajectory given final time ii boundary value problem initial final state time given seek likely trajectory connecting iii trajectory inference partial observability analogous finding maximum likelihood trajectory hidden markov model show maximum likelihood trajectory always well defined describe polynomial time test well definedness well definedness hold show three problem solved polynomial time develop efficient dynamic programming algorithm', 'abstract missing', 'propose unsupervised method given word automatically selects non abstract sens word online ontology generates image depicting corresponding entity faced task learning visual model based name object common approach find image web associated object name train visual classifier search result word generally polysemous approach lead relatively noisy model many example due outlier sens added model argue image associated abstract word sense excluded training visual classifier learn model physical object image clustering group together visually coherent set returned image difficult distinguish whether image cluster relates desired object abstract sense word propose method us image feature text associated image relate latent topic particular sens model require human supervision take input name object category show result retrieving concrete sense image two available multimodal multi sense database well experiment object classifier trained concrete sense image returned method set ten common office object', 'present system construct topological map environment given sequence image system includes novel image similarity score us dynamic programming match image using appearance relative position local feature simultaneously additionally mrf constructed model probability loop closure locally optimal labeling found using loopy bp finally outline method generate topological map loop closure data result presented four urban sequence one indoor sequence', 'visit following fundamental problem generic model consumer choice namely distribution preference list limited amount data consumer actually make decision marginal preference information may one predict revenue offering particular assortment choice problem central area within operation research marketing econometrics present framework answer question design number tractable algorithm data computational standpoint', 'consider problem learning probabilistic model complex relational structure various type object model help u understand dataset relational fact least two way finding interpretable structure data supporting prediction inference whether particular unobserved relation likely true often tradeoff two aim cluster based model yield easily interpretable representation factorization based approach better predictive performance large data set introduce bayesian clustered tensor factorization bctf model embeds factorized representation relation nonparametric bayesian clustering framework inference fully bayesian scale well large data set model simultaneously discovers interpretable cluster yield predictive performance match beat previous probabilistic model relational data', 'long standing problem efficient nearest neighbor nn search ubiquitous application ranging astrophysics mp fingerprinting bioinformatics movie recommendation dimensionality dataset increase exact nn search becomes computationally prohibitive eps distance approximate nn search provide large speedup risk losing meaning nn search present rank ordering distance paper present simple practical algorithm allowing user first time directly control true accuracy nn search term rank still achieving large speedup exact nn experiment high dimensional datasets show often achieves faster accurate result best known distance approximate method much stable behavior', 'paper explore problem biasing unsupervised model favor sparsity extend posterior regularization framework encourage model achieve posterior sparsity unlabeled training data apply new method learn rst order hmms unsupervised part speech po tagging show hmms learned way consistently signi cantly performs em trained hmms hmms sparsity inducing dirichlet prior trained variational em evaluate hmms three language english bulgarian portuguese four condition nd method always improves performance respect baseline variational bayes actually degrades performance case increase accuracy respect em absolute see improvement even semisupervised condition limited dictionary provided', 'describe probability distribution dubbed compressible prior whose independent identically distributed iid realization result compressible signal signal compressible sorted magnitude coefficient exhibit power law decay signal well approximated sparse signal since compressible signal live close sparse signal intrinsic information stably embedded via simple non adaptive linear projection much lower dimensional space whose dimension grows logarithmically ambient signal dimension using order statistic show n sample iid realization generalized pareto student log normal frechet log logistic distribution compressible e constant expected decay rate independent n contrast show generalized gaussian distribution shape parameter q compressible restricted case since expected decay rate n sample iid realization decrease n q log n q use compressible prior scaffold build new iterative sparse signal recovery algorithm based bayesian inference argument show tuning algorithm explicitly depends parameter compressible prior signal learn parameter signal compressible prior fly recovery', 'paper present novel approach learn directed acyclic graph dag factor model within framework also allowing model comparison purpose exploit connection factor model dag propose bayesian hierarchy based spike slab prior promote sparsity heavy tailed prior ensure identifiability predictive density perform model comparison require identifiability able produce variable ordering leading valid dag sparsity learn structure effectiveness approach demonstrated extensive experiment artificial biological data showing approach outperform number state art method', 'introduce new type neural network activation function based recent physiological rate model complex cell visual area v single hidden layer neural network kind model achieves error mnist also introduce existing criterion learning slow decorrelated feature pretraining strategy image model pretraining strategy result orientation selective feature similar receptive field complex cell pretraining single hidden layer model achieves better generalization error even though pretraining sample distribution different fine tuning distribution implement pretraining strategy derive fast algorithm online learning decorrelated feature iteration algorithm run linear time respect number feature', 'conditional random field crf quite successful sequence labeling task natural language processing biological sequence analysis crf model use linear potential function represent relationship input feature output however many real world application protein structure prediction handwriting recognition relationship input feature output highly complex nonlinear cannot accurately modeled linear function model nonlinear relationship input feature output propose conditional neural field cnf new conditional probabilistic graphical model sequence labeling cnf model extends crf adding one possibly several middle layer input feature output middle layer consists number hidden parameterized gate acting local neural network node feature extractor capture nonlinear relationship input feature output therefore conceptually cnf model much expressive linear crf model better control complexity cnf model also present hyperparameter optimization procedure within evidence framework experiment two widely used benchmark indicate cnf model performs significantly better number popular method particular cnf model best among ten machine learning method protein secondary tructure prediction also among best method handwriting recognition', 'abstract missing', 'across wide range cognitive task recent experience uences behavior example individual repeatedly perform simple two alternative forced choice task afc response latency vary dramatically based immediately preceding trial sequence sequential effect interpreted adaptation statistical structure uncertain changing environment e g jones sieck mozer kinoshita shettel yu cohen dynamic belief model dbm yu cohen explains sequential effect afc task rational consequence dynamic internal representation track second order statistic trial sequence repetition rate predicts whether upcoming trial repetition alternation previous trial experimental result suggest rst order statistic base rate also uence sequential effect propose model learns rst second order sequence property according basic principle dbm uni ed inferential framework model dynamic belief mixture model dbm obtains precise parsimonious t data furthermore model predicts dissociation behavioral maloney dal martello sahm spillmann electrophysiological study jentzsch sommer supporting psychological neurobiological reality two component', 'consider online decision problem discrete space loss function submodular give algorithm computationally efficient hannan consistent full information bandit setting', 'introduce new type deep belief net evaluate object recognition task top level model third order boltzmann machine trained using hybrid algorithm combine generative discriminative gradient performance evaluated norb database normalized uniform version contains stereo pair image object different lighting condition viewpoint model achieves error test set close best published result norb using convolutional neural net built knowledge translation invariance substantially outperforms shallow model svms dbns especially suited semi supervised learning demonstrate consider modified version norb recognition task additional unlabeled image created applying small translation image database extra unlabeled data amount labeled data model achieves error making current best result norb', 'adapt probabilistic latent variable model namely gap gamma poisson ad targeting context sponsored search s behaviorally targeted bt display advertising also approach important problem ad positional bias formulating one latent dimension gap factorization learning click data intrinsically large scale even ad scale algorithm terabyte real world s bt data contains hundred million user hundred thousand feature leveraging scalability characteristic algorithm inherent structure problem including data sparsity locality specifically demonstrate two somewhat orthogonal philosophy scaling algorithm large scale problem s bt implementation respectively finally report experimental result using yahoo vast datasets show approach substantially outperform state art method prediction accuracy bt particular roc area achieved gap exceeding one prior approach using poisson regression yielded computational performance compare single node sparse implementation parallel implementation using hadoop mapreduce result counterintuitive yet quite interesting therefore provide insight underlying principle large scale learning', 'visual recognition image frequently modeled set local feature bag show bag word common method handle case viewed special match kernel count two local feature fall region partitioned visual word otherwise despite simplicity quantization coarse therefore appealing design match kernel accurately measure similarity local feature however impractical use kernel large datasets due significant computational cost address problem propose efficient match kernel emk map local feature low dimensional feature space average resulting feature vector form set level feature apply linear classifier local feature map learned inner product preserve best possible value specified kernel function emk linear number image number local feature demonstrate emk extremely efficient achieves current state art performance three difficult real world datasets scene caltech caltech', 'paper introduces new method semi supervised learning high dimensional nonlinear manifold includes phase unsupervised basis learning phase supervised function learning learned base provide set anchor point form local coordinate system data point x manifold locally approximated linear combination nearby anchor point linear weight become local coordinate coding show high dimensional nonlinear function approximated global linear function respect coding scheme approximation quality ensured locality coding method turn difficult nonlinear learning problem simple global linear learning problem overcomes drawback traditional local learning method', 'present general inference framework inter domain gaussian process gps focusing usefulness build sparse gp model state art sparse gp model introduced snelson ghahramani relies finding small representative pseudo data set element domain n available data element able explain existing data well us perform inference reduces inference model selection computation time n n n inter domain gps used find possibly compact representative set feature lying different domain computational cost able specify different domain representative feature allows incorporate prior knowledge relevant characteristic data detaches functional form covariance basis function show previously existing model fit framework use develop two new sparse gp model test large representative regression data set suggest significant improvement achieved retaining computational efficiency', 'automated recovery failure key component management large data center system typically employ hand made controller created expert controller capture many important aspect recovery process often systematically optimized reduce cost server downtime paper explain use data gathered interaction hand made controller system create optimized controller suggest learning indefinite horizon partially observable markov decision process model decision making uncertainty solve using point based algorithm describe complete process starting data gathering model learning model checking procedure computing policy paper focus specific domain method applicable system use hand coded imperfect controller', 'consider problem variable group selection least square regression namely selecting group variable best regression performance leveraging adhering natural grouping structure within explanatory variable show problem efficiently addressed using certain greedy style algorithm precisely propose group orthogonal matching pursuit algorithm group omp extends standard omp procedure also referred forward greedy feature selection algorithm least square regression perform stage wise group variable selection prove certain condition group omp identify correct group variable also provide upperbound l infty norm difference estimated regression coefficient true coefficient experimental result simulated real world datasets indicate group omp compare favorably group lasso omp lasso term variable selection prediction accuracy', 'paper concerned consistency analysis listwise ranking method among various ranking method listwise method competitive performance benchmark datasets regarded one state art approach listwise ranking method manage optimize ranking whole list permutation object however practical application information retrieval correct ranking top k position much important paper aim analyze whether existing listwise ranking method statistically consistent top k setting purpose define top k ranking framework true loss thus risk defined basis top k subgroup permutation framework include permutation level ranking framework proposed previous work special case based new framework derive sufficient condition listwise ranking method consistent top k true loss show effective way modifying surrogate loss function existing method satisfy condition experimental result show modification method work significantly better original version', 'abstract missing', 'motivated real world problem like object categorization study particular mixed norm regularization multiple kernel learning mkl assumed given set kernel grouped distinct component component crucial learning task hand formulation hence employ l infty regularization promoting combination component level l regularization promoting sparsity among kernel component previous attempt formulated non convex problem formulation given instance non smooth convex optimization problem admits efficient mirror descent md based procedure md procedure optimizes product simplexes well studied case literature result real world datasets show new mkl formulation well suited object categorization task md based algorithm outperforms state art mkl solver like texttt simplemkl term computational effort', 'training conditional maximum entropy model massive data requires significant time computational resource paper investigate three common distributed training strategy distributed gradient majority voting ensemble parameter mixture analyze worst case runtime resource cost present theoretical foundation convergence parameter parameter mixture efficient strategy present large scale experiment comparing different strategy demonstrate parameter mixture independent model use fewer resource achieve comparable loss compared standard approach', 'consider regularized stochastic learning online optimization problem objective function sum two convex term one loss function learning task simple regularization term l norm sparsity develop new online algorithm regularized dual averaging method explicitly exploit regularization structure online setting particular iteration learning variable adjusted solving simple optimization problem involves running average past subgradients loss function whole regularization term subgradient method achieves optimal convergence rate often enjoys low complexity per iteration similar standard stochastic gradient method computational experiment presented special case sparse online learning using l regularization', 'study problem decision theoretic online learning dtol motivated practical application focus dtol number action large previous algorithm learning framework tunable learning rate parameter major barrier using online learning practical application understood set parameter optimally particularly number action large paper offer clean solution proposing novel completely parameter free algorithm dtol addition introduce new notion regret natural application large number action show algorithm achieves good performance respect new notion regret addition also achieves performance close best bound achieved previous algorithm optimally tuned parameter according previous notion regret', 'develop algorithm efficient range search notion dissimilarity given bregman divergence range search task return point potentially large database within specified distance query arises many learning algorithm locally weighted regression kernel density estimation neighborhood graph based algorithm task like outlier detection information retrieval metric space efficient range search like algorithm based spatial data structure deployed variety statistical task describe first algorithm range search arbitrary bregman divergence broad class dissimilarity measure includes relative entropy mahalanobis distance itakura saito divergence variety matrix divergence metric method cannot directly applied since bregman divergence general satisfy triangle inequality derive geometric property bregman divergence yield efficient algorithm range search based recently proposed space decomposition bregman divergence', 'propose new sketch recognition framework combine rich representation low level visual appearance graphical model capturing high level relationship symbol joint model appearance context allows framework le sensitive noise drawing variation improving accuracy robustness result recognizer better able handle wide range drawing style found messy freehand sketch evaluate work two real world domain molecular diagram electrical circuit diagram show combined approach significantly improves recognition performance', 'last decade model complexity received lot press many method proposed jointly measure model descriptive adequacy complexity measure exist measure complexity moreover existing measure ignore parameter prior inherent part model affect complexity paper present stand alone measure model complexity take number parameter functional form range parameter parameter prior account prior predictive complexity ppc intuitive easy compute measure start observation model complexity property model enables fit wide range outcome ppc measure wide range exactly', 'image segmented first using classifier predict affinity graph reflects degree image pixel must grouped together partitioning graph yield segmentation machine learning applied affinity classifier produce affinity graph good sense minimizing edge misclassification rate however error measure indirectly related quality segmentation produced ultimately partitioning affinity graph present first machine learning algorithm training classifier produce affinity graph good sense producing segmentation directly minimize rand index well known segmentation performance measure rand index measure segmentation performance quantifying classification connectivity image pixel pair segmentation using simple graph partitioning algorithm finding connected component thresholded affinity graph able train affinity classifier directly minimize rand index segmentation resulting graph partitioning learning algorithm corresponds learning maximin affinity image pixel pair predictive pixel pair connectivity', 'online learning algorithm impressive convergence property come risk minimization convex game large problem however inherently sequential design prevents taking advantage modern multi core architecture paper prove online learning delayed update converges well thereby facilitating parallel online learning', 'paper study forward greedy strategy sparse nonparametric regression additive model propose algorithm called additive forward regression general multivariate regression propose algorithm called generalized forward regression simultaneously conduct estimation variable selection nonparametric setting high dimensional sparse learning problem main emphasis empirical simulated real data two simple greedy method clearly outperform several state art competitor including lasso nonparametric version lasso called sparse additive model spam recently proposed adaptive parametric forward backward algorithm called foba theoretical justification also provided', 'abstract missing', 'cur decomposition provides approximation matrix x low reconstruction error sparse sense resulting approximation lie span column x regard appears similar many sparse pca method however cur take randomized algorithmic approach whereas sparse pca method framed convex optimization problem paper try understand cur sparse optimization viewpoint particular show cur implicitly optimizing sparse regression objective furthermore cannot directly cast sparse pca method observe sparsity attained cur posse interesting structure lead u formulate sparse pca method achieves cur like sparsity', 'commute distance two vertex graph expected time take random walk travel first second vertex back study behavior commute distance size underlying graph increase prove commute distance converges expression take account structure graph completely meaningless distance function graph consequently use raw commute distance machine learning purpose strongly discouraged large graph high dimension alternative introduce amplified commute distance corrects undesired large sample effect', 'accurate short term wind forecast stwfs time horizon hour essential efficient integration wind power electrical power grid physical model based numerical weather prediction currently competitive research machine learning approach ongoing two major challenge confronting effort missing observation weather regime induced dependency shift among wind variable geographically distributed site paper introduce approach address challenge describe new regime aware approach stwf use auto regressive hidden markov model ar hmm subclass conditional linear gaussian clg model although ar hmms natural representation weather regime clg model general exact inference np hard observation missing lerner parr high cost introduce simple approximate inference method ar hmms believe application sequential temporal problem domain involve continuous variable empirical evaluation publicly available wind data two geographically distinct region approach make significantly accurate prediction baseline model uncovers meteorologically relevant regime', 'introduce new family online learning algorithm based upon constraining velocity flow distribution weight vector particular show effectively herd gaussian weight vector distribution trading velocity constraint loss function uniformly bounding loss function demonstrate solve resulting optimization analytically compare resulting algorithm variety real world datasets demonstrate algorithm achieve state art robust performance especially high label noise training data', 'establish excess risk bound h r n sqrt h l r n erm h smooth loss function hypothesis class rademacher complexity r n l best risk achievable hypothesis class typical hypothesis class r n sqrt r n translates learning rate rh n separable l case rh n sqrt l rh n generally also provide similar guarantee online stochastic convex optimization smooth non negative objective', 'describe log bilinear model computes class probability combining input vector multiplicatively vector binary latent variable even though latent variable take exponentially many possible combination value efficiently compute exact probability class marginalizing latent variable make possible get exact gradient log likelihood bilinear score function defined using three dimensional weight tensor show factorizing tensor allows model encode invariance inherent task learning dictionary invariant basis function experiment set benchmark problem show fully probabilistic model achieve classification performance competitive kernel svms backpropagation deep belief net', 'consider online binary classification problem given classifier stage classifier map input probability input belongs positive class online classification meta algorithm algorithm combine output classifier order attain certain goal without prior knowledge form statistic input without prior knowledge performance given classifier paper use sensitivity specificity performance metric meta algorithm particular goal design algorithm satisfies following two property asymptotically average false positive rate fp rate given threshold ii average true positive rate tp rate worse tp rate best convex combination given classifier satisfies fp rate constraint hindsight show problem fact special case regret minimization problem constraint therefore goal attainable hence pose relaxed goal propose corresponding practical online learning meta algorithm attains case two classifier show algorithm take simple form best knowledge first algorithm address problem average tp rate maximization average fp rate constraint online setting', 'identify investigate strong connection probabilistic inference differential privacy latter recent privacy definition permit indirect observation data noisy measurement previous research differential privacy focused designing measurement process whose output likely useful consider potential applying probabilistic inference measurement measurement process derive posterior distribution data set model parameter thereof find probabilistic inference improve accuracy integrate multiple observation measure uncertainty even provide posterior distribution quantity directly measured', 'paper explores link basis construction method markov decision process power series expansion value function perspective provides useful framework analyze property existing base well provides insight constructing effective base krylov bellman error base based neumann series expansion base incur large initial bellman error converge rather slowly discount factor approach unity laurent series expansion relates discounted average reward formulation provides explanation slow convergence well suggests way construct efficient basis representation first two term laurent series represent scaled average reward average adjusted sum reward subsequent term expand discounted value function using power generalized inverse called drazin group inverse singular matrix derived transition matrix experiment show drazin base converge considerably quickly several base particularly large value discount factor incremental variant drazin base called bellman average reward base barb described provides benefit lower computational cost', 'probabilistic graphical model use local factor represent dependence among set variable many problem domain instance climatology epidemiology addition local dependency may also wish model heavy tailed statistic extreme deviation treated outlier specifying distribution using graphical model probability density function pdfs generally lead intractable inference learning cumulative distribution network cdns provide mean tractably specify multivariate heavy tailed model product cumulative distribution function cdfs currently algorithm inference learning correspond computing mixed derivative exact tree structured graph graph arbitrary topology efficient algorithm needed take advantage sparse structure model unlike symbolic differentiation program mathematica present algorithm recursively decomposing computation derivative cdns arbitrary topology decomposition naturally described using junction tree compare performance resulting algorithm mathematica apply method learning model rainfall h n data show cdns cycle able provide significantly better fit data compared tree structured unstructured cdns heavy tailed multivariate distribution multivariate copula logistic model', 'abstract missing', 'abstract missing', 'many complex system ranging neural cell assembly insect society involve rely division labor enforce division decentralized distributed way tackled paper using spiking neuron network architecture specifically spatio temporal model called spikeants shown enforce emergence synchronized activity ant colony ant modelled two spiking neuron ant colony sparsely connected spiking neuron network ant make decision among foraging sleeping self grooming competition two neuron signal received neighbor ant interestingly three type temporal pattern emerge ant colony asynchronous synchronous synchronous periodic foraging activity similar actual behavior living ant colony phase diagram emergent activity pattern respect two control parameter respectively accounting ant sociability receptivity presented discussed', 'paper discus topic dimensionality reduction k mean clustering prove set n point dimension row matrix rr n time projected omega k eps dimension eps n lceil eps k log rceil time constant probability optimal k partition point set preserved within factor eps projection done post multiplying time random matrix r entry sqrt sqrt equal probability numerical implementation technique experiment large face image dataset verify speed accuracy theoretical result', 'develop online variational bayes vb algorithm latent dirichlet allocation lda online lda based online stochastic optimization natural gradient step show converges local optimum vb objective function handily analyze massive document collection including arriving stream study performance online lda several way including fitting topic topic model article wikipedia single pas demonstrate online lda find topic model good better found batch vb fraction time', 'introduce cst algorithm constructing skill tree demonstration trajectory continuous reinforcement learning domain cst us changepoint detection method segment trajectory skill chain detecting change appropriate abstraction segment complex model single skill skill chain trajectory merged form skill tree demonstrate cst construct appropriate skill tree refined learning challenging continuous domain used segment demonstration trajectory mobile manipulator chain skill skill assigned appropriate abstraction', 'minimizing rank matrix subject affine constraint fundamental problem many important application machine learning statistic paper propose simple fast algorithm svp singular value projection rank minimization affine constraint armp show svp recovers minimum rank solution affine constraint satisfy restricted isometry property rip method guarantee geometric convergence rate even presence noise requires strictly weaker assumption rip constant existing method also introduce newton step svp framework speed convergence substantial empirical gain next address practically important application armp problem low rank matrix completion defining affine constraint directly obey rip hence guarantee svp hold however provide partial progress towards proof exact recovery algorithm showing restricted isometry property observe empirically algorithm recovers low rank incoherent matrix almost optimal number uniformly sampled entry also demonstrate empirically algorithm outperform existing method cite caics leeb b keshavanom armp matrix completion problem order magnitude also robust noise sampling scheme particular result show svp newton method significantly robust noise performs impressively realistic power law sampling scheme matrix completion problem', 'distribution unlabeled data feature space lie along manifold information provides may used learner assist classification semi supervised setting manifold learning well known machine learning use manifold human learning largely unstudied perform set experiment test human ability use manifold semi supervised learning task varying condition show human may encouraged using manifold overcoming strong preference simple axis parallel linear boundary', 'paper concerned rank aggregation aim combine multiple input ranking get better ranking popular approach rank aggregation based probabilistic model permutation e g luce model mallow model however model limitation either poor expressiveness high computational complexity avoid limitation paper propose new model defined coset permutation distance model generation permutation stagewise process refer new model coset permutation distance based stagewise cps model cps model rich expressiveness therefore used versatile application many different permutation distance used induce coset permutation distance complexity cps model low stagewise decomposition permutation probability efficient computation coset permutation distance apply cps model supervised rank aggregation derive learning inference algorithm empirically study effectiveness efficiency experiment public datasets show derived algorithm based cps model achieve state art ranking accuracy much efficient previous algorithm', 'dimensionality reduction commonly used setting multi label supervised classification control learning capacity provide meaningful representation data introduce simple forward probabilistic model multinomial extension reduced rank regression show model provides probabilistic interpretation discriminative clustering method added benefit term number hyperparameters optimization expectation maximization em algorithm commonly used learn model optimization usually lead local minimum relies non convex cost function many local minimum avoid problem introduce local approximation cost function lead quadratic non convex optimization problem product simplices order minimize function propose efficient algorithm based convex relaxation low rank representation data allows deal large instance experiment text document classification show new model outperforms supervised dimensionality reduction method simulation unsupervised clustering show probabilistic formulation better property existing discriminative clustering method', 'define data dependent permutation complexity hypothesis set math hset similar rademacher complexity maximum discrepancy permutation complexity based like maximum discrepancy dependent sampling prove uniform bound generalization error well concentration result mean permutation estimate efficiently estimated', 'given ensemble distinct low level segmentation image goal identify visually meaningful segment ensemble knowledge specific object surface present image available selection image region occupied object formalized maximum weight independent set mwis problem mwis heaviest subset mutually non adjacent node attributed graph construct graph segment ensemble mwis selects maximally distinctive segment together partition image new mwis algorithm presented algorithm seek solution directly discrete domain instead relaxing mwis continuous problem common previous work iteratively find candidate discrete solution taylor series expansion original mwis objective function around previous solution algorithm shown converge maximum empirical evaluation benchmark berkeley segmentation dataset show new algorithm eliminates need hand picking optimal input parameter state art segmenters outperforms best manually optimized result', 'abstract missing', 'human vision system able effortlessly perceive short range long range motion pattern complex dynamic scene previous work assumed two different mechanism involved processing two type motion paper propose hierarchical model unified framework modeling short range long range motion perception model consists two key component data likelihood proposes multiple motion hypothesis using nonlinear matching hierarchical prior imposes slowness spatial smoothness constraint motion field multiple scale tested model two type stimulus random dot kinematograms multiple aperture stimulus commonly used human vision research demonstrate hierarchical model adequately account human performance psychophysical experiment', 'consider problem discovering link evolving undirected graph given series past snapshot graph graph observed time sequence adjacency matrix presence edge observed absence edge certain snapshot cannot distinguished missing entry adjacency matrix additional information provided examining dynamic graph set topological feature degree vertex develop novel methodology building static matrix completion method estimation future state relevant graph feature procedure relies formulation optimization problem approximately solved fast alternating linearized algorithm whose property examined show experiment simulated real data reveal interest methodology', 'present model describes structure response different brain area set stimulus term stimulus category cluster stimulus functional unit cluster voxels assume voxels within unit respond similarly stimulus category design nonparametric hierarchical model capture inter subject variability among unit model explicitly capture relationship brain activation fmri time course variational inference algorithm derived based model learn category unit set unit category activation probability data applied data fmri study object recognition method find meaningful consistent clustering stimulus category voxels unit', 'paper propose approximated learning framework large scale graphical model derive message passing algorithm learning parameter efficiently first relate crfs structured svms show crf primal variant log partition function known soft max smoothly approximates hinge loss function structured svms propose intuitive approximation structured prediction problem using fenchel duality based local entropy approximation computes exact gradient approximated problem guaranteed converge unlike existing approach allow u learn graphical model cycle large number parameter efficiently demonstrate effectiveness approach image denoising task task previously solved sharing parameter across clique contrast algorithm able efficiently learn large number parameter resulting order magnitude better prediction', 'support vector machine svm increasingly used brain image analysis since allow capturing complex multivariate relationship data moreover kernel linear svms used localize spatial pattern discrimination two group subject however feature spatial distribution taken account consequence optimal margin hyperplane often scattered lack spatial coherence making anatomical interpretation difficult paper introduces framework spatially regularize svm brain image analysis show laplacian regularization provides flexible framework integrate various type constraint applied cortical surface brain image proposed framework applied classification mr image based gray matter concentration map cortical thickness measure patient alzheimer disease elderly control result demonstrate proposed method enables natural spatial anatomical regularization classifier', 'determining whether someone talking application many area speech recognition speaker diarization social robotics facial expression recognition human computer interaction one popular approach problem audio visual synchrony detection candidate speaker deemed talking visual signal around speaker correlate auditory signal show proper visual feature case movement various facial muscle group accurate detector speech created use audio signal show person independent visual detector used train accurate audio based person dependent voice model voice model advantage able identify particular person speaking even visible camera e g case mobile robot moreover show simple sensory fusion scheme auditory visual model improves performance task talking detection work provides dramatic evidence efficacy two different approach multimodal speech detection challenging database', 'undirected graphical model encode graph g dependency structure random vector many application interest model given another random vector x input refer problem estimating graph g x conditioned x x graph valued regression paper propose semiparametric method estimating g x build tree x space cart classification regression tree leaf tree estimate graph call method graph optimized cart go cart study theoretical property go cart using dyadic partitioning tree establishing oracle inequality risk minimization tree partition consistency also demonstrate application go cart meteorological dataset showing graph valued regression provide useful tool analyzing complex data', 'stimulated complex action potential sequence synapsis exhibit spike timing dependent plasticity stdp attenuated enhanced pre postsynaptic contribution long term synaptic modification order investigate functional consequence contribution dynamic cd propose minimal model formulated term differential equation find model reproduces wide range experimental result small number biophysically interpretable parameter model allows investigate susceptibility stdp arbitrary time course pre postsynaptic activity e nonlinear filter property demonstrate simple example small periodic modulation pre postsynaptic firing rate model solved predicts synaptic strengthening synchronous rate modulation low baseline rate modification dominant theta frequency range result underline well known relevance theta activity hippocampus cortex learning also find emphasis low baseline spike rate suppression high baseline rate latter suggests mechanism network activity regulation inherent stdp furthermore novel formulation provides general framework investigating joint dynamic neuronal activity cd stdp spike based well rate based neuronal network model', 'goal inverse reinforcement learning find reward function markov decision process given example trace optimal policy current irl technique generally rely user supplied feature form concise basis reward present algorithm instead construct reward feature large collection component feature building logical conjunction component feature relevant example policy given example trace algorithm return reward function well constructed feature reward function used recover full deterministic stationary policy feature used transplant reward function novel environment component feature well defined', 'recently batch mode active learning attracted lot attention paper propose novel batch mode active learning approach selects batch query iteration maximizing natural form mutual information criterion labeled unlabeled instance employing gaussian process framework mutual information based instance selection problem formulated matrix partition problem although matrix partition np hard combinatorial optimization problem show good local solution obtained exploiting effective local optimization technique relaxed continuous optimization problem proposed active learning approach independent employed classification model empirical study show approach achieve comparable superior performance discriminative batch mode active learning method', 'abstract missing', 'multi label classification task predicting potentially multiple label given instance common several application image annotation document classification gene function prediction paper present formulation problem based reverse prediction predict set instance given label viewing problem perspective popular quality measure assessing performance multi label classification admit relaxation efficiently optimised optimise relaxation standard algorithm compare result several state art method showing excellent performance', 'problem learning predict structured label key importance many application however general graph structure learning inference setting intractable show possible circumvent difficulty input distribution rich enough via method similar spirit pseudo likelihood show new method achieves consistency illustrate empirically indeed performs well exact method sufficiently large training set used', 'likelihood ratio policy gradient method successful reinforcement learning algorithm especially learning physical system describe likelihood ratio policy gradient derived importance sampling perspective derivation highlight likelihood ratio method use past experience using past experience estimate em gradient expected return u theta current policy parameterization theta rather obtain complete estimate u theta b using past experience current policy em rather using past experience improve estimate present new policy search method leverage observation well generalized baseline new technique generalizes commonly used baseline technique policy gradient method algorithm outperforms standard likelihood ratio policy gradient algorithm several testbeds', 'latent variable model powerful tool addressing several task machine learning however algorithm learning parameter latent variable model prone getting stuck bad local optimum alleviate problem build intuition rather considering sample simultaneously algorithm presented training data meaningful order facilitates learning order sample determined easy main challenge often provided readily computable measure easiness sample address issue proposing novel iterative self paced learning algorithm iteration simultaneously selects easy sample learns new parameter vector number sample selected governed weight annealed entire training data considered empirically demonstrate self paced learning algorithm outperforms state art method learning latent structural svm four application object localization noun phrase coreference motif finding handwritten digit recognition', 'remarkably easy implementation guaranteed convergence made em algorithm one used algorithm mixture modeling downside e step linear sample size number mixture component making impractical large scale data based variational em framework propose fast alternative us component specific data partition obtain sub linear e step sample size algorithm still maintains provable convergence approach build previous work significantly faster scale much better number mixture component demonstrate speedup experiment large scale synthetic real data', 'cast problem identifying basic block code binary executable learning mapping byte sequence segmentation sequence general inference segmentation model semi crfs cubic length sequence taking advantage structure problem derive linear time inference algorithm make approach practical given even small program ten hundred thousand byte long furthermore introduce two loss function appropriate problem show use structural svms optimize learned mapping loss finally present experimental result demonstrate advantage method strong baseline', 'multiple instance learning long known hard non convex problem work propose approach recasts convex likelihood ratio estimation problem firstly constraint multiple instance learning reformulated convex constraint likelihood ratio show joint estimation likelihood ratio function likelihood training instance learned convexly theoretically prove quantitative relationship risk estimated classification loss loss function likelihood ratio estimation shown likelihood ratio estimation generally good surrogate loss separate positive negative instance well however joint estimation tends underestimate likelihood example positive propose use likelihood ratio estimate feature learn linear combination classify bag experiment synthetic real datasets show superiority approach', 'consider markov decision process value parameter uncertain uncertainty described sequence nested set set contains previous one corresponds probabilistic guarantee different confidence level set admissible probability distribution unknown parameter specified formulation model case decision maker aware want exploit yet imprecise priori information distribution parameter arises naturally practice method estimate confidence region parameter abound propose decision criterion based distributional robustness optimal policy maximizes expected total reward adversarial probability distribution realization uncertain parameter admissible e agrees priori information show finding optimal distributionally robust policy reduced standard robust mdp parameter belong single uncertainty set hence computed polynomial time mild technical condition', 'extend logistic regression using exponential family introduced recently statistical physic give rise regularized risk minimization problem non convex loss function efficient block coordinate descent optimization scheme derived estimating parameter nature loss function algorithm tolerant label noise furthermore unlike algorithm employ non convex loss function algorithm fairly robust choice initial value verify observation empirically number synthetic real datasets', 'paper proposes principled extension traditional single layer flat sparse coding scheme two layer coding scheme derived based theoretical analysis nonlinear functional approximation extends recent result local coordinate coding two layer approach easily generalized deeper structure hierarchical multiple layer manner empirically shown deep coding approach yield improved performance benchmark datasets', 'abstract missing', 'sparse coding recently become popular approach computer vision learn dictionary natural image paper extend sparse coding learn interpretable spatio temporal primitive human motion cast problem learning spatio temporal primitive tensor factorization problem introduce constraint learn interpretable primitive particular use group norm tensor diagonal constraint activation well smoothness constraint inherent human motion demonstrate effectiveness approach learn interpretable representation human motion motion capture data show approach outperforms recently developed matching pursuit sparse coding algorithm', 'consider tree structured group lasso structure feature represented tree leaf node feature internal node cluster feature structured regularization pre defined tree structure based group lasso penalty one group defined node tree regularization help uncover structured sparsity desirable application meaningful tree structure feature however tree structured group lasso challenging solve due complex regularization paper develop efficient algorithm tree structured group lasso one key step proposed algorithm solve moreau yosida regularization associated grouped tree structure main technical contribution paper include show associated moreau yosida regularization admits analytical solution develop efficient algorithm determining effective interval regularization parameter experimental result ar jaffe face data set demonstrate efficiency effectiveness proposed algorithm', 'pose transductive classification matrix completion problem assuming underlying matrix low rank formulation able handle three problem simultaneously multi label learning item one label ii transduction label unspecified iii missing data large number feature missing obtained satisfactory result several real world task suggesting low rank assumption may restrictive seems method allows different loss function apply feature label entry matrix resulting nuclear norm minimization problem solved modified fixed point continuation method guaranteed find global optimum', 'sparse method supervised learning aim finding good linear predictor variable possible e small cardinality support combinatorial selection problem often turned convex optimization problem replacing cardinality function convex envelope tightest convex lower bound case l norm paper investigate general set function cardinality may incorporate prior knowledge structural constraint common many application namely show nondecreasing submodular set function corresponding convex envelope obtained lovasz extension common tool submodular analysis defines family polyhedral norm provide generic algorithmic tool subgradients proximal operator theoretical result condition support recovery high dimensional inference selecting specific submodular function give new interpretation known norm based rank statistic grouped norm potentially overlapping group also define new norm particular one used non factorial prior supervised learning', 'although dirichlet distribution widely used independence structure component limit accuracy model proposed shadow dirichlet distribution manipulates support order model probability mass function pmfs dependency constraint often arise real world problem regularized pmfs monotonic pmfs pmfs bounded variation describe property new class distribution provide maximum entropy construction give expectation maximization method estimating mean parameter illustrate real data', 'multi task learning mtl improves prediction performance multiple different related learning problem shared parameter representation one prominent multi task learning algorithm extension svms evgeniou et al although elegant multi task svm inherently restricted fact support vector machine require class addressed explicitly weight vector multi task setting requires different learning task share set class paper proposes alternative formulation multi task learning extending recently published large margin nearest neighbor lmnn algorithm mtl paradigm instead relying separating hyperplanes decision function based nearest neighbor rule inherently extends many class becomes natural fit multitask learning evaluate resulting multi task lmnn real world insurance data speech classification problem show consistently outperforms single task knn several metric state art mtl classifier', 'robust regression classification often thought require non convex loss function prevent scalable global training however view neglect possibility reformulated training method yield practically solvable alternative natural way make loss function robust outlier truncate loss value exceed maximum threshold demonstrate relaxation form loss clipping made globally solvable applicable standard loss guaranteeing robustness outlier present generic procedure applied standard loss function demonstrate improved robustness regression classification problem', 'intelligent agent often faced need choose action uncertain consequence modify action according ongoing sensory processing changing task demand requisite ability dynamically modify cancel planned action known inhibitory control psychology formalize inhibitory control rational decision making problem apply classical stop signal task using bayesian inference stochastic control tool show optimal policy systematically depends various parameter problem relative cost different action choice noise level sensory input dynamic changing environmental demand normative model account range behavioral data human animal stop signal task suggesting brain implement statistically optimal dynamically adaptive reward sensitive decision making context inhibitory control problem', 'sequence memoizer model sequence data state art performance language modeling compression propose number improvement model inference algorithm including enlarged range hyperparameters memory efficient representation inference algorithm operating new representation derivation based precise definition various process also allow u provide elementary proof mysterious coagulation fragmentation property used original paper sequence memoizer wood et al present experimental result supporting improvement', 'neuronal connection weight exhibit short term depression std present study investigates impact std dynamic continuous attractor neural network cann potential role neural information processing find network std generate static traveling bump std enhances performance network tracking external input particular find std endows network slow decaying plateau behavior namely network initially stimulated active state decay silence slowly time scale std rather neural signaling argue provides mechanism neural system hold short term memory easily shut persistent activity naturally', 'abstract missing', 'present technique exact simulation gaussian markov random field gmrfs interpreted locally injecting noise gaussian factor independently followed computing mean mode perturbed gmrf coupled standard iterative technique solution symmetric positive definite system yield efficient sampling algorithm essentially linear complexity term speed memory requirement well suited extremely large scale probabilistic model apart synthesizing data gaussian model proposed technique directly lead efficient unbiased estimator marginal variance beyond gaussian model proposed algorithm also useful handling highly non gaussian continuously valued mrfs arising statistical image modeling first layer deep belief network describing real valued data non quadratic potential coupling different site represented finite infinite mixture gaussians help local distributed latent mixture assignment variable bayesian treatment model naturally involves block gibbs sampler alternately draw sample conditionally independent latent mixture assignment conditionally multivariate gaussian continuous vector show directly benefit proposed method', 'multi instance learning two kind prediction failure e false negative false positive current research mainly focus avoding former attempt utilize geometric distribution instance inside positive bag avoid former latter based kernel principal component analysis define projection constraint positive bag classify constituent instance far away separating hyperplane place positive instance negative instance opposite side apply constrained concave convex procedure solve resulted problem empirical result demonstrate approach offer improved generalization performance', 'continuous markov random field general formalism model joint probability distribution event continuous outcome prove marginal computation constrained continuous mrfs p hard general present polynomial time approximation scheme mild assumption structure random field moreover introduce sampling algorithm compute marginal distribution develop novel technique increase efficiency continuous mrfs general purpose probabilistic modeling tool demonstrate applied statistical relational learning problem collective classification evaluate algorithm show standard deviation marginals serf useful measure confidence', 'bayesian approach utility elicitation typically adopt myopic expected value information evoi natural criterion selecting query however evoi optimization usually computationally prohibitive paper examine evoi optimization using emph choice query query user ask select preferred product set show general assumption optimal choice query w r evoi coincides emph optimal recommendation set set maximizing expected utility user selection since recommendation set optimization simpler submodular problem greatly reduce complexity exact approximate greedy computation optimal choice query also examine case user response choice query error prone using constant follow mixed multinomial logit noise model provide worst case guarantee finally present local search technique work well large outcome space', 'conventional dynamic bayesian network dbns based homogeneous markov assumption restrictive many practical application various approach relax homogeneity assumption therefore proposed last year present paper aim improve flexibility two recent version non homogeneous dbns either suffer need data discretization ii assume time invariant network structure allowing network structure fully flexible lead risk overfitting inflated inference uncertainty though especially highly topical field system biology independent measurement tend sparse present paper investigate three conceptually different regularization scheme based inter segment information sharing ass performance comparative evaluation study based simulated data compare predicted segmentation gene expression time series obtained embryogenesis drosophila melanogaster state art technique conclude evaluation application synthetic biology objective predict known regulatory network five gene saccharomyces cerevisiae', 'method computing rarity latent fingerprint represented minutia given allows determining probability finding match evidence print database n known print probability random correspondence evidence database determined three procedural step registration step latent print aligned finding core point done using procedure based machine learning approach based gaussian process evidence probability evaluation step generative model based bayesian network used determine probability evidence take account dependency minutia nearby minutia confidence presence evidence specific probability random correspondence step evidence probability used determine probability match among n given tolerance last evaluation similar birthday correspondence probability specific birthday generative model validated using goodness fit test evaluated standard database fingerprint probability random correspondence several latent fingerprint evaluated varying number minutia', 'paper present bayesian non parametric model simultaneously learn segment word phoneme string learn referent word show synergistic interaction acquisition two kind linguistic information model novel kind adaptor grammar extension embedding topic model pcfgs model simultaneously segment phoneme sequence word learn relationship non linguistic object word refer show modelling inter word dependency improves accuracy word segmentation also word object relationship ii model simultaneously learns word object relationship word segmentation segment accurately one learns word segmentation argue result support interactive view language acquisition take advantage synergy', 'propose new variational em algorithm fitting factor analysis model mixed continuous categorical observation algorithm based simple quadratic bound log sum exp function special case fully observed binary data bound propose significantly faster previous variational method show em significantly robust presence missing data compared treating latent factor parameter approach used exponential family pca related matrix factorization method benefit variational approach easily extended case mixture factor analyzer show present result synthetic real data set demonstrating several desirable property proposed method', 'speculated human motion system combine noisy measurement prior expectation optimal rational manner basic goal work discover experimentally prior distribution used specifically seek infer functional form motion prior performance human subject motion estimation task restricted prior combine three term motion slowness first order smoothness second order smoothness focused two functional form prior distribution l norm l norm regularization corresponding gaussian laplace distribution respectively first experimental session estimate weight three term functional form maximize fit human performance measured human performance motion task found obtained better fit l norm laplace l norm gaussian note l norm also better fit statistic motion natural environment addition found large weight second order smoothness term indicating importance high order smoothness compared slowness lower order smoothness validate result used best fit model using l norm predict human performance second session different experimental setup result showed excellent agreement human performance model prediction ranging five human subject ten experimental condition give support human visual system us l norm laplace prior', 'heavy tailed distribution naturally occur many real life problem unfortunately typically possible compute inference closed form graphical model involve heavy tailed distribution work propose novel simple linear graphical model independent latent random variable called linear characteristic model lcm defined characteristic function domain using stable distribution heavy tailed family distribution generalization cauchy l evy gaussian distribution show first time compute exact approximate inference linear multivariate graphical model lcm limited stable distribution fact lcm always defined random variable discrete continuous mixture provide realistic problem field computer network demonstrate applicability construction potential application iterative decoding linear channel non gaussian noise', 'abstract missing', 'diffusion network dn stochastic recurrent network shown capable modeling distribution continuous valued continuous time path however dynamic dn governed stochastic differential equation making dn unfavourable simulation digital computer paper present implementation dn analogue large scale integration enabling dn simulated real time moreover log domain representation applied dn allowing supply voltage thus power consumption reduced without limiting dynamic range diffusion process vlsi chip containing dn two stochastic unit designed fabricated design component circuit described simulation full system presented simulation result demonstrate dn vlsi able regenerate various type continuous path real time', 'communication speaker hearer efficient party make accurate inference study inference communication television game called password speaker must convey secret word hearer providing one word clue working hypothesis human communication relatively efficient use game show data examine three prediction first predict speaker hearer considerate take perspective account second predict speaker hearer calibrated make accurate assumption strategy used finally predict speaker hearer collaborative tend share cognitive burden communication equally find evidence support three prediction demonstrate addition efficient communication tends break speaker hearer placed time pressure', 'propose new approach value function approximation combine linear temporal difference reinforcement learning subspace identification practical application reinforcement learning rl complicated fact state either high dimensional partially observable therefore rl method designed work feature state rather state success failure learning often determined suitability selected feature comparison subspace identification ssid method designed select feature set preserve much information possible state paper connect two approach looking problem reinforcement learning large set feature may marginally useful value function approximation introduce new algorithm situation called predictive state temporal difference pstd learning ssid predictive state representation pstd find linear compression operator project large set feature small set preserve maximum amount predictive information rl pstd us bellman recursion estimate value function discus connection pstd prior approach rl ssid prove pstd statistically consistent perform several experiment illustrate property demonstrate potential difficult optimal stopping problem', 'recent approach multi view learning shown factorizing information part shared across view part private view could effectively account dependency independency different input modality unfortunately approach involve minimizing non convex objective function paper propose approach learning factorized representation inspired sparse coding technique particular show structured sparsity allows u address multi view learning problem alternately solving two convex optimization problem furthermore resulting factorized latent space generalize existing approach allow latent dimension shared subset view instead view show approach outperforms state art method task human pose estimation', 'paper point exist scaling initialization problem existing multiple kernel learning mkl approach employ large margin principle jointly learn kernel svm classifier reason margin well describe good kernel due negligence scaling use ratio margin radius minimum enclosing ball measure goodness kernel present new minimization formulation kernel learning formulation invariant scaling learned kernel learning linear combination basis kernel also invariant scaling basis kernel type e g l l norm constraint combination coefficient establish differentiability formulation propose gradient projection algorithm kernel learning experiment show method significantly outperforms svm uniform combination basis kernel state art mkl approach', 'study problem segmenting specific white matter structure interest diffusion tensor dt mr image human brain important requirement many neuroimaging study instance evaluate whether brain structure exhibit group level difference function disease set image typically interactive expert guided segmentation method choice application tedious large datasets common today address problem endow image segmentation algorithm advice encoding global characteristic region want extract accomplished constructing using expert segmented image epitome specific region histogram bag word e g suitable feature descriptor given representation problem reduces segmenting new brain image additional constraint enforce consistency segmented foreground pre specified histogram feature present combinatorial approximation algorithm incorporate domain specific constraint markov random field mrf segmentation making use recent result image co segmentation derive effective solution strategy problem provide analysis solution quality present promising experimental evidence showing many structure interest neuroscience extracted reliably brain image volume using algorithm', 'present copula bayesian network model representing multivariate continuous distribution approach build novel copula based parameterization conditional density joined graph encodes independency offer great flexibility modeling high dimensional density maintaining control form univariate marginals demonstrate advantage framework generalization standard bayesian network well tree structured copula model varied real life domain substantially higher dimension typically considered copula literature', 'network model widely used capture interaction among component complex system social biological understand behavior often necessary analyze functionally related component system corresponding subsystem therefore analysis subnetworks may provide additional insight behavior system evident individual component propose novel approach incorporating available network information analysis arbitrary subnetworks proposed method offer efficient dimension reduction strategy using laplacian eigenmaps neumann boundary condition provides flexible inference framework analysis subnetworks based group penalized principal component regression model graph asymptotic property proposed inference method well choice tuning parameter control false positive rate discussed high dimensional setting performance proposed methodology illustrated using simulated real data example biology', 'hypothesis high dimensional data tends lie vicinity low dimensional manifold basis collection methodology termed manifold learning paper study statistical aspect question fitting manifold nearly optimal least squared error given upper bound dimension volume curvature show empirical risk minimization produce nearly optimal manifold using number random sample independent ambient dimension space data lie obtain upper bound required number sample depends polynomially curvature exponentially intrinsic dimension linearly intrinsic volume constant error prove matching minimax lower bound sample complexity show dependence intrinsic dimension volume curvature unavoidable whether known lower bound frac k eps frac log frac de eps sample complexity empirical risk minimization k mean applied data unit ball arbitrary dimension tight open question since cite bart eps desired bound error de bound probability failure improve best currently known upper bound cite pontil frac k eps frac log frac de eps left frac k eps left min left k frac log frac k eps eps right right frac log frac de eps right based result devise simple algorithm k mean another us family convex program fit piecewise linear curve specified length high dimensional data sample complexity independent ambient dimension', 'develop deterministic single pas algorithm latent dirichlet allocation lda order process received document one time discard excess text stream algorithm need store old statistic data proposed algorithm much faster batch algorithm comparable batch algorithm term perplexity experiment', 'abstract missing', 'learning using privileged information lupi paradigm along standard training data decision space teacher supply learner privileged information correcting space goal learner find classifier low generalization error decision space consider new version empirical risk minimization algorithm called privileged erm take account privileged information order find good function decision space outline condition correcting space satisfied allow privileged erm much faster learning rate decision space one regular empirical risk minimization', 'long standing open research problem use information different experiment including background knowledge infer causal relation recent development shown way use multiple data set provided originate identical experiment present mci algorithm first method infer provably valid causal relation large sample limit different experiment fast reliable produce clear easily interpretable output based result show constraint based causal discovery decomposable candidate pair identification subsequent elimination step applied separately different model test algorithm variety synthetic input model set ass behavior quality output method show promising sign adapted suit causal discovery real world application area well including large database', 'consider bandit problem motivated application online advertising news story selection learner must repeatedly select slate subset size k possible action receives reward selected action goal minimize regret respect total reward best slate computed hindsight consider unordered ordered version problem give efficient algorithm regret sqrt constant depends specific nature problem also consider version problem access number policy make recommendation slate every round give algorithm sqrt regret competing best policy well make use technique relative entropy projection combined usual multiplicative weight update algorithm obtain algorithm', 'present generative probabilistic model learning general graph structure term concept graph text concept graph provide visual summary thematic content collection document task difficult accomplish using keyword search proposed model learn different type concept graph structure capable utilizing partial prior knowledge graph structure well labeled document describe generative model based stick breaking process graph markov chain monte carlo inference procedure experiment simulated data show model recover known graph structure learning unsupervised semi supervised mode also show proposed model competitive term empirical log likelihood existing structure based topic model hpam hlda real world text data set finally illustrate application model problem updating wikipedia category graph', 'stochastic environment well known reinforcement learning algorithm q learning performs poorly poor performance caused large overestimation action value overestimation result positive bias introduced q learning us maximum action value approximation maximum expected action value introduce alternative way approximate maximum expected value set random variable obtained double estimator method shown sometimes underestimate rather overestimate maximum expected value apply double estimator q learning construct double q learning new policy reinforcement learning algorithm show new algorithm converges optimal policy performs well setting q learning performs poorly due overestimation', 'consider class learning problem involve structured sparsity inducing norm defined sum ell infty norm group variable whereas lot effort put developing fast optimization method group disjoint embedded specific hierarchical structure address case general overlapping group end show corresponding optimization problem related network flow optimization precisely proximal problem associated norm consider dual quadratic min cost flow problem propose efficient procedure computes solution exactly polynomial time algorithm scale million group variable open whole new range application structured sparse model present several experiment image video data demonstrating applicability scalability approach various problem', 'challenging problem estimating high dimensional graphical model choose regularization parameter data dependent way standard technique include k fold cross validation k cv akaike information criterion aic bayesian information criterion bic though method work well low dimensional problem suitable high dimensional setting paper present star new stability based method choosing regularization parameter high dimensional inference undirected graph method clear interpretation use least amount regularization simultaneously make graph sparse replicable random sampling interpretation requires essentially condition mild condition show star partially sparsistent term graph estimation e high probability true edge included selected model even graph size asymptotically increase sample size empirically performance star compared state art model selection procedure including k cv aic bic synthetic data real microarray dataset star outperforms competing procedure', 'generalized linear model glms increasingly popular framework modeling neural spike train linked theory stochastic point process researcher used relation ass goodness fit using method point process theory e g time rescaling theorem however high neural firing rate coarse discretization lead breakdown assumption necessary connection show goodness fit test point process theory still applied glms constructing equivalent surrogate point process time series observation furthermore two additional test based thinning complementing point process introduced augment instrument available checking model adequacy point process well discretized model', 'propose discriminative latent model annotating image unaligned object level textual annotation instead using bag word image representation currently popular computer vision community model explicitly capture intricate relationship underlying visual textual information particular model mapping translates image region annotation mapping allows u relate image region corresponding annotation term also model overall scene label latent information allows u cluster test image training data consist image associated annotation access ground truth region annotation mapping overall scene label develop novel variant latent svm framework model latent variable experimental result demonstrate effectiveness proposed model compared baseline method', 'present novel probabilistic model distribution set structure example set sequence tree graph critical characteristic model preference diversity set containing dissimilar structure likely model marriage structured probabilistic model like markov random field context free grammar determinantal point process arise quantum physic model particle repulsive interaction extend determinantal point process model handle exponentially sized set particle structure via natural factorization model part show factorization lead tractable algorithm exact inference including computing marginals computing conditional probability sampling algorithm exploit novel polynomially sized dual representation determinantal point process use message passing special semiring compute relevant quantity illustrate advantage model tracking articulated pose estimation problem', 'abstract missing', 'sodium entry action potential determines energy efficiency neuron classic hodgkin huxley model action potential generation notoriously inefficient regard time charge flowing membrane theoretical minimum required achieve observed depolarization yet recent experimental result show mammalian neuron close optimal metabolic efficiency dynamic voltage gated channel significantly different one exhibited classic hodgkin huxley model action potential nevertheless original hodgkin huxley model still widely used rarely model squid giant axon extracted introduce novel family hodgkin huxley model correctly account sodium entry action potential width whose voltage gated channel display dynamic similar recent experimental observation mammalian neuron speak family model model parameterized unique parameter variation allow reproduce entire range experimental observation cortical pyramidal neuron purkinje cell yielding economical framework model wide range different central neuron present paper demonstrates performance discus property new family model', 'partially observable markov decision process pomdps model sequential decision making problem uncertainty partial observability unfortunately problem cannot modeled state dependent reward function e g problem whose objective explicitly implies reducing uncertainty state end introduce rho pomdps extension pomdps reward function rho depends belief state show common assumption rho convex value function also convex make possible approximate rho arbitrarily well piecewise linear convex pwlc function use state art exact approximate solving algorithm limited change', 'propose computationally efficient random walk convex body rapidly mix time varying gibbs distribution setting online convex optimization repeated game algorithm yield low regret present novel efficient method implementing mixture forecasting strategy', 'consider least square regression using randomly generated subspace g p subset f finite dimension p f function space infinite dimension e g l g p defined span p random feature linear combination basis function f weighted random gaussian coefficient particular consider multi resolution random combination scale given mother function hat function wavelet latter case resulting gaussian object called em scrambled wavelet show enable approximate function sobolev space h result given n data least square estimate hat g built p scrambled wavelet excess risk f hat g p f h log n p p log n n target function f h smoothness order interesting aspect resulting bound depend distribution p data generated important statistical regression setting considered randomization enables adapt possible distribution conclude describing efficient numerical implementation using lazy expansion numerical complexity tilde n log n n dimension input space', 'deal problem variable selection variable must selected group wise possibly overlapping group defined priori particular propose new optimization procedure solving regularized algorithm presented jacob et al group lasso penalty generalized overlapping group variable jacob et al proposed implementation requires explicit replication variable belonging one group iterative procedure based combination proximal method primal space constrained newton method reduced dual space corresponding active group procedure provides scalable alternative need data duplication allows deal high dimensional problem without pre processing reduce dimensionality data computational advantage scheme respect state art algorithm using data duplication shown empirically numerical simulation', 'probabilistic grammar generative statistical model useful compositional sequential structure present framework reminiscent structural risk minimization empirical risk minimization parameter fixed probabilistic grammar using log loss derive sample complexity bound framework apply supervised setting unsupervised setting', 'paper describes probabilistic framework studying association multiple genotype biomarkers phenotypic trait presence noise unobserved confounders large genetic study framework build sparse linear method developed regression modified inferring causal structure richer network latent variable method motivated use genotype instrument infer causal association phenotypic biomarkers outcome without making common restrictive assumption instrumental variable method method may used effective screening potentially interesting genotype phenotype biomarker phenotype association genome wide study may important implication validating biomarkers possible proxy endpoint early stage clinical trial biomarkers gene transcript method used fine mapping quantitative trait locus qtls detected genetic linkage study method applied examining effect gene transcript level liver plasma hdl cholesterol level sample sequenced mouse heterogeneous stock sim genetic instrument sim time gene transcript', 'provide sound consistent foundation use emph nonrandom exploration data contextual bandit partially labeled setting value chosen action learned primary challenge variety setting exploration policy offline data logged explicitly known prior solution require either control action learning process recorded random exploration action chosen obliviously repeated manner technique reported lift restriction allowing learning policy choosing action given feature historical data randomization occurred logged empirically verify solution two reasonably sized set real world data obtained internet online advertising company', 'study worst case bound quality fixed point assignment max product algorithm markov random field mrf start proving bound independent mrf structure parameter afterwards show bound improved mrfs particular structure bipartite graph grid result provide interesting insight behavior max product example prove max product provides good result least optimal mrfs large variable disjoint cycle mrfs cycle variable disjoint namely share edge cycle contains least variable', 'motivated application unsupervised part speech tagging present algorithm euclidean embedding large set categorical data based co occurrence statistic use code model globerson et al constrain embedding lie high dimensional unit sphere constraint allows efficient optimization even case large datasets high embedding dimensionality using k mean clustering embedded data approach efficiently produce state art result analyze reason sphere constraint beneficial application conjecture reason might apply quite generally large scale task', 'abstract missing', 'recent proposal suggest large generic neuronal network could store memory trace past input sequence instantaneous state proposal raise important theoretical question duration memory trace dependence network size connectivity signal statistic prior work case gaussian input sequence linear neuronal network show duration memory trace network cannot exceed number neuron unit neuronal time constant network perform equivalent feedforward network however ethologically relevant scenario sparse input sequence scenario show linear neural network essentially perform compressed sensing c past input thereby attaining memory capacity exceeds number neuron enhanced capacity achieved class orthogonal recurrent network feedforward network generic recurrent network exploit technique statistical physic disordered system analytically compute decay memory trace network function network size signal sparsity integration time alternately viewed purely perspective c work introduces new ensemble measurement matrix derived dynamical system provides theoretical analysis asymptotic performance', 'study learning curve gaussian process regression characterise performance term bayes error averaged datasets given size whilst learning curve general difficult calculate show discrete input domain similarity input point characterised term graph accurate prediction obtained fact become exact large graph drawn broad range random graph ensemble arbitrary degree distribution input node connected finite number others method based translating appropriate belief propagation equation graph ensemble demonstrate accuracy prediction poisson erdos renyi regular random graph discus previous approximation learning curve fail', 'determination dominant orientation given image location formulated decision theoretic question lead novel measure dominance given orientation theta similar used sift shown new measure computed network implement sequence operation standard neurophysiological model v measure thus seen biologically plausible version sift denoted biosift network unit shown exhibit trademark property v neuron cross orientation suppression sparseness independence connection sift biological vision provides justification success sift like feature reinforces importance contrast normalization computer vision illustrate replacing gabor unit hmax network new biosift unit shown lead significant gain classification task leading state art performance among biologically inspired network model performance competitive best non biological object recognition system', 'recent experimental work suggested neural firing rate interpreted fractional derivative least signal variation induces neural adaptation show actual neural spike train considered fractional derivative provided neural signal approximated sum power law kernel simple standard thresholding spiking neuron suffices carry approximation given suitable refractory response empirically find online approximation signal sum power law kernel beneficial encoding signal slowly varying component like long memory self similar signal signal online power law kernel approximation typically required le half number spike similar snr compared sum similar exponentially decaying kernel power law kernel accurately approximated using sum cascade weighted exponential demonstrate corresponding decoding spike train receiving neuron allows natural transparent temporal signal filtering tuning weight decoding kernel', 'many statistical estimator based convex optimization problem formed weighted sum loss function norm based regularizer analyze convergence rate first order gradient method solving problem within high dimensional framework allows data dimension grow possibly exceed sample size n high dimensional structure precludes usual global assumption namely strong convexity smoothness condition underlie classical optimization analysis define appropriately restricted version condition show satisfied high probability various statistical model condition theory guarantee nesterov first order method cite nesterov globally geometric rate convergence statistical precision model meaning typical euclidean distance true unknown parameter theta optimal solution widehat theta globally linear rate substantially faster previous analysis global convergence specific method yielded sublinear rate analysis applies wide range estimator statistical model including sparse linear regression using lasso ell regularized regression group lasso block sparsity low rank matrix recovery using nuclear norm regularization overall result reveals interesting connection statistical precision computational efficiency high dimensional estimation', 'objective train p norm multiple kernel learning mkl generally linear mkl regularised bregman divergence using sequential minimal optimization smo algorithm smo algorithm simple easy implement adapt efficiently scale large problem result gained widespread acceptance svms routinely trained using smo diverse real world application training using smo long standing goal mkl reason unfortunately standard mkl dual differentiable therefore optimised using smo style co ordinate ascent paper demonstrate linear mkl regularised p norm squared certain bregman divergence indeed trained using smo resulting algorithm retains simplicity efficiency significantly faster state art specialised p norm mkl solver show train hundred thousand kernel approximately seven minute fifty thousand point le half hour single core', 'present fast online solver large scale maximum flow problem occur portfolio optimization inventory management computer vision logistics algorithm solves integer linear program online fashion exploit total unimodularity constraint matrix lagrangian relaxation solve problem convex online game algorithm generates approximate solution max flow problem performing stochastic gradient descent set flow apply algorithm optimize tier arrangement million web page layered set cache serve incoming query stream optimally provide empirical demonstration effectiveness method real query page data', 'paper propose efficient algorithm estimating natural policy gradient parameter based exploration algorithm sample directly parameter space unlike previous method based natural gradient algorithm calculates natural policy gradient using inverse exact fisher information matrix computational cost algorithm equal conventional policy gradient whereas previous natural policy gradient method prohibitive computational cost experimental result show proposed method outperforms several policy gradient method', 'feature selection important component many machine learning application especially many bioinformatics task efficient robust feature selection method desired extract meaningful feature eliminate noisy one paper propose new robust feature selection method emphasizing joint norm minimization loss function regularization norm based loss function robust outlier data point norm regularization selects feature across data point joint sparsity efficient algorithm introduced proved convergence regression based objective make feature selection process efficient method applied genomic proteomic biomarkers discovery extensive empirical study performed six data set demonstrate effectiveness feature selection method', 'application brain machine interface typically estimate user intent based biological signal voluntary control example might want estimate patient paralyzed arm want move based residual muscle activity solve problem necessary integrate obtained information time state art approach typically use probabilistic model state e g position velocity arm evolves time called trajectory model wanted develop approach using two intuitive insight given point time may small set likely movement target potentially identified location object workspace gaze information user user may want produce movement varying speed thus use generative model trajectory model incorporating insight approximate inference generative model implemented using mixture extended kalman filter find resulting algorithm allows u decode arm movement dramatically better use trajectory model linear dynamic', 'abstract missing', 'propose algorithm perform multitask learning task potentially distinct label set label correspondence readily available contrast existing method either assume label set shared different task exists label mapping oracle method directly maximizes mutual information among label show resulting objective function efficiently optimized using existing algorithm proposed approach direct application data integration different label space purpose classification integrating yahoo dmoz web directory', 'sample complexity active learning realizability assumption well studied realizability assumption however rarely hold practice paper theoretically characterize sample complexity active learning non realizable case multi view setting prove unbounded tsybakov noise sample complexity multi view active learning widetilde log frac epsilon contrasting single view setting polynomial improvement best possible achievement also prove general multi view setting sample complexity active learning unbounded tsybakov noise widetilde frac epsilon order epsilon independent parameter tsybakov noise contrasting previous polynomial bound order epsilon related parameter tsybakov noise', 'consider reinforcement learning partially observable domain agent query expert demonstration nonparametric bayesian approach combine model knowledge inferred expert information independent exploration policy knowledge inferred expert trajectory introduce prior bias agent towards model simple representation simple policy resulting improved policy model learning', 'consider multivariate regression problem involving high dimensional predictor response space efficiently address problem propose variable selection method multivariate group orthogonal matching pursuit extends standard orthogonal matching pursuit technique account arbitrary sparsity pattern induced domain specific grouping input output variable also taking advantage correlation may exist multiple output illustrate utility framework inferring causal relationship collection high dimensional time series variable applied time evolving social medium content model yield new family causality based influence measure may seen alternative pagerank theoretical guarantee extensive simulation empirical study confirm generality value framework', 'consider problem reinforcement learning high dimensional space number feature bigger number sample particular study least square temporal difference lstd learning algorithm space low dimension generated random projection high dimensional space provide thorough theoretical analysis lstd random projection derive performance bound resulting algorithm also show error lstd random projection propagated iteration policy iteration algorithm provide performance bound resulting least square policy iteration lspi algorithm', 'describe accelerated hardware neuron capable emulating adap tive exponential integrate fire neuron model firing pattern membrane stimulated step current analyzed transistor level simulation silicon prototype chip neuron destined hardware neuron highly integrated wafer scale system reaching new computational paradigm opening new experimentation possibility neuron dedicated universal device neuroscientific experiment focus lay parameterizability reproduction analytical model', 'heavy tailed distribution often used enhance robustness regression classification method outlier output space often however confronted outlier input space isolated observation sparsely populated region show heavy tailed process prior construct gaussian process via copula used improve robustness regression classification estimator outlier selectively shrinking strongly sparse region dense region carry theoretical analysis show selective shrinkage occurs provided marginals heavy tailed process sufficiently heavy tail analysis complemented experiment biological data indicate significant improvement estimate sparse region producing competitive result dense region', 'propose class sparse coding model utilizes laplacian scale mixture lsm prior model dependency among coefficient coefficient modeled laplacian distribution variable scale parameter gamma distribution prior scale parameter show due conjugacy gamma prior possible derive efficient inference procedure coefficient scale parameter scale parameter group coefficient combined single variable possible describe dependency occur due common amplitude fluctuation among coefficient shown constitute large fraction redundancy natural image show consequence group sparse coding resulting inference coefficient follows divisive normalization rule may efficiently implemented network architecture similar proposed occur primary visual cortex also demonstrate improvement image coding compressive sensing recovery using lsm model', 'dimensionality reduction often needed many application due high dimensionality data involved paper first analyze scatter measure used conventional linear discriminant analysis lda model note formulation based average case view based analysis propose new dimensionality reduction method called worst case linear discriminant analysis wlda defining new class within class scatter measure new model adopts worst case view arguably suitable application classification number training data point number feature large relax optimization problem involved formulate metric learning problem otherwise take greedy approach finding one direction transformation time moreover also analyze special case wlda show relationship conventional lda experiment conducted several benchmark datasets demonstrate effectiveness wlda compared related dimensionality reduction method', 'address problem estimating f measure given model accurately possible fixed labeling budget problem occurs whenever estimate cannot obtained held training data instance data used train model held back reason privacy reflect test distribution case new test instance drawn labeled cost active estimation procedure selects instance according instrumental sampling distribution analysis source estimation error lead optimal sampling distribution minimizes estimator variance explore condition active estimate f measure accurate estimate based instance sampled test distribution', 'abstract missing', 'abstract missing', 'abstract missing', 'regularization technique become principle tool statistic machine learning research practice however situation regularization term well interpreted especially related loss function data paper propose robust minimax framework interpret relationship data regularization term large class loss function show various regularization term essentially corresponding different distortion original data matrix minimax framework includes ridge regression lasso elastic net fused lasso group lasso local coordinate coding multiple kernel learning etc special case within minimax framework gave mathematically exact definition novel representation called sparse grouping representation sgr proved sufficient condition generating group level sparsity sufficient condition large set consistent regularization term designed sgr essentially different group lasso way using class group information outperforms group lasso appears group label noise also gave generalization bound classification setting', 'latent force model encode interaction multiple related dynamical system form kernel covariance function variable modeled represented output differential equation differential equation driven weighted sum latent function uncertainty given gaussian process prior paper consider employing latent force model framework problem determining robot motor primitive deal discontinuity dynamical system latent driving force introduce extension basic latent force model switch different latent function potentially different dynamical system creates versatile representation robot movement capture discrete change non linearity dynamic give illustrative example synthetic data striking movement recorded using barrett wam robot haptic input device inspiration robot motor primitive expect model wide application dynamical system including model human motion capture data system biology', 'present simple effective approach learning tractable conditional random field structure depends evidence approach retains advantage tractable discriminative model namely efficient exact inference exact parameter learning time algorithm suffer large expressive power penalty inherent fixed tractable structure real life relational datasets approach match exceeds state art accuracy dense model time provides order magnitude speedup', 'many machine learning domain scene understanding several related sub task scene categorization depth estimation object detection operate raw data provide correlated output task often notoriously hard state art classifier already exist many sub task desirable algorithm capture correlation without requiring make change inner working classifier propose feedback enabled cascaded classification model fe ccm maximizes joint likelihood sub task requiring black box interface original classifier sub task use two layer cascade classifier repeated instantiation original one output first layer fed second layer input training method involves feedback step allows later classifier provide earlier classifier information error mode focus show method significantly improves performance sub task two different domain scene understanding consider depth estimation scene categorization event categorization object detection geometric labeling saliency detection ii robotic grasping consider grasp point detection object classification', 'paper develops connection traditional perceptron algorithm recently introduced herding algorithm shown algorithm viewed application perceptron cycling theorem connection strengthens herding result suggests new supervised herding algorithm like crfs discriminative rbms make prediction conditioning input attribute develop investigate variant conditional herding show conditional herding lead practical algorithm perform better par related classifier voted perceptron discriminative rbm', 'singular value decomposition principal component analysis one widely used technique dimensionality reduction successful efficiently computable nevertheless plagued well known well documented sensitivity outlier recent work considered setting point arbitrarily corrupted component yet application svd pca robust collaborative filtering bioinformatics malicious agent defective gene simply corrupted contaminated experiment may effectively yield entire point completely corrupted present efficient convex optimization based algorithm call outlier pursuit mild assumption uncorrupted point satisfied e g standard generative assumption pca problem recovers exact optimal low dimensional subspace identifies corrupted point identification corrupted point conform low dimensional approximation paramount interest bioinformatics financial application beyond technique involve matrix decomposition using nuclear norm minimization however result setup approach necessarily differ considerably existing line work matrix completion matrix decomposition since develop approach recover correct column space uncorrupted matrix rather exact matrix', 'increase available data parallel machine learning become increasingly pressing problem paper present first parallel stochastic gradient descent algorithm including detailed analysis experimental evidence unlike prior work parallel optimization algorithm variant come parallel acceleration guarantee pose overly tight latency constraint might available multicore setting analysis introduces novel proof technique contractive mapping quantify speed convergence parameter distribution asymptotic limit side effect answer question quickly stochastic gradient descent algorithm reach asymptotically normal regime', 'modelling camera shake space invariant convolution simplifies problem removing camera shake often insufficiently model actual motion blur due camera rotation movement outside sensor plane object scene different distance camera order overcome limitation contribute threefold introduce taxonomy camera shake ii show combine recently introduced framework space variant filtering based overlap add hirsch et al fast algorithm single image blind deconvolution space invariant filter cho lee introduce method blind deconvolution space variant blur iii present experimental setup evaluation allows u take image real camera shake time record space variant point spread function corresponding blur finally demonstrate method able deblur image degraded spatially varying blur originating real camera shake', 'robust low level image feature proven effective representation variety visual recognition task object recognition scene classification pixel even local image patch carry little semantic meaning high level visual task low level image representation potentially enough paper propose high level image representation called object bank image represented scale invariant response map large number pre trained generic object detector blind testing dataset visual task leveraging object bank representation superior performance high level visual recognition task achieved simple shelf classifier logistic regression linear svm sparsity algorithm make representation efficient scalable large scene datasets reveal semantically meaningful feature pattern', 'paper present co regularization based approach semi supervised domain adaptation proposed approach ea build notion augmented space introduced easyadapt ea harness unlabeled data target domain enable transfer information source target semi supervised approach domain adaptation extremely simple implement applied pre processing step supervised learner theoretical analysis term rademacher complexity ea ea show hypothesis class ea lower complexity compared ea hence result tighter generalization bound experimental result sentiment analysis task reinforce theoretical finding demonstrate efficacy proposed method compared ea well baseline approach', 'abstract missing', 'present algorithm learning high treewidth markov network inference still tractable made possible exploiting context specific independence determinism domain class model algorithm learn desirable property thin junction tree polynomial inference closed form weight learning etc much broader algorithm search feature divide state space subspace remaining variable decompose independent subset conditioned feature negation recurses subspace subset variable useful new feature found provide probabilistic performance guarantee algorithm assumption maximum feature length k treewidth much larger dependence bounded strength also propose greedy version algorithm forgoing guarantee much efficient experiment variety domain show approach compare favorably thin junction tree markov network structure learner', 'arithmetic circuit ac exploit context specific independence determinism allow exact inference even network high treewidth paper introduce first ever approximate inference method using ac domain exact inference remains intractable propose evaluate variety technique based exact compilation forward sampling ac structure learning markov network parameter learning variational inference gibbs sampling experiment eight challenging real world domain find method based sampling learning work best one method ac f faster usually accurate loopy belief propagation mean field gibbs sampling another ac g running time similar gibbs sampling consistently accurate baseline', 'paper present approach visual recognition human action using single image input task easy human difficult current approach object recognition action instance may similar term body pose often require detailed examination relation participating object body part order recognized proposed approach applies two stage interpretation procedure training test image first stage produce accurate detection relevant body part actor forming prior local evidence needed considered identifying action second stage extract feature anchored detected body part us feature feature part relation order recognize action body anchored prior propose apply large range human action prior allow focusing relevant region relation thereby significantly simplifying learning process increasing recognition performance', 'present policy gradient result within framework linearly solvable mdps first time compatible function approximators natural policy gradient obtained estimating cost go function rather much larger state action advantage function necessary traditional mdps also develop first compatible function approximators natural policy gradient continuous time stochastic system', 'present analyze agnostic active learning algorithm work without keeping version space unlike previous approach restricted set candidate hypothesis maintained throughout learning hypothesis set ever returned avoiding version space approach algorithm shed computational burden brittleness associated maintaining version space yet still allows substantial improvement supervised learning classification', 'consider following sparse signal recovery feature selection problem given design matrix x mathbb r n time gg n noisy observation vector mathbb r n satisfying x beta epsilon epsilon noise vector following gaussian distribution n sigma recover signal parameter vector beta signal sparse dantzig selector proposed sparse signal recovery strong theoretical guarantee paper propose multi stage dantzig selector method iteratively refines target signal beta show x obeys certain condition large probability difference solution hat beta estimated proposed method true solution beta measured term l p norm p geq bounded begin equation hat beta beta p leq left c n p sqrt log delta right sigma end equation c constant number nonzero entry beta delta independent much smaller first term n number entry beta larger certain value order mathcal sigma sqrt log proposed method improves estimation bound standard dantzig selector approximately c p sqrt log sigma c n p sqrt log sigma value n depends number large entry beta n proposed algorithm achieves oracle solution high probability addition large probability proposed method select number correct feature milder condition dantzig selector', 'functional segregation integration fundamental characteristic human brain studying connectivity among segregated region dynamic integrated brain network drawn increasing interest controversial yet fundamental issue study determine best functional brain region roi region interest individual essentially computed connectivity pattern dynamic brain network sensitive location size shape roi paper present novel methodology optimize location individual roi working memory system strategy formulate individual roi optimization group variance minimization problem group wise functional structural connectivity pattern anatomic profile defined optimization constraint optimization problem solved via simulated annealing approach experimental result show optimized roi significantly improved consistency structural functional profile across subject reasonable localization consistent morphological anatomic profile', 'propose general framework online learning classification problem time varying potential function adversarial setting framework allows design prove relative mistake bound generic loss function mistake bound specialized hinge loss allowing recover improve bound known online classification algorithm optimizing general bound derive new online classification algorithm called narow hybridly us adaptive fixed second order information analyze property algorithm illustrate performance using synthetic dataset', 'algorithm based iterative local approximation present practical approach optimal control robotic system however generally require temporal parameter e g movement duration time point reaching intermediate goal specified textit priori present methodology capable jointly optimising temporal parameter addition control command profile presented approach based bayesian canonical time formulation optimal control problem temporal mapping canonical real time parametrised additional control variable approximate em algorithm derived efficiently optimises movement duration control command offering first time practical approach tackling generic via point problem systematic way optimal control framework proposed approach evaluated simulation redundant robotic plant', 'paper concerned generalization analysis learning rank information retrieval ir ir data hierarchically organized e consisting query document per query previous generalization analysis ranking however fully considered structure cannot explain simultaneous change query number document number training data affect performance algorithm paper propose performing generalization analysis assumption two layer sampling e sampling query conditional sampling document per query sampling better describe generation mechanism real data corresponding generalization analysis better explain real behavior learning rank algorithm however challenging perform analysis document associated different query identically distributed document associated query become longer independent represented feature extracted matching document query tackle challenge decompose generalization error according two layer make use new concept two layer rademacher average generalization bound obtained quite intuitive accordance previous empirical study performance ranking algorithm', 'abstract missing', 'striking aspect cortical neural network divergence relatively small number input channel peripheral sensory apparatus large number cortical neuron complete representation strategy cortical neuron connected sparse network lateral synapsis propose architecture may increase persistence representation incoming stimulus percept demonstrate family network receptive field neuron expressed outgoing connection represented percept remain constant despite changing activity term choice connectivity receptive field recombination refire network sparse refire network may serve high dimensional integrator biologically plausible model local cortical circuit', 'consider convex relaxation hat f pseudo boolean function f say relaxation em totally half integral hat f bx polyhedral function half integral extreme point bx property preserved adding arbitrary combination constraint form x x j x x j x gamma gamma frac constant well known example em roof duality relaxation quadratic pseudo boolean function f argue total half integrality natural requirement generalization roof duality arbitrary pseudo boolean function contribution follows first provide complete characterization totally half integral relaxation hat f establishing one one correspondence em bisubmodular function second give new characterization bisubmodular function finally show relationship general totally half integral relaxation relaxation based roof duality', 'software developer modify one file large code base must also identify update related file many file dependency detected mining development history code base essence group related file revealed log previous workflow data form show detect dependent file solving problem binary matrix completion explore different latent variable model lvms problem including bernoulli mixture model exponential family pca restricted boltzmann machine fully bayesian approach evaluate model development history three large open source software system mozilla firefox eclipse subversive gimp application find lvms improve performance related file prediction current leading method', 'present novel approach inference conditionally gaussian continuous time stochastic process latent process markovian jump process first consider case jump diffusion process drift linear stochastic differential equation jump arbitrary time point derive partial differential equation exact inference present efficient mean field approximation introducing novel lower bound free energy generalise approach gaussian process arbitrary covariance non markovian rbf covariance present result simulated real data showing approach accurate capturing latent dynamic useful number real data modelling task', 'problem controlling margin classifier studied detailed analytical study presented property classification risk optimal link minimum risk function related shape loss margin enforcing property shown class risk denoted canonical risk asymptotic bayes consistency compatible simple analytical relationship function enable precise characterization loss popular class link function shown risk canonical form link inverse sigmoidal margin property loss determined single parameter novel family bayes consistent loss function variable margin derived family used design boosting style algorithm explicit control classification margin new algorithm generalize well established approach logitboost experimental result show proposed variable margin loss outperform fixed margin counterpart used existing algorithm finally shown best performance achieved cross validating margin parameter', 'study setting poisson process generate sequence decision making event optimization goal allowed depend rate decision outcome rate may depend potentially long backlog event decision model problem poisson process throttling policy enforces data dependent rate limit reduce learning problem convex optimization problem solved efficiently problem setting match application damage caused attacker grows function rate unsuppressed hostile event report experiment abuse detection email service', 'present novel algorithm random conic pursuit solves semidefinite program sdps via repeated optimization randomly selected two dimensional subcones psd cone scheme simple easily implemented applicable general sdps scalable theoretically interesting advantage realized expense ability readily compute highly exact solution though useful approximate solution easily obtained property render random conic pursuit particular interest machine learning application relevant sdps generally based upon random data exact minimum often priority indeed present empirical result effect various sdps encountered machine learning experiment demonstrate potential practical usefulness random conic pursuit also provide preliminary analysis yield insight theoretical property convergence algorithm', 'multi class classification becomes challenging test time number class large testing every possible class become computationally infeasible problem alleviated imposing learning structure set class propose algorithm learning tree structure classifier optimizing overall tree loss provides superior accuracy existing tree labeling method also propose method learns embed label low dimensional space faster non embedding approach superior accuracy existing embedding approach finally combine two idea resulting label embedding tree outperforms alternative method including one v rest order magnitude faster', 'many combinatorial problem arising machine learning reduced problem minimizing submodular function submodular function natural discrete analog convex function minimized strongly polynomial time unfortunately state art algorithm general submodular minimization intractable practical problem paper introduce novel subclass submodular minimization problem call decomposable decomposable submodular function represented sum concave function applied linear function develop algorithm slg efficiently minimize decomposable submodular function ten thousand variable algorithm exploit recent result smoothed convex minimization apply slg synthetic benchmark joint classification segmentation task show outperforms state art general purpose submodular minimization algorithm several order magnitude', 'animal repeatedly choose action multiple alternative allocate choice stochastically depending past action outcome commonly assumed ability achieved modification synaptic weight related decision making choice behavior empirically found follow herrnstein matching law loewenstein amp seung demonstrated matching behavior steady state learning neural network synaptic weight change proportionally covariance reward neural activity however proof take account change entire synaptic distribution study show matching behavior necessarily steady state covariance based learning rule synaptic strength sufficiently strong fluctuation input individual sensory neuron influence net input output neuron caused increasing variance input potential due diffusion synaptic weight effect cause undermatching phenomenon observed many behavioral experiment suggest synaptic diffusion effect provide robust neural mechanism stochastic choice behavior', 'abstract missing', 'layered model powerful way describing natural scene containing smooth surface may overlap occlude image motion estimation model long history achieved wide use accuracy non layered method present new probabilistic model optical flow layer address many shortcoming previous approach particular define probabilistic graphical model explicitly capture occlusion disocclusions depth ordering layer temporal consistency layer segmentation additionally optical flow layer modeled combination parametric model smooth deviation based mrf robust spatial prior resulting model allows roughness layer finally key contribution formulation layer using image dependent hidden field prior based recent model static scene segmentation method achieves state art result middlebury benchmark produce meaningful scene segmentation well detected occlusion region', 'paper introduces monte carlo algorithm online planning large pomdps algorithm combine monte carlo update agent belief state monte carlo tree search current belief state new algorithm pomcp two important property first monte carlo sampling used break curse dimensionality belief state update planning second black box simulator pomdp required rather explicit probability distribution property enable pomcp plan effectively significantly larger pomdps previously possible demonstrate effectiveness three large pomdps scale well known benchmark problem rocksample several order magnitude also introduce two challenging new pomdps x battleship partially observable pacman approximately state respectively monte carlo planning algorithm achieved high level performance prior knowledge also able exploit simple domain knowledge achieve better result le search pomcp first general purpose planner achieve high performance large unfactored pomdps', 'obtain tight distribution specific characterization sample complexity large margin classification l regularization introduce gamma adapted dimension simple function spectrum distribution covariance matrix show distribution specific upper lower bound sample complexity governed gamma adapted dimension source distribution conclude new quantity tightly characterizes true sample complexity large margin classification bound hold rich family sub gaussian distribution', 'problem optimal automatic design detector cascade considered novel mathematical model introduced cascaded detector model analytically tractable lead recursive computation account classification complexity boosting algorithm fcboost proposed fully automated cascade design exploit new cascade model minimizes lagrangian cost account classification risk complexity search space cascade configuration automatically determine optimal number stage predictor compatible bootstrapping negative example cost sensitive learning experiment show resulting cascade state art performance various computer vision problem', 'increasing amount sensitive personal information find way data repository important develop analysis mechanism derive aggregate information repository without revealing information individual data instance though differential privacy model provides framework analyze mechanism database belonging single party framework yet considered multi party setting paper propose privacy preserving protocol composing differentially private aggregate classifier using classifier trained locally separate mutually untrusting party protocol allows party interact untrusted curator construct additive share perturbed aggregate classifier also present detailed theoretical analysis containing proof differential privacy perturbed aggregate classifier bound excess risk introduced perturbation verify bound experimental evaluation real dataset', 'address problem semi supervised learning adversarial setting instead assuming label missing random analyze le favorable scenario label information missing partially arbitrarily motivated several practical example present nearly matching upper lower generalization bound learning setting reasonable assumption available label information motivated analysis formulate convex optimization problem parameter estimation derive efficient algorithm analyze convergence provide experimental result several standard data set showing robustness algorithm pattern missing label information outperforming several strong baseline', 'since discovery sophisticated fully polynomial randomized algorithm range p problem karzanov et al jerrum et al wilson theoretical work approximate inference combinatorial space focused markov chain monte carlo method despite strong theoretical guarantee slow running time many randomized algorithm restrictive assumption potential hindered applicability algorithm machine learning application combinatorial space simple exact model often preferred complex model require approximate inference siepel et al variational inference would appear provide appealing alternative given success variational method graphical model wainwright et al unfortunately however obvious develop variational approximation combinatorial object matchings partial order plane partition sequence alignment propose new framework extends variational inference wide range combinatorial space method based simple assumption existence tractable measure factorization show hold many example simulation range matching model show algorithm general empirically faster popular fully polynomial randomized algorithm also apply framework problem multiple alignment protein sequence obtaining state art result balibase dataset thompson et al', 'present new way converting reversible finite markov chain nonreversible one theoretical guarantee asymptotic variance mcmc estimator based non reversible chain reduced method applicable reversible chain whose state connected tree interpreted graphically inserting vortex state transition graph result confirms non reversible chain fundamentally better reversible one term asymptotic performance suggests interesting direction improving mcmc', 'understand relationship genomic variation among population complex disease essential detect eqtls associated phenotypic effect however detecting eqtls remains challenge due complex underlying mechanism large number genetic locus involved compared number sample thus address problem desirable take advantage structure data prior information genomic location conservation score transcription factor binding site paper propose novel regularized regression approach detecting eqtls take account related trait simultaneously incorporating many regulatory feature first present bayesian network multi task learning problem includes prior snp making possible estimate significance covariate adaptively find maximum posteriori map estimation regression coefficient estimate weight covariates jointly optimization procedure efficient since achieved using convex optimization coordinate descent procedure iteratively experimental result simulated real yeast datasets confirm model outperforms previous method finding eqtls', 'random projection tree rptree structure proposed dasgupta freund stoc space partitioning data structure automatically adapt various notion intrinsic dimensionality data prove new result rptree max rptree mean data structure result rptree max give near optimal bound number level required data structure reduce size cell factor also prove packing lemma data structure final result show low dimensional manifold posse bounded local covariance dimension consequence show rptree mean adapts manifold dimension well', 'abstract missing', 'consider problem learning local metric enhance performance nearest neighbor classification conventional metric learning method attempt separate data distribution purely discriminative manner show take advantage information parametric generative model focus bias information theoretic error arising finite sampling effect find appropriate local metric maximally reduces bias based upon knowledge generative model byproduct asymptotic theoretical analysis work relates metric learning dimensionality reduction understood previous discriminative approach empirical experiment show learned local metric enhances discriminative nearest neighbor performance various datasets using simple class conditional generative model', 'many real world application access fully labeled training data list possible label case e g learning visual classifier image downloaded web using text caption tag learning oracle general problem difficult however time exist different implicit source information coming relation instance label usually dismissed paper propose semi supervised framework model kind problem training sample bag containing multi instance associated set candidate labeling vector labeling vector encodes possible label instance bag one fully correct use labeling vector provides principled way exclude information propose large margin discriminative formulation efficient algorithm solve experiment conducted artificial datasets real world image caption dataset show approach achieves performance comparable svm trained ground truth label outperforms baseline', 'steinwart rst prove universal consistency support vector machine classi cation proof analyzed standard support vector machine classi er restricted binary classi cation problem contrast recent analysis resulted common belief several extension svm classi cation two class inconsistent countering belief proof universal consistency multi class support vector machine crammer singer proof extends steinwart technique multi class case', 'propose new supervised learning framework visual object counting task estimating number cell microscopic image number human surveillance video frame focus practically attractive case training image annotated dot one dot per object goal accurately estimate count however evade hard task learning detect localize individual object instance instead cast problem estimating image density whose integral image region give count object within region learning infer density formulated minimization regularized risk quadratic cost function introduce new loss function well suited learning time computed efficiently via maximum subarray algorithm learning posed convex quadratic program solvable cutting plane optimization proposed framework flexible accept domain specific visual feature trained system provides accurate object count requires small time overhead feature extraction step making good candidate application involving real time processing dealing huge amount visual data', 'working network datasets theoretical framework detection theory euclidean vector space longer applies nevertheless desirable determine detectability small anomalous graph embedded background network known statistical property casting problem subgraph detection signal processing context article provides framework empirical result elucidate detection theory graph valued data focus detection anomaly unweighted undirected graph l property eigenvectors graph called modularity matrix metric observed relatively low variance certain category randomly generated graph reveal presence anomalous subgraph reasonable reliability anomaly well correlated stronger portion background graph analysis subgraphs real network datasets confirms efficacy approach', 'paper regard clustering ensemble k ary affinity relation cluster correspond subset object maximal average affinity relation average affinity relation cluster relaxed well approximated constrained homogenous function present efficient procedure solve optimization problem show underlying cluster robustly revealed using prior systematically constructed data method automatically select point form cluster leaving point un grouped thus inherently robust large number outlier seriously limited applicability classical method method also provides unified solution clustering k ary affinity relation k applies graph based hypergraph based clustering problem theoretical analysis experimental result show superiority method classical solution clustering problem especially exists large number outlier', 'neural network parameter space attractive field likely induced singularity singularity region first order gradient learning typically cause long plateau little change objective function value e hence flat region therefore may confused attractive local minimum analysis show hessian matrix e tends indefinite vicinity perturbed singular point suggesting promising strategy exploit negative curvature escape singularity plateau numerical evidence limit scope small example found journal paper allow u confirm singularity eigenvalue hessian matrix computation using descent direction negative curvature encounter plateau even small problem efficient method previously developed avoided plateau', 'present new learning strategy classification problem train test data suffer missing feature previous work instance represented vector feature space one forced impute missing value consider instance specific subspace contrast method considers instance set feature value pair naturally handle missing value case building onto framework propose classification strategy set proposal map feature value pair embedding space non linearly combine set embedded vector embedding combination parameter learned jointly final classification objective simple strategy allows great flexibility encoding prior knowledge feature embedding step yield advantageous result compared alternative solution several datasets', 'consider online learning finite stochastic markovian environment time step new reward function chosen oblivious adversary goal learning agent compete best stationary policy term total reward received time step agent observes current state reward associated last transition however agent observe reward associated state action pair agent assumed know transition probability state art result setting regret algorithm paper propose new learning algorithm assuming stationary policy mix uniformly fast show time step expected regret new algorithm ln giving first rigorously proved convergence rate result problem', 'identifying feature object becomes challenge feature change appearance introduce transformed indian buffet process tibp use define nonparametric bayesian model infers feature transform across instantiation show model identify feature location invariant modeling previous experiment human feature learning however allowing feature transform add new kind ambiguity two part object feature different transformation two unique feature transformation feature undergo present two new experiment explore people resolve question showing tibp model demonstrates similar sensitivity context shown human learner determining invariant aspect feature', 'abstract missing', 'activity neuron even early sensory area simply function local receptive field tuning property depends global context stimulus well neural context suggests activity surrounding neuron global brain state exert considerable influence activity neuron paper implemented l regularized point process model ass contribution multiple factor firing rate many individual unit recorded simultaneously v electrode utah array found spike surrounding neuron indeed provide strong prediction neuron response addition neuron receptive field transfer function also found spike could accounted local field potential surrogate measure global network state work show accounting network fluctuation improve estimate single trial firing rate stimulus response transfer function', 'spatial pattern spontaneous evoked population response related study impact connectivity spatial pattern fluctuation input generated response neural network comparing distribution evoked intrinsically generated activity across different unit develop complementary approach principal component analysis separate high variance direction typically derived input condition analyze subspace angle compute difference shape trajectory corresponding different network state orientation low dimensional subspace driven trajectory occupy within full space neuronal activity addition revealing spatiotemporal structure spontaneous activity affect input evoked response method used infer input selectivity induced network dynamic experimentally accessible measure spontaneous activity e g voltage calcium sensitive optical imaging experiment conclude absence detailed spatial map afferent input cortical connectivity limit ability design spatially extended stimulus evoke strong response', 'study several class interactive assistant point view decision theory computational complexity first introduce class pomdps called hidden goal mdps hgmdps formalize problem interactively assisting agent whose goal hidden whose action observable spite restricted nature show optimal action selection finite horizon hgmdps pspace complete even domain deterministic dynamic introduce restricted model called helper action mdps hamdps assistant action accepted agent helpful easily ignored agent otherwise show class hamdps complete pspace np along polynomial time class furthermore show general hamdps simple myopic policy achieves regret compared omniscient assistant bounded entropy initial goal distribution variation policy shown achieve worst case regret logarithmic number goal goal distribution', 'expert human computer often required ass probability uncertain event collection expert independently ass event structurally interrelated resulting assessment may violate fundamental law probability assessment termed incoherent work investigate problem incoherence may affected allowing expert specify likelihood model update assessment based realization globally observable random sequence', 'energy disaggregation task taking whole home energy signal separating component appliance study shown device level energy information cause user conserve significant amount energy current electricity meter report whole home data thus developing algorithmic method disaggregation present key technical challenge effort maximize energy conservation paper examine large scale energy disaggregation task apply novel extension sparse coding problem particular develop method based upon structured prediction discriminatively training sparse coding algorithm specifically maximize disaggregation performance show significantly improves performance sparse coding algorithm energy task illustrate disaggregation result provide useful information energy usage', 'consider linear model stochastic dynamic model associated network namely directed graph describing degree freedom interact dynamic tackle problem learning network observation system trajectory time interval analyse l regularized least square algorithm setting underlying network sparse prove performance guarantee uniform sampling rate long sufficiently high result substantiates notion well defined time complexity network inference problem', 'automatic speech recognition gradually improved year reliable recognition unconstrained speech still within reach order achieve breakthrough many research group investigating new methodology potential outperform hidden markov model technology core present commercial system paper shown recently introduced concept reservoir computing might form basis methodology limited amount time reservoir system recognize elementary sound continuous speech built system already achieves state art performance evidence margin improvement still significant', 'functional magnetic resonance imaging fmri applied study functional connectivity neural element form complex network whole brain level analysis functional resting state network rsn based analysis correlation temporal dynamic various region brain model identify coherently behaving group term correlation give little insight group interact paper take different view analysis functional resting state network starting definition resting state functional coherent group search functional unit brain communicate part brain coherent manner measured mutual information use infinite relational model irm quantify functional coherent group resting state network demonstrate extracted component interaction used discriminate functional resting state activity multiple sclerosis normal subject', 'figure ground assignment visual image divided nearer figural farther ground surface essential step visual processing underlying computational mechanism poorly understood figural assignment often referred border ownership vary along contour suggesting spatially distributed process whereby local global cue combined yield local estimate border ownership paper model figure ground estimation bayesian belief network attempting capture propagation border ownership across image local cue contour curvature junction interact global cue yield figure ground assignment network includes nonlocal factor skeletal medial axis structure hypothesis medial structure draw border ownership border owned interior also briefly present psychophysical experiment measured local border ownership along contour various distance inducing cue junction human subject network show similar pattern performance converging rapidly similar pattern spatial variation border ownership along contour', 'matching functional brain region across individual challenging task largely due variability location extent particularly difficult highly relevant patient pathology brain tumor cause substantial reorganization functional system case spatial registration based anatomical data limited value goal establish correspondence functional area among different individual localize potentially displaced active region rather rely spatial alignment propose perform registration alternative space whose geometry governed functional interaction pattern brain first embed brain functional map reflects connectivity pattern fmri experiment resulting functional map registered obtained correspondence propagated back two brain application language fmri experiment preliminary result suggest proposed method yield improved functional correspondence across subject advantage pronounced subject tumor affect language area thus cause spatial reorganization functional region', 'abstract missing', 'score matching recently proposed criterion training high dimensional density model maximum likelihood training intractable applied learning natural image statistic far limited simple model due difficulty differentiating loss respect model parameter show differentiation automated extended version double backpropagation algorithm addition introduce regularization term score matching loss enables use broader range problem suppressing instability occur finite training sample size quantized input value result reported image denoising super resolution', 'deep network potentially express learning problem efficiently local learning machine deep network outperform local learning machine problem still unclear nice representation emerges complex structure present analysis based gaussian kernel measure representation learning problem evolves layer layer deep network build higher level abstract representation input use analysis show empirically deep network build progressively better representation learning problem best representation obtained deep network discriminates last layer', 'paper consider problem learning data support probability distribution distribution em density respect reference measure propose new class regularized spectral estimator based new notion reproducing kernel hilbert space call em completely regular completely regular kernel allow capture relevant geometric topological property arbitrary probability space particular key ingredient prove universal consistency spectral estimator respect analogue universal kernel supervised problem numerical experiment show spectral estimator compare favorably state art machine learning algorithm density support estimation', 'bayesian method matrix factorization mf actively explored recently promising alternative classical singular value decomposition paper show despite fact optimization problem non convex global optimal solution variational bayesian vb mf computed analytically solving quartic equation highly advantageous popular vbmf algorithm based iterated conditional mode since find local optimal solution iteration show global optimal solution empirical vbmf hyperparameters also learned data also analytically computed illustrate usefulness result experiment', 'current image categorization method require large collection manually annotated training example learn accurate visual recognition model time consuming human labeling effort effectively limit approach recognition problem involving small number different object class order address shortcoming recent year several author proposed learn object classifier weakly labeled internet image photo retrieved keyword based image search engine strategy eliminates need human supervision recognition accuracy method considerably lower obtained fully supervised approach noisy nature label associated web data paper investigate compare method learn image classifier combining manually annotated example e g image per class large number weakly labeled web photo retrieved using keyword based image search cast domain adaptation problem given strongly labeled example target domain manually annotated example many source domain example weakly labeled web photo learn classifier yielding small generalization error target domain experiment demonstrate number strongly labeled example domain adaptation approach produce significant recognition rate improvement best published result e g better using labeled training example per class classifier one order magnitude faster learn evaluate best competing method despite use large weakly labeled data set', 'divisive normalization dn advocated effective nonlinear em efficient coding transform natural sensory signal application biology engineering work aim establish connection dn transform statistical property natural sensory signal analysis based use multivariate em model capture important statistical property natural sensory signal multivariate em model justifies dn approximation transform completely eliminates statistical dependency furthermore using multivariate em model measuring statistical dependency multi information precisely quantify statistical dependency reduced dn transform compare actual performance dn transform reducing statistical dependency natural sensory signal theoretical analysis quantitative evaluation confirm dn effective efficient coding transform natural sensory signal hand also observe previously unreported phenomenon dn may increase statistical dependency size pooling small', 'many study explored impact response variability quality sensory code source variability almost always assumed intrinsic brain however inferring particular stimulus property variability associated stimulus attribute also effectively act noise study impact stimulus induced response variability case binocular disparity inference characterize response distribution binocular energy model response random dot stereograms find different poisson like noise usually assumed compute fisher information respect binocular disparity present monocular input standard model early binocular processing thereby obtain upper bound much information model could theoretically extract analyze information loss incurred different way combining input produce scalar single neuron response find case depth inference monocular stimulus variability place greater limit extractable information intrinsic neuronal noise typical spike count furthermore largest loss information incurred standard model position disparity neuron tuned excitatory ubiquitous monkey primary visual cortex information input preserved phase disparity neuron tuned near tuned far primarily found higher cortical region', 'lifted inference algorithm representation combine first order logic probabilistic graphical model focus much recent research lifted algorithm developed date based underlying idea take standard probabilistic inference algorithm e g variable elimination belief propagation etc improve efficiency exploiting repeated structure first order model paper propose approach side use technique logic probabilistic inference particular define set rule look logical representation identify model exact efficient inference possible show rule yield several new tractable class cannot solved efficiently existing technique', 'density f r high density cluster connected component x f x c c set high density cluster form hierarchy called cluster tree f present procedure estimating cluster tree given sample f give finite sample convergence rate algorithm well lower bound sample complexity estimation problem', 'discriminative machine learning one interested training system optimize certain desired measure performance loss binary classification one typically try minimizes error rate structured prediction task often measure performance bleu score machine translation intersection union score pascal segmentation common approach structured prediction structural svms crfs minimize task loss former minimizes surrogate loss guarantee task loss latter minimizes log loss independent task loss main contribution paper theorem stating certain perceptron like learning rule involving feature vector derived loss adjusted inference directly corresponds gradient task loss give empirical result phonetic alignment standard test set timit corpus surpasses previously reported result problem', 'abstract missing', 'system identification input output system available observer algorithm sought identify parameter hypothesized model system present novel formal methodology identifying dendritic processing neural circuit consisting linear dendritic processing filter cascade spiking neuron model input circuit analog signal belongs space bandlimited function output time sequence associated spike train derive algorithm identification dendritic processing filter reconstruct kernel arbitrary precision', 'propose new probabilistic model analyzing dynamic evolution relational data addition deletion split merge relation cluster like community social network proposed model abstract observed time varying object object relationship relationship object cluster extend infinite hidden markov model follow dynamic time sensitive change structure relational data estimate number cluster simultaneously show usefulness model experiment synthetic real world data set', 'present simple computationally efficient nonparametric estimator r enyi entropy mutual information based sample drawn unknown absolutely continuous distribution r estimator calculated sum p th power euclidean length edge generalized nearest neighbor graph sample empirical copula sample respectively first time prove almost sure consistency estimator upper bound rate convergence latter assumption density underlying sample lipschitz continuous experiment demonstrate usefulness independent subspace analysis', 'tackle fundamental problem bayesian active learning noise need adaptively select number expensive test order identify unknown hypothesis sampled known prior distribution case noise free observation greedy algorithm called generalized binary search gb known perform near optimally show observation noisy perhaps surprisingly gb perform poorly develop ec novel greedy active learning algorithm prove competitive optimal policy thus obtaining first competitiveness guarantee bayesian active learning noisy observation bound rely recently discovered diminishing return property called adaptive submodularity generalizing classical notion submodular set function adaptive policy result hold even test non uniform cost noise correlated also propose effecxtive particularly fast approximation ec evaluate bayesian experimental design problem involving human subject intended tease apart competing economic theory people make decision uncertainty', 'abstract missing', 'consider problem identifying activation pattern complex large scale network embedded noisy measurement problem relevant several application identifying trace biochemical spread sensor network expression level gene anomalous activity congestion internet extracting pattern challenging task specially network large pattern high dimensional noise excessive mask activity single node however typically statistical dependency network activation process leveraged fuse measurement multiple node enable reliable extraction high dimensional noisy pattern paper analyze estimator based graph laplacian eigenbasis establish limit mean square error recovery noisy pattern arising probabilistic gaussian ising model based arbitrary graph structure consider deterministic probabilistic network evolution model result indicate leveraging network interaction structure possible consistently recover high dimensional pattern even noise variance increase network size', 'much information neural population convey stimulus answer question known strongly depend correlation response variability neural population noise correlation however essentially immeasurable number parameter noise correlation matrix grows quadratically population size suggest bypass problem imposing parametric model noise correlation matrix basic assumption noise correlation arise due common input neuron average noise correlation therefore reflect signal correlation measured neural population suggest explicit parametric dependency signal noise correlation show dependency used fill gap noise correlation matrix using iterative application wishart distribution positive definitive matrix apply method data primary somatosensory cortex monkey performing two alternative forced choice task compare discrimination threshold read population recorded neuron discrimination threshold monkey show method predicts different result simpler average scheme noise correlation', 'prove rate convergence statistical sense kernel based least square regression using conjugate gradient algorithm regularization overfitting obtained early stopping method directly related kernel partial least square regression method combine supervised dimensionality reduction least square projection rate depend two key quantity first regularity target regression function second effective dimensionality data mapped kernel space lower bound attainable rate depending two quantity established earlier literature obtain upper bound considered method match lower bound log factor true regression function belongs reproducing kernel hilbert space latter assumption fulfilled obtain similar convergence rate provided additional unlabeled data available order learning rate two situation match state art result recently obtained least square support vector machine linear regularization operator', 'cardiovascular disease leading cause death globally resulting million death year despite availability various treatment option existing technique based upon conventional medical knowledge often fail identify patient might benefited aggressive therapy paper describe evaluate novel unsupervised machine learning approach cardiac risk stratification key idea approach avoid specialized medical knowledge ass patient risk using symbolic mismatch new metric ass similarity long term time series activity hypothesize high risk patient identified using symbolic mismatch individual population unusual long term physiological activity describe related approach build idea provide improved medical decision making patient recently suffered coronary attack first describe compute symbolic mismatch pair long term electrocardiographic ecg signal algorithm map original signal symbolic domain provides quantitative assessment difference symbolic representation original signal show measure used one class svm nearest neighbor classifier hierarchical clustering improve risk stratification evaluated method population cardiac patient available long term electrocardiographic data univariate analysis method provided statistically significant association occurrence major adverse cardiac event next day multivariate analysis incorporated widely used clinical risk variable nearest neighbor hierarchical clustering approach able statistically significantly distinguish patient roughly two fold risk suffering major adverse cardiac event next day', 'new algorithm isotonic regression presented based recursively partitioning solution space develop efficient method partitioning subproblem equivalent representation network flow problem prove sequence partition converges global solution network flow problem decomposed order solve large problem success isotonic regression prediction algorithm favorable computational property demonstrated simulated example large x variable constraint', 'abstract missing', 'spontaneous brain activity observed functional neuroimaging shown display reproducible structure express brain architecture carry marker brain pathology important view modern neuroscience large scale structure coherent activity reflects modularity property brain connectivity graph however date demonstration limited noisy data available spontaneous activity observation could used learn full brain probabilistic model generalize new data learning model entail two main challenge modeling full brain connectivity difficult estimation problem face curse dimensionality ii variability subject coupled variability functional signal experimental run make use multiple datasets challenging describe subject level brain functional connectivity structure multivariate gaussian process introduce new strategy estimate group data imposing common structure graphical model population show individual model learned functional magnetic resonance imaging fmri data using population prior generalize better unseen data model based alternative regularization scheme knowledge first report cross validated model spontaneous brain activity finally use estimated graphical model explore large scale characteristic functional architecture show first time known cognitive network appear integrated community functional connectivity graph', 'present original empirical bernstein inequality u statistic bounded symmetric kernel q expressed respect empirical estimate either variance q conditional variance appears bernstein type inequality u statistic derived arcones result subsumes existing empirical bernstein inequality reduces u statistic order considered addition based rather direct argument using two application non empirical bernstein inequality u statistic discus potential application new inequality especially realm learning ranking scoring function process exhibit efficient procedure compute variance estimate special case bipartite ranking rest sorting argument also argue result may provide test set bound particularly interesting empirical racing algorithm problem online learning scoring function', 'define copula process describes dependency arbitrarily many random variable independently marginal distribution example develop stochastic volatility model gaussian copula process volatility gcpv predict latent standard deviation sequence random variable make prediction use bayesian inference laplace approximation markov chain monte carlo alternative find model outperform garch simulated financial data unlike garch gcpv easily handle missing data incorporate covariates time model rich class covariance structure', 'bayesian optimization method often used optimize unknown function costly evaluate typically method sequentially select input evaluated one time based posterior unknown function updated evaluation number effective sequential policy selecting individual input many application however desirable perform multiple evaluation parallel requires selecting batch multiple input evaluate paper propose novel approach batch bayesian optimization providing policy selecting batch input goal optimizing function efficiently possible key idea exploit availability high quality efficient sequential policy using monte carlo simulation select input batch closely match expected behavior best knowledge first batch selection policy bayesian optimization experimental result six benchmark show proposed approach significantly outperforms two baseline lead large advantage top sequential approach term performance per unit time', 'learning model represented matrix form enforcing low rank constraint dramatically improve memory run time complexity providing natural regularization model however naive approach minimizing function set low rank matrix either prohibitively time consuming repeated singular value decomposition matrix numerically unstable optimizing factored representation low rank matrix build recent advance optimization manifold describe iterative online learning procedure consisting gradient step followed second order retraction back manifold ideal retraction hard compute projection operator approximates describe another second order retraction computed efficiently run time memory complexity n k rank k matrix dimension x n given rank one gradient use algorithm loreta learn matrix form similarity measure pair document represented high dimensional vector loreta improves mean average precision passive aggressive approach factorized model also improves full model trained pre selected feature using memory requirement loreta also showed consistent improvement standard method large class multi label image classification task', 'language vary widely many way including canonical word order basic aspect observed variation fact word order much common others although regularity recognized time well explained paper offer information theoretic explanation observed word order distribution across language based concept uniform information density uid suggest object first language particularly disfavored highly non optimal goal distribute information content approximately evenly throughout sentence rest observed word order distribution least partially explainable term uid support theoretical analysis data child directed speech experimental work', 'recent work reinforcement learning emphasized power l regularization perform feature selection prevent overfitting propose formulating l regularized linear fixed point problem linear complementarity problem lcp formulation offer several advantage lars inspired formulation lars td lcp formulation allows use efficient shelf solver lead new uniqueness result initialized starting point similar problem warm start demonstrate warm start well efficiency lcp solver speed policy iteration moreover warm start permit form modified policy iteration used approximate greedy homotopy path generalization lars td homotopy path combine policy evaluation optimization', 'gaussian graphical model sparsity inverse covariance matrix significant interest many modern application problem recovering graphical structure information criterion provide useful optimization objective algorithm searching set graph selection tuning parameter method graphical lasso likelihood penalization technique paper establish asymptotic consistency extended bayesian information criterion gaussian graphical model scenario number variable p sample size n grow compared earlier work regression case treatment allows growth number non zero parameter true model necessary order cover connected graph demonstrate performance criterion simulated data used conjuction graphical lasso verify criterion indeed performs better either cross validation ordinary bayesian information criterion p number non zero parameter q scale n', 'consider problem retrieving database point nearest given em hyperplane query without exhaustively scanning database propose two hashing based solution first approach map data two bit binary key locality sensitive angle hyperplane normal database point second approach embeds data vector space euclidean norm reflects desired distance original point hyperplane query use hashing retrieve near point sub linear time first method preprocessing stage efficient second stronger accuracy guarantee apply pool based active learning taking current hyperplane classifier query algorithm identifies point approximately satisfying well known minimal distance hyperplane selection criterion empirically demonstrate method tradeoff show make practical perform active selection million unlabeled point', 'describe model based boltzmann machine third order connection learn accumulate information shape several fixation model us retina enough high resolution pixel cover small area image must decide sequence fixation must combine glimpse fixation location fixation integrating information information glimpse object evaluate model synthetic dataset two image classification datasets showing perform least well model trained whole image', 'reinforcement learning community explored many approach obtain ing value estimate model guide decision making approach ever usually provide measure confidence estimate accurate estimate agent confidence useful many application bi asing exploration automatically adjusting parameter reduce dependence parameter tuning computing confidence interval reinforcement learning value estimate however challenging data generated agent environment interaction rarely satisfies traditional assumption sample value estimate dependent likely non normally distributed often limited partic ularly early learning confidence estimate pivotal work investigate compute robust confidence value estimate continuous markov decision process illustrate use bootstrapping compute confidence interval online changing policy previously possible prove validity reasonable assumption demonstrate applica bility confidence estimation algorithm experiment exploration parameter estimation tracking', 'clinician accurately identify different type heartbeat electrocardiogram ecg different patient researcher limited success applying supervised machine learning task problem made challenging variety task inter intra patient difference often severe class imbalance high cost getting cardiologist label data individual patient address difficulty using active learning perform patient adaptive task adaptive heartbeat classification tested benchmark database cardiologist annotated ecg recording method considerably better performance recently proposed method two primary classification task recommended association advancement medical instrumentation additionally method required le patient specific training data method compared', 'order study property total visual input human single subject wore camera two week capturing average image every second www research microsoft com jojic aihs resulting new dataset contains mix indoor outdoor scene well numerous foreground object first analysis goal create visual summary subject two week life using unsupervised algorithm would automatically discover recurrent scene familiar face common action direct application existing algorithm panoramic stitching e g photosynth appearance based clustering model e g epitome impractical due either large dataset size dramatic variation lighting condition remedy problem introduce novel image representation stel epitome associated efficient learning algorithm model image image patch characterized hidden mapping previous epitome model defines mapping image coordinate coordinate large seen epitome matrix limited epitome real estate force mapping different image overlap overlap indicating image similarity however model image similarity depend direct pixel pixel intensity color feature comparison previous epitome model spatial configuration scene object part model based palette invariant stel model result stel epitome capture structure invariant non structural change illumination tend uniformly affect pixel belonging single scene object part', 'new algorithm proposed unsupervised learning sparse representation subsampled measurement b estimating parameter required linearly reconstructing signal sparse code verify new algorithm performs efficient data compression par recent method compressive sampling demonstrate algorithm performs robustly stacked several stage applied undercomplete overcomplete situation new algorithm explain neural population brain receive subsampled input fiber bottleneck able form coherent response property', 'extend latent dirichlet allocation lda explicitly allowing encoding side information distribution word result variety new capability improved estimate infrequently occurring word well ability leverage thesaurus dictionary order boost topic cohesion within across language present experiment multi language topic synchronisation dictionary information used bias corresponding word towards similar topic result indicate model substantially improves topic cohesion compared standard lda model', 'paper propose matrix variate normal penalty sparse inverse covariance couple multiple task learning multiple parametric model viewed estimating matrix parameter row column matrix correspond task feature respectively following matrix variate normal density design penalty decomposes full covariance matrix element kronecker product row covariance column covariance characterizes task relatedness feature representation several recently proposed method variant special case formulation address overfitting issue select meaningful task feature structure include sparse covariance selection matrix normal regularization via l penalty task feature inverse covariance empirically study proposed method compare related model two real world problem detecting landmines multiple field recognizing face different subject experimental result show proposed framework provides effective flexible way model various different structure multiple task', 'consider problem learning coefficient vector x noisy linear observation ax w many context ranging model selection image processing desirable construct sparse estimator case popular approach consists solving l penalized least square problem known lasso bpdn sequence matrix increasing dimension iid gaussian entry prove normalized risk lasso converges limit obtain explicit expression limit result first rigorous derivation explicit formula asymptotic risk lasso random instance proof technique based analysis amp recently developed efficient algorithm inspired graphical model idea simulation real data matrix gene expression data hospital medical record observe result relevant broad array practical application', 'charles bonnet syndrome cbs characterized complex vivid visual hallucination people primarily eye disease neurological pathology present deep boltzmann machine model cbs exploring two core hypothesis first visual cortex learns generative predictive model sensory input thus explaining capability generate internal imagery second homeostatic mechanism stabilize neuronal activity level leading hallucination formed input lacking reproduce variety qualitative finding cbs also introduce modification dbm allows u model possible role acetylcholine cbs mediating balance feed forward feed back processing model might provide new insight cbs also demonstrates generative framework promising hypothetical model cortical learning perception', 'study convex stochastic optimization problem noisy objective function value observed decision made many stochastic optimization problem whose behavior depends exogenous state variable affect shape objective function currently general purpose algorithm solve class problem use nonparametric density estimation joint distribution state outcome pair create weight previous observation weight effectively group similar state similar current state used create convex deterministic approximation objective function propose two solution method depend problem characteristic function based gradient based optimization offer two weighting scheme kernel based weight dirichlet process based weight use solution method weight solution method tested synthetic multi product newsvendor problem hour ahead wind commitment problem result show dirichlet process weight offer substantial benefit kernel based weight generally nonparametric estimation method provide good solution otherwise intractable problem', 'gaussian graphical model great interest statistical learning conditional independency different node correspond zero entry inverse covariance matrix gaussian distribution one learn structure graph estimating sparse inverse covariance matrix sample data solving convex maximum likelihood problem ell regularization term paper propose first order method based alternating linearization technique exploit problem special structure particular subproblems solved iteration closed form solution moreover algorithm obtains epsilon optimal solution epsilon iteration numerical experiment synthetic real data gene association network show practical version algorithm outperforms competitive algorithm', 'abstract missing', 'abstract missing', 'international monitoring system ims global network sensor whose purpose identify potential violation comprehensive nuclear test ban treaty ctbt primarily detection localization seismic event report first stage project improve current automated software system bayesian inference system computes likely global event history given record local sensor data new system visa vertically integrated seismological analysis based empirically calibrated generative model event occurrence signal propagation signal detection visa exhibit significantly improved precision recall compared current operational system able detect event missed even human analyst post process ims output', 'clustering basic data mining task wide variety application surprisingly exist many clustering algorithm however clustering ill defined problem given data set clear correct clustering set indeed different algorithm may yield dramatically different output input set faced concrete clustering task user need choose appropriate clustering algorithm currently decision often made ad hoc completely random manner given crucial effect choice clustering algorithm resulting clustering state affair truly regrettable paper address major research challenge developing tool helping user make informed decision come pick clustering tool data course ambitious endeavor paper make first step towards goal propose address problem distilling abstract property input output behavior different clustering paradigm paper demonstrate abstract intuitive property clustering function used taxonomize set popular clustering algorithmic paradigm top addressing deterministic clustering algorithm also propose similar property randomized algorithm use highlight functional difference different common implementation k mean clustering also study relationship property independent particular algorithm particular strengthen kleinbergs famous impossibility result providing simpler proof', 'show matrix completion trace norm regularization significantly hurt entry matrix sampled non uniformly properly weighted version trace norm regularizer work well non uniform sampling show weighted trace norm regularization indeed yield significant gain highly non uniformly sampled netflix dataset', 'generalized binary search gb well known greedy algorithm identifying unknown object minimizing number yes question posed object arises problem active learning active diagnosis provide coding theoretic interpretation gb show gb viewed top algorithm greedily minimizes expected number query required identify object interpretation used extend gb two way first consider case object partitioned group objective identify group object belongs consider case cost identifying object grows exponentially number query case present exact formula objective function involving shannon renyi entropy develop greedy algorithm minimizing', 'metric constraint known highly discriminative many object training limited data captured particular sensor quantity training data may severly limited paper show crucial aspect information object feature absolute size added model learned commonly available online imagery without use sensing construction training time model utilized test time together explicit sensing perform robust search model us local feature combine traditional appearance gradient statistic estimate average absolute depth within local window show category size information obtained online image exploiting relatively unbiquitous metadata field specifying camera intrinstics develop efficient metric branch bound algorithm search task imposing size constraint part optimal search set feature indicate presence category experiment test scene captured traditional stereo rig shown exploiting training data purely monocular source associated exif metadata', 'standard approach learning object category detector provide strong supervision form region interest roi specifying instance object training image work goal learn heterogeneous label image weakly supervised specifying presence absence object weak indication object location whilst others fully annotated end develop discriminative learning approach make two contribution propose structured output formulation weakly annotated image full annotation treated latent variable ii propose optimize ranking objective function allowing method effectively use negatively labeled image improve detection average precision performance method demonstrated benchmark inria pedestrian detection dataset dalal triggs pascal voc dataset shown significant proportion weakly supervised image performance achieved similar fully supervised state art result', 'number objective function clustering problem described submodular function paper introduce minimum average cost criterion show theory intersecting submodular function used clustering submodular objective function proposed algorithm require number cluster advance determined property given set data point minimum average cost clustering problem parameterized real variable surprisingly show information optimal clustering parameter computed polynomial time total additionally evaluate performance proposed algorithm computational experiment', 'paper proposes simple efficient finite difference method implicit differentiation marginal inference result discrete graphical model given arbitrary loss function defined marginals show derivative loss respect model parameter obtained running inference procedure twice slightly perturbed model parameter method used approximate inference loss function approximate marginals convenient choice loss function make practical fit graphical model hidden variable high treewidth model misspecification', 'many data naturally modeled unobserved hierarchical structure paper propose flexible nonparametric prior unknown data hierarchy approach us nested stick breaking process allow tree unbounded width depth data live node infinitely exchangeable one view model providing infinite mixture component dependency structure corresponding evolutionary diffusion tree using stick breaking approach apply markov chain monte carlo method based slice sampling perform bayesian inference simulate posterior distribution tree apply method hierarchical clustering image topic modeling text data', 'many time series human movement data consist sequence basic action e g forehand backhand tennis automatically extracting characterizing action important problem variety different application paper present probabilistic segmentation approach observed time series modeled concatenation segment corresponding different basic action segment generated noisy transformation one hidden trajectory representing different type movement possible time scaling analyze three different approximation method dealing model intractability demonstrate proposed approach successfully segment table tennis movement recorded using robot arm haptic input device', 'abstract missing', 'many problem machine learning statistic formulated generalized eigenproblems term associated optimization problem computing linear eigenvectors amount finding critical point quadratic function subject quadratic constraint paper show certain class constrained optimization problem nonquadratic objective constraint understood nonlinear eigenproblems derive generalization inverse power method guaranteed converge nonlinear eigenvector apply inverse power method spectral clustering sparse pca naturally formulated nonlinear eigenproblems application achieve state art result term solution quality runtime moving beyond standard eigenproblem useful also many application inverse power method easily adapted new problem', 'matrix factorization presence missing data core many computer vision problem structure motion sfm non rigid sfm photometric stereo formulate problem matrix factorization missing data low rank semidefinite program lrsdp advantage efficient quasi newton implementation lrsdp enables u solve large scale factorization problem additional constraint ortho normality required orthographic sfm directly incorporated new formulation empirical evaluation suggest condition matrix completion theory proposed algorithm find optimal solution also requires fewer observation compared current state art algorithm demonstrate effectiveness proposed algorithm solving affine sfm problem non rigid sfm photometric stereo problem', 'size color orientation long considered elementary feature whose attribute extracted parallel available guide deployment attention processed fashion simply different set local detector one would expect similar search behaviour localizing equivalent flickering change among identically laid disk analyze feature transition associated saccadic search find size color orientation alike dynamic attribute processing time markovian feature transition attractive size repulsive color largely reversible orientation', 'many real world scenario nearly impossible collect explicit social network data case whole network must inferred underlying observation formulate problem inferring latent social network based network diffusion disease propagation data consider contagion propagating edge unobserved social network observe time node became infected infected given node infection time identify optimal network best explains observed data present maximum likelihood approach based convex programming l like penalty term encourages sparsity experiment real synthetic data reveal method near perfectly recovers underlying network structure well parameter contagion propagation model moreover approach scale well infer optimal network thousand node matter minute', 'gaussian process gp popular way specify dependency random variable probabilistic model bayesian framework covariance structure specified using unknown hyperparameters integrating hyperparameters considers different possible explanation data making prediction integration often performed using markov chain monte carlo mcmc sampling however non gaussian observation standard hyperparameter sampling approach require careful tuning may converge slowly paper present slice sampling approach requires little tuning mixing well strong weak data regime', 'despite ubiquity clustering tool unsupervised learning yet consensus formal theory vast majority work direction focused unsupervised clustering study recently proposed framework supervised clustering access teacher give improved generic algorithm cluster concept class model algorithm query efficient sense involves small amount interaction teacher also present study two natural generalization model model assumes teacher response algorithm perfect eliminate limitation proposing noisy model give algorithm clustering class interval noisy model also propose dynamic model teacher see random subset point finally datasets satisfying spectrum weak strong property give query bound show class clustering function containing single linkage find target clustering strongest property', 'develop theory online learning defining several complexity measure among analogue rademacher complexity covering number fat shattering dimension statistical learning theory relationship among complexity measure connection online learning tool bounding provided apply result various learning problem provide complete characterization online learnability supervised setting', 'paper introduces first set pac bayesian bound batch reinforcement learning problem finite state space bound hold regardless correctness prior distribution demonstrate bound used model selection control problem prior information available either dynamic environment value action empirical result confirm pac bayesian model selection able leverage prior distribution informative unlike standard bayesian rl approach ignores misleading', 'tackle problem simultaneously detecting occlusion estimating optical flow show standard assumption lambertian reflection static illumination task posed convex minimization problem therefore solution computed using efficient algorithm guaranteed globally optimal number independently moving object number occlusion layer test proposed algorithm benchmark datasets expanded enable evaluation occlusion detection performance', 'computing two way multi way set similarity fundamental problem study focus estimating way resemblance jaccard similarity using b bit minwise hashing traditional minwise hashing method store hashed value using bit b bit minwise hashing store lowest b bit b way extension way similarity prior work way similarity technically non trivial develop precise estimator accurate complicated recommend much simplified estimator suitable sparse data analysis show b bit minwise hashing normally achieve fold improvement storage space required given estimator accuracy way resemblance', 'abstract missing', 'recent push extraction spatial layout scene however none approach model interaction object spatial layout paper argue parametric representation object allows u incorporate volumetric constraint physical world show augmenting current structured prediction technique volumetric reasoning significantly improves performance state art', 'several motor related brain computer interface bcis developed year use activity decoded contralateral hemisphere operate device many recent study also talked importance ipsilateral activity planning motor movement successful upper limb bcis important decode finger movement brain activity study us ipsilateral cortical signal human using ecog decode finger movement demonstrate first time successful finger movement detection using machine learning algorithm result show high decoding accuracy case always chance also show significant accuracy achieved use fraction feature recorded core feature also make sense physiologically result study great potential emerging world motor neuroprosthetics bcis', 'apply framework kernel dimension reduction originally designed supervised problem unsupervised dimensionality reduction framework kernel based measure independence used derive low dimensional representation maximally capture information covariates order predict response extend idea develop similarly motivated measure unsupervised problem covariates response empirical study show resulting compact representation yield meaningful appealing visualization clustering data furthermore used conjunction supervised learner classification method lead lower classification error state art method especially embedding data space dimension', 'study repeated zero sum game adversary budget given adversary constraint sequence action play consider ought player best mixed strategy knowledge budget show general class normal form game minimax strategy indeed efficiently computable relies random playout technique give three diverse application algorithmic template cost sensitive hedge setting particular problem metrical task system design combinatorial prediction market', 'max norm proposed convex matrix regularizer srebro et al shown empirically superior trace norm collaborative filtering problem although max norm computed polynomial time currently practical algorithm solving large scale optimization problem incorporate max norm present work us factorization technique burer monteiro devise scalable first order algorithm convex program involving max norm algorithm applied solve huge collaborative filtering graph cut clustering problem empirically new method outperform mature technique three area', 'consider multiple linear regression problem setting set relevant feature could shared across task lot recent research studied use ell ell q norm block regularization q possibly block structured problem establishing strong guarantee recovery even high dimensional scaling number feature scale number observation however paper also caution performance block regularized method dependent em extent feature shared across task indeed show citep nwjoint extent overlap le threshold even parameter em value shared feature highly uneven block ell ell q regularization could actually perform em worse simple separate elementwise ell regularization far away realistic multi task setting set relevant feature exactly across task value well ask question leverage support parameter overlap exists pay penalty indeed fall general question whether model emph dirty data may fall single neat structural bracket block sparse low rank take first step focusing developing dirty model multiple regression problem method us simple idea decompose parameter two component em regularize differently show theoretically empirically method strictly noticeably outperforms ell ell ell q method entire range possible overlap also provide theoretical guarantee method performs well high dimensional scaling', 'hypothesis testing point process several application model fitting plasticity detection non stationarity detection standard tool hypothesis testing include test mean firing rate time varying rate function however statistic fully describe point process thus test misleading paper introduce family non parametric divergence measure hypothesis testing extend traditional kolmogorov smirnov cramer von mi test point process via stratification proposed divergence measure compare underlying probability structure thus zero point process lead robust test hypothesis prove consistency show measure efficiently estimated data demonstrate application using proposed divergence cost function find optimally matched spike train', 'localise source sound use location specific property signal received two ear caused asymmetric filtering original sound head pinna head related transfer function hrtfs hrtfs change throughout organism lifetime development example required neural circuitry cannot entirely hardwired since hrtfs directly accessible perceptual experience inferred filtered sound present spiking neural network model sound localisation based extracting location specific synchrony pattern simple supervised algorithm learn mapping synchrony pattern location set example sound previous knowledge hrtfs learning model able accurately localise new sound azimuth elevation including difficult task distinguishing sound coming front back', 'learning multi view data important many application image classification annotation paper present large margin learning framework discover predictive latent subspace representation shared multiple view approach based undirected latent space markov network fulfills weak conditional independence assumption multi view observation response variable independent given set latent variable provide efficient inference parameter estimation method latent subspace model finally demonstrate advantage large margin learning real video web image data discovering predictive latent representation improving performance image classification annotation retrieval', 'cope concept drift placed probability distribution location recent drift point used bayesian model comparison update distribution prediction model trained block consecutive observation pruned potential drift point low probability compare approach non probabilistic method drift probabilistic method change point detection experiment approach generally yielded improved accuracy speed method', 'abstract missing', 'optimal coding provides guiding principle understanding representation sensory variable neural population consider influence prior probability distribution sensory variable optimal allocation cell spike neural population model spike cell sample independent poisson process rate governed associated tuning curve response model approximate fisher information term density amplitude tuning curve assumption tuning width varies inversely cell density consider family objective function based expected value sensory prior functional fisher information family includes lower bound mutual information perceptual discriminability special case case find closed form expression optimum density gain cell population power law function stimulus prior also implies power law relationship prior perceptual discriminability show preliminary evidence theory successfully predicts relationship empirically measured stimulus prior physiologically measured neural response property cell density tuning width firing rate psychophysically measured discrimination threshold', 'paper consider problem learning n x n kernel matrix similarity matrix general convex loss past research extensively studied case derived several algorithm require sophisticated technique like accp socp etc existing algorithm apply one us arbitrary loss often handle case present several provably convergent iterative algorithm iteration requires either svm multiple kernel learning mkl solver case one major contribution paper extend well known mirror descent md framework handle cartesian product psd matrix novel extension lead algorithm called emkl solves problem log n iteration iteration one solves mkl involving kernel eigen decomposition n x n matrix suitably defining restriction objective function faster version emkl proposed called rekl avoids eigen decomposition alternative emkl rekl also suggested requires svm solver experimental result real world protein data set involving several similarity matrix illustrate efficacy proposed algorithm', 'study application strongly non linear generative model image patch standard approach sparse coding independent component analysis model assumes sparse prior independent hidden variable however place standard approach use sum combine basis function use maximum derive tractable approximation parameter estimation apply novel approach based variational expectation maximization derived learning algorithm applied large scale problem hundred observed hidden variable furthermore infer model parameter including observation noise degree sparseness application image patch find gabor like basis function obtained gabor like function thus feature exclusive approach assuming linear superposition quantitatively inferred basis function show large diversity shape many strongly elongated many circular symmetric function distribution basis function shape reflects property simple cell receptive field reproduced standard linear approach study natural image statistic implication using different superposition assumption far investigated systematically model strong non linearity found analytically computationally challenging presented algorithm represents first large scale application approach', 'propose unsupervised method learning multi stage hierarchy sparse convolutional feature sparse coding become increasingly popular method learning visual feature often trained patch level applying resulting filter convolutionally result highly redundant code overlapping patch encoded isolation training convolutionally large image window method reduces redudancy feature vector neighboring location improves efficiency overall representation addition linear decoder reconstructs image sparse feature method train efficient feed forward encoder predicts quasi sparse feature input patch based training rarely produce anything oriented edge detector show convolutional training produce highly diverse filter including center surround filter corner detector cross detector oriented grating detector show using filter multi stage convolutional network architecture improves performance number visual recognition detection task', 'many structured prediction problem complex model often require adopting approximate inference technique variational method sampling generally provide satisfactory accuracy guarantee work propose sidestepping intractable inference altogether learning ensemble tractable sub model part structured prediction cascade focus particular problem high treewidth large state space occur many computer vision task unlike variational method ensemble enforce agreement sub model filter space possible output simply adding thresholding max marginals constituent model framework jointly estimate parameter model ensemble level cascade minimizing novel convex loss function yet requires linear increase computation learning inference single tractable sub model provide generalization bound filtering loss ensemble theoretical justification approach evaluate method synthetic data task estimating articulated human pose challenging video find approach significantly outperforms loopy belief propagation synthetic data state art model pose estimation tracking problem', 'abstract missing', 'convolutional neural network cnns successfully applied many task digit object recognition using convolutional tied weight signi cantly reduces number parameter learned also allows translational invariance hard coded architecture paper consider problem learning invariance rather relying hard coding propose tiled convolution neural network tiled cnns use regular tiled pattern tied weight require adjacent hidden unit share identical weight instead requires hidden unit k step away tied weight pooling neighboring unit architecture able learn complex invariance scale rotational invariance beyond translational invariance also enjoys much cnns advantage relatively small number learned parameter ease learning greater scalability provide efficient learning algorithm tiled cnns based topographic ica show learning complex invariant feature allows u achieve highly competitive result norb cifar datasets', 'study problem learning sparse linear regression vector additional condition structure sparsity pattern present family convex penalty function encode prior knowledge mean set constraint absolute value regression coefficient family subsumes ell norm flexible enough include different model sparsity pattern practical theoretical importance establish important property function discus example computed explicitly moreover present convergent optimization algorithm solving regularized least square penalty function numerical simulation highlight benefit structured sparsity advantage offered approach lasso related method', 'probabilistic model natural image usually evaluated measuring performance rather indirect task denoising inpainting direct way evaluate generative model draw sample check whether statistical property sample match statistic natural image method seldom used high resolution image current model produce sample different natural image assessed even simple visual inspection investigate reason failure show augmenting existing model two set latent variable one set modelling pixel intensity set modelling image specific pixel covariance able generate high resolution image look much realistic overall model interpreted gated mrf pair wise dependency mean intensity pixel modulated state latent variable finally confirm disallow weight sharing receptive field overlap gated mrf learns efficient internal representation demonstrated several recognition task', 'paper outline hierarchical bayesian model human category learning learns organization object category context knowledge applied model fit multiple data set provides parsimonious method describing human learn context specific conceptual representation', 'abstract missing', 'combine random forest rf conditional random field crf new computational framework called random forest random field rf inference rf us swendsen wang cut algorithm characterized metropolis hastings jump jump one state another depends ratio proposal distribution ratio posterior distribution two state prior work typically resort parametric estimation four distribution computes ratio key idea instead directly estimate ratio using rf rf collect leaf node decision tree class histogram training example use class histogram non parametric estimation distribution ratio derive theoretical error bound two class rf rf applied challenging task multiclass object recognition segmentation random field input image region empirical evaluation use visual information provided image region e g color texture spatial layout whereas competing method additionally use higher level cue horizon location layout surface scene nevertheless rf outperforms state art benchmark datasets term accuracy computation time', 'bayesian approach preference elicitation pe particularly attractive due ability explicitly model uncertainty user latent utility function however previous approach bayesian pe ignored important problem generalizing previous user unseen user order reduce elicitation burden new user paper address deficiency introducing gaussian process gp prior user latent utility function joint space user item feature learn hyper parameter gp set preference previous user use aid elicitation process new user approach provides flexible model multi user utility function facilitates efficient value information voi heuristic query selection strategy provides principled way incorporate elicitation multiple user back model show effectiveness method comparison previous work real dataset user preference sushi type', 'discus online learning framework agent allowed say know well making incorrect prediction given example analyze trade saying know making mistake number know prediction forced zero model reduces well known mistake bound model introduced littlestone lit hand mistake allowed model reduces kwik framework introduced li et al llw propose general though inefficient algorithm general finite concept class minimizes number know prediction certain number mistake allowed present specific polynomial time algorithm concept class monotone disjunction linear separator', 'paper tackle complex problem visually matching people similar pose different clothes background appearance change achieve novel method learning nonlinear embedding based several extension neighborhood component analysis nca framework method convolutional enabling scale realistically sized image cheaply labeling head hand large video database amazon mechanical turk crowd sourcing service use task localizing head hand proxy determining body pose apply method challenging real world data show generalize beyond hand localization infer general notion body pose evaluate method quantitatively embedding method also demonstrate real world performance improved use synthetic data', 'recent paper joachim presented svm perf cutting plane method cpm training linear support vector machine svms converges epsilon accurate solution epsilon iteration tightening analysis teo et al showed epsilon iteration suffice given impressive convergence speed cpm number practical problem conjectured rate could improved paper disprove conjecture present counter example applicable training linear svms hinge loss also hold support vector method optimize emph multivariate performance score however surprisingly problem inherently hard exploiting structure objective function devise algorithm converges sqrt epsilon iteration', 'predicting execution time computer program important challenging problem community computer system existing method require expert perform detailed analysis program code order construct predictor select important feature recently developed new system automatically extract large number feature program execution sample input prediction model constructed without expert knowledge paper study construction predictive model problem propose spore sparse polynomial regression methodology build accurate prediction model program performance using feature data collected program execution sample input two spore algorithm able build relationship response e g execution time computer program feature select hundred retrieved feature construct explicitly sparse non linear model predict response variable compact explicitly polynomial form estimated model could reveal important insight computer program e g feature non linear combination dominate execution time enabling better understanding program behavior evaluation three widely used computer program show spore method give accurate prediction relative error le using moderate number training data sample addition compare spore algorithm state art sparse regression algorithm show spore method motivated real application outperform method term interpretability prediction accuracy', 'recent work demonstrated artificial agent limited ability achieve goal agent designer benefit making agent goal different designer give rise optimization problem designing artificial agent goal rl framework designing agent reward function existing attempt solving optimal reward problem leverage experience gained online agent lifetime take advantage knowledge agent structure work develop gradient ascent approach formal convergence guarantee approximately solving optimal reward problem online agent lifetime show method generalizes standard policy gradient approach demonstrate ability improve reward function agent various form limitation', 'design low level image feature critical computer vision algorithm orientation histogram sift cite lowe distinctive hog cite dalal histogram successful popular feature visual object scene recognition highlight kernel view orientation histogram show equivalent certain type match kernel image patch novel view allows u design family kernel descriptor provide unified principled framework turn pixel attribute gradient color local binary pattern etc compact patch level feature particular introduce three type match kernel measure similarity image patch construct compact low dimensional kernel descriptor match kernel using kernel principal component analysis kpca cite scholkopf nonlinear kernel descriptor easy design turn type pixel attribute patch level feature outperform carefully tuned sophisticated feature including sift deep belief network report superior performance standard image classification benchmark scene caltech cifar cifar imagenet', 'standard strategy efficient object detection consists building cascade composed several binary classifier detection process take form lazy evaluation conjunction response classifier concentrate computation difficult part image trivially rejected introduce novel algorithm construct jointly classifier cascade interpret response classifier probability positive prediction overall response cascade probability prediction positive noisy model derive consistent loss boosting procedure optimize global probability training set joint learning allows individual predictor focus restricted modeling problem improves performance compared standard cascade demonstrate efficiency approach face pedestrian detection standard data set comparison reference baseline', 'upstream supervised topic model widely used complicated scene understanding however existing maximum likelihood estimation mle scheme make prediction model learning independent latent topic discovery result imbalanced prediction rule scene classification paper present joint max margin max likelihood learning method upstream scene understanding model latent topic discovery prediction model estimation closely coupled well balanced optimization problem efficiently solved variational em procedure iteratively solves online loss augmented svm demonstrate advantage large margin approach category sport dataset class mit indoor scene dataset scene categorization', 'abstract missing', 'recently variant l norm particularly matrix norm l l infty norm widely used multi task learning compressed sensing related area enforce sparsity via joint regularization paper unify l l infty norm considering family l q norm q le infty study problem determining appropriate sparsity enforcing norm use context multi task feature selection using generalized normal distribution provide probabilistic interpretation general multi task feature selection problem using l q norm based probabilistic interpretation develop probabilistic model using noninformative jeffreys prior also extend model learn exploit general type pairwise relationship task version model devise expectation maximization em algorithm learn model parameter including q automatically experiment conducted two cancer classification application using microarray gene expression data', 'abstract missing', 'consider problem one incomplete binary matrix evolve time e g vote legislator particular legislation year characterized different matrix objective analysis infer structure inter relationship underlying matrix defined latent feature associated axis matrix addition assumed document available entity associated least one matrix ax jointly analyzing matrix document one may used inform within analysis model offer opportunity predict matrix value e g vote based associated document e g legislation research presented merges two area machine learning previously investigated separately incomplete matrix analysis topic modeling analysis performed bayesian perspective efficient inference constituted via gibbs sampling framework demonstrated considering voting data available document legislation year lifetime united state senate house representative', 'recent study compare gene expression data across specie identify core specie specific gene biological system perform comparison researcher need match gene across specie challenging task since correct match orthologs known gene previous work area used deterministic matchings reduced multidimensional expression data binary representation develop new method utilize soft match given prior infer unique similar expression pattern across specie matching gene specie method us dirichlet process mixture model includes latent data matching variable present learning inference algorithm based variational method model applying method immune response data show accurately identify common unique response pattern improving matchings human mouse gene', 'principled way learn probabilistic discriminative classifier unlabeled data set present framework simultaneously cluster data train discriminative classifier call regularized information maximization rim rim optimizes intuitive information theoretic objective function balance class separation class balance classifier complexity approach flexibly incorporate different likelihood function express prior assumption relative size different class incorporate partial label semi supervised learning particular instantiate framework unsupervised multi class kernelized logistic regression empirical evaluation indicates rim outperforms existing method several real data set demonstrates rim effective model selection method', 'functional viewpoint spiking neuron device transforms input spike train various synapsis output spike train axon demonstrate paper function mapping underlying device tractably learned based input output spike train data alone begin posing problem classification based framework derive novel kernel srm model based psp ahp like function kernel demonstrate learning problem posed quadratic program experimental result demonstrate strength approach', 'paper present analysis importance weighting learning finite sample give series theoretical algorithmic result point simple case importance weighting fail suggests need analysis property technique give upper lower bound generalization bounded importance weight significantly give learning guarantee common case unbounded importance weight weak assumption second moment bounded condition related renyi divergence training test distribution result based series novel general bound derive unbounded loss function independent interest use bound guide definition alternative reweighting algorithm report result experiment demonstrating benefit finally analyze property normalized importance weight also commonly used', 'present fast algorithm detection multiple change point frequently shared member set co occurring one dimensional signal give condition consistency method number signal increase provide empirical evidence support consistency result', 'propose discriminative model recognizing group activity model jointly capture group activity individual person action interaction among two new type contextual information group person interaction person person interaction explored latent variable framework different previous latent structured model assume predefined structure hidden layer e g tree structure treat structure hidden layer latent variable implicitly infer learning inference experimental result demonstrate inferring contextual information together adaptive structure proposed model significantly improve activity recognition performance', 'paper consider fundamental problem semi supervised kernel function learning propose general regularized framework learning kernel matrix demonstrate equivalence proposed kernel matrix learning framework general linear transformation learning problem result show learned kernel matrix parameterize linear transformation kernel function applied inductively new data point furthermore result give constructive method kernelizing existing mahalanobis metric learning formulation make result practical large scale data modify framework limit number parameter optimization process also consider problem kernelized inductive dimensionality reduction semi supervised setting introduce novel method problem considering special case general kernel learning framework select trace norm function regularizer empirically demonstrate framework learns useful kernel function improving k nn classification accuracy significantly variety domain furthermore kernelized dimensionality reduction technique significantly reduces dimensionality feature space achieving competitive classification accuracy', 'abstract missing', 'consider problem apprenticeship learning example demonstrated expert cover small part large state space inverse reinforcement learning irl provides efficient tool generalizing demonstration based assumption expert maximizing utility function linear combination state action feature irl algorithm use simple monte carlo estimation approximate expected feature count expert policy paper show quality learned policy highly sensitive error estimating feature count reduce error introduce novel approach bootstrapping demonstration assuming expert near optimal ii dynamic system known empirical result gridworlds car racing problem show approach able learn good policy small number demonstration', 'propose novel bayesian nonparametric approach learning probabilistic deterministic finite automaton pdfa define develop sampler pdfa infinite number state call probabilistic deterministic infinite automaton pdia posterior predictive inference model given finite training sequence interpreted averaging multiple pdfas varying structure pdfa biased towards state suggest method averaging pdfas novel approach predictive distribution smoothing test pdia inference pdfa structure learning natural language dna data prediction task result suggest pdia present attractive compromise computational cost hidden markov model storage requirement hierarchically smoothed markov model', 'half century psychologist struck poor people expressing internal sensation impression evaluation via rating scale individual make judgment incapable using absolute rating scale instead rely reference point recent experience relativity judgment limit usefulness response provided individual survey questionnaire evaluation form fortunately cognitive process transform internal state response simply noisy rather influenced recent experience lawful manner explore technique remove sequential dependency thereby decontaminate series rating obtain meaningful human judgment formulation decontamination fundamentally problem inferring latent state internal sensation relativity judgment temporal dependency propose decontamination solution using conditional random field constraint motivated psychological theory relative judgment exploration decontamination model supported two experiment conducted obtain ground truth rating data simple length estimation task decontamination technique yield reduction error human judgment', 'present novel method multitask learning mtl based manifold regularization assume task parameter lie manifold generalization common assumption made existing literature task parameter share common linear subspace one proposed method us projection distance manifold regularize task parameter manifold structure task parameter learned using alternating optimization framework manifold structure fixed method decomposes across task learnt independently approximation manifold regularization scheme presented preserve convexity single task learning problem make proposed mtl framework efficient easy implement show efficacy method several datasets', 'goal decentralized optimization network optimize global objective formed sum local possibly nonsmooth convex function using local computation communication develop analyze distributed algorithm based dual averaging subgradients provide sharp bound convergence rate function network size topology analysis clearly separate convergence optimization algorithm effect communication constraint arising network structure show number iteration required algorithm scale inversely spectral gap network sharpness prediction confirmed theoretical lower bound simulation various network', 'computing em maximum posteriori map assignment graphical model crucial inference problem many practical application several provably convergent approach successfully developed using linear programming lp relaxation map problem present alternative approach transforms map problem inference finite mixture simple bayes net derive expectation maximization em algorithm mixture also monotonically increase lower bound map assignment convergence update equation em algorithm remarkably simple conceptually computationally implemented using graph based message passing paradigm similar max product computation experiment real world protein design dataset show em convergence rate significantly higher previous lp relaxation based approach mplp em achieves solution quality within optimal instance often order magnitude faster mplp', 'consider structured multi armed bandit task agent guided prior structural knowledge exploited efficiently select optimal arm situation number arm large even infinite pro pose new optimistic ucb like algorithm non linearly parameterized bandit problem using generalized linear model glm framework analyze regret proposed algorithm termed glm ucb obtaining result similar recently proved literature linear regression case analysis also highlight key difficulty non linear case solved glm ucb focusing reward space rather parameter space moreover actual efficiency current parameterized bandit algorithm often deceiving practice provide asymptotic argument leading significantly faster convergence simulation study real data set illustrate performance robustness proposed glm ucb approach', 'optimal control entail combining probability utility however practical problem probability density represented approximately choosing approximation requires balancing benefit accurate approximation cost computing propose variational framework achieving balance apply problem population code optimally represent distribution resource constraint essence analysis conjecture population code organized maximize lower bound log expected utility theory account plethora experimental data including reward modulation sensory receptive field', 'last year support vector machine svms successfully applied even situation input space x necessarily subset r example include svms using probability measure analyse e g histogram coloured image svms text classification web mining svms application computational biology using e g kernel tree graph moreover svms known consistent bayes risk either input space complete separable metric space reproducing kernel hilbert space rkhs h subset l p p x dense svm based universal kernel k far however rkhss practical interest known satisfy assumption ch k x subset r close gap providing general technique based taylor type kernel explicitly construct universal kernel compact metric space subset r apply technique following special case universal kernel set probability measure universal kernel based fourier transforms universal kernel signal processing', 'straightforward application deep belief net dbns acoustic modeling produce rich distributed representation speech data useful recognition yield impressive result speaker independent timit phone recognition task however first layer gaussian bernoulli restricted boltzmann machine grbm important limitation shared mixture diagonal covariance gaussians grbms treat different component acoustic input vector conditionally independent given hidden state mean covariance restricted boltzmann machine mcrbm first introduced modeling natural image much representationally efficient powerful way modeling covariance structure speech data every configuration precision unit mcrbm specifies different precision matrix conditional distribution acoustic space work use mcrbm learn feature speech data serve input standard dbn mcrbm feature combined dbns allow u achieve phone error rate superior published result speaker independent timit date', 'abstract missing', 'abstract missing', 'game incomplete information bayesian game important game theoretic model many application economics propose bayesian action graph game baggs novel graphical representation bayesian game baggs represent arbitrary bayesian game furthermore compactly express bayesian game exhibiting commonly encountered type structure including symmetry action type specific utility independence probabilistic independence type distribution provide algorithm computing expected utility baggs discus condition algorithm run polynomial time bayes nash equilibrium baggs computed adapting existing algorithm complete information normal form game leveraging expected utility algorithm show theoretically empirically approach improve significantly state art', 'propose algorithm simultaneously estimating state transition among neural state number neural state nonstationary firing rate using switching state space model sssm model enables u detect state transition based discontinuous change mean firing rate also discontinuous change temporal profile firing rate e g temporal correlation derive variational bayes algorithm non gaussian sssm whose non gaussian property caused binary spike event synthetic data analysis reveals high performance algorithm estimating state transition number neural state nonstationary firing rate compared previous method also analyze neural data recorded medial temporal area statistically detected neural state probably coincide transient sustained state detected heuristically estimated parameter suggest algorithm detects state transition based discontinuous change temporal correlation firing rate transition previous method cannot detect result suggests advantage algorithm real data analysis', 'propose novel method inferring whether x cause vice versa joint observation x basic idea model observed data using probabilistic latent variable model incorporate effect unobserved noise end consider hypothetical effect variable function hypothetical cause variable independent noise term necessarily additive important novel aspect work restrict model class instead put general non parametric prior function distribution cause causal direction inferred using standard bayesian model selection evaluate approach synthetic data real world data report encouraging result', 'introduce new bayesian nonparametric approach identification sparse dynamic linear system impulse response modeled gaussian process whose autocovariances encode bibo stability constraint defined recently introduced stable spline kernel sparse solution obtained placing exponential hyperpriors scale factor kernel numerical experiment regarding estimation armax model show technique provides definite advantage group lar algorithm state art parametric identification technique based prediction error minimization', 'markov network mn incorporate arbitrarily complex feature modeling relational data however flexibility come sharp price training exponentially complex model address challenge propose novel relational learning approach consists restricted class relational mn rmns called relation tree based rmn treermn efficient hidden variable detection algorithm called contrastive variable induction cvi one hand restricted treermn considers simple e g unary pairwise feature relational data thus achieves computational efficiency hand cvi algorithm efficiently detects hidden variable capture long range dependency therefore resultant approach highly efficient yet sacrifice expressive power empirical result four real datasets show proposed relational learning method achieve similar prediction quality state art approach significantly efficient training induced hidden variable semantically meaningful crucial improve training speed prediction quality treermns', 'active learning approach select either informative representative unlabeled instance query label although several active learning algorithm proposed combine two criterion query selection usually ad hoc finding unlabeled instance informative representative address challenge principled approach termed quire based min max view active learning proposed approach provides systematic way measuring combining informativeness representativeness instance extensive experimental result show proposed quire approach outperforms several state art active learning approach', 'recent study shown multiple kernel learning effective object recognition leading popularity kernel learning computer vision problem work develop efficient algorithm multi label multiple kernel learning ml mkl assume class consideration share combination kernel function objective find optimal kernel combination benefit class although several algorithm developed ml mkl computational cost linear number class making unscalable number class large challenge frequently encountered visual object recognition address computational challenge developing framework ml mkl combine worst case analysis stochastic approximation analysis show complexity algorithm sqrt ln number class empirical study object recognition show achieving similar classification accuracy proposed method significantly efficient state art algorithm ml mkl', 'propose new nonparametric learning method based multivariate dyadic regression tree mdrts unlike traditional dyadic decision tree ddt classification regression tree cart mdrts constructed using penalized empirical risk minimization novel sparsity inducing penalty theoretically show mdrts simultaneously adapt unknown sparsity smoothness true regression function achieve nearly optimal rate convergence minimax sense class alpha c smooth function empirically mdrts simultaneously conduct function estimation variable selection high dimension make mdrts applicable large scale learning problem propose greedy heuristic superior performance mdrts demonstrated synthetic real datasets', 'estimating pose monocular image highly ambiguous problem physical constraint exploited restrict space feasible configuration paper propose approach constraining prediction discriminative predictor first show mean prediction gaussian process implicitly satisfies linear constraint constraint satisfied training example show performing change variable gp forced satisfy quadratic constraint evidenced experiment method outperforms state art approach task rigid non rigid pose estimation', 'abstract missing', 'provide new theoretical result apprenticeship learning variant reinforcement learning true reward function unknown goal perform well relative observed expert study common approach learning expert demonstration using classification algorithm learn imitate expert behavior although straightforward learning strategy widely used practice subject little formal analysis prove learned classifier error rate eps difference value apprentice policy expert policy sqrt eps prove difference eps expert policy close optimal latter result important practical consequence imitating near optimal expert result better policy far fewer demonstration required successfully imitate expert suggests opportunity substantial saving whenever expert known good demonstration expensive difficult obtain', 'address question approximation error bellman residual iteration approximate policy value iteration algorithm influence quality resulted policy quantify performance loss lp norm approximation error bellman residual iteration moreover show performance loss depends expectation squared radon nikodym derivative certain distribution rather supremum opposed suggested previous result also result indicate contribution approximation bellman error performance loss prominent later iteration api avi effect error term earlier iteration decay exponentially fast', 'paper consider problem policy evaluation continuous state system present non parametric approach policy evaluation us kernel density estimation represent system true form value function model determined computed using galerkin method furthermore also present unified view several well known policy evaluation method particular show galerkin method used derive least square temporal difference learning kernelized temporal difference learning discrete state dynamic programming solution well proposed method numerical evaluation algorithm proposed approach performed better method', 'many application computer vision measure similarity image image patch based statistic oriented gradient often modeled implicitly explicitly gaussian noise assumption leading use euclidean distance comparing image descriptor paper show statistic gradient based image descriptor often follow heavy tailed distribution undermines principled motivation use euclidean distance advocate use distance measure based likelihood ratio test appropriate probabilistic model fit empirical data distribution instantiate similarity measure gamma compound laplace distribution show significant improvement existing distance measure application sift feature matching relatively low computational cost', 'study multi label prediction structured output space problem occurs example object detection image secondary structure prediction computational biology graph matching symmetry conventional multi label classification technique typically applicable situation require explicit enumeration label space infeasible case structured output relying technique originally designed single label structured prediction particular structured support vector machine result reduced prediction accuracy lead infeasible optimization problem work derive maximum margin training formulation multi label structured prediction remains computationally tractable achieving high prediction accuracy also share beneficial property single label maximum margin approach particular formulation convex optimization problem efficient working set training pac bayesian generalization bound', 'study family p resistance graph p family generalizes standard resistance distance prove fixed graph p p resistance coincides shortest path distance p coincides standard resistance distance p converges inverse minimal cut graph secondly consider special case random geometric graph k nearest neighbor graph number n vertex graph tends infinity prove interesting phase transition take place exist two critical threshold p p p p p resistance depends meaningful global property graph whereas p p depends trivial local quantity convey useful information explicitly compute critical value p p dimension underlying space believe fact small gap p p artifact proof also relate finding laplacian regularization suggest use q laplacians regularizers q satisfies p q', 'propose maximum covariance unfolding mcu manifold learning algorithm simultaneous dimensionality reduction data different input modality given high dimensional input two different naturally aligned source mcu computes common low dimensional embedding maximizes cross modal inter source correlation preserving local intra source distance paper explore two application mcu first use mcu analyze eeg fmri data important goal visualize fmri voxels strongly correlated change eeg trace perform visualization augment mcu additional step metric learning high dimensional voxel space second use mcu perform cross modal retrieval matched image text sample wikipedia manage large application mcu develop fast implementation based idea spectral graph theory idea transform original problem mcu one semidefinite programming simpler problem semidefinite quadratic linear programming', 'possible crowdsource categorization amongst challenge annotator partial view data b different annotator may different clustering criterion may produce different number category c underlying category structure may hierarchical propose bayesian model annotator may approach clustering show one may infer cluster category well annotator parameter using model experiment carried large collection image suggest bayesian crowdclustering work well may superior single expert annotation', 'present new algorithm exactly solving decision making problem represented influence diagram require usual assumption forgetting regularity allows u solve problem limited information algorithm implement sophisticated variable elimination procedure empirically shown outperform state art algorithm randomly generated problem variable strategy', 'propose novel generative model able reason jointly scene layout well location orientation object scene particular infer scene topology geometry well traffic activity short video sequence acquired single camera mounted moving car generative model take advantage dynamic information form vehicle tracklets well static information coming semantic label geometry e vanishing point experiment show approach outperforms discriminative baseline based multiple kernel learning mkl access image information furthermore reason object able significantly increase performance state art object detector ability estimate object orientation', 'abstract missing', 'study problem active learning stream based setting allowing distribution example change time prove upper bound number prediction mistake number label request established disagreement based active learning algorithm realizable case tsybakov noise prove minimax lower bound problem', 'method decision theoretic online learning based hedge algorithm take parameter called learning rate previous analysis learning rate carefully tuned obtain optimal worst case performance leading suboptimal performance easy instance example exists action significantly better others propose new way setting learning rate adapts difficulty learning problem worst case procedure still guarantee optimal performance easy instance achieves much smaller regret particular adaptive method achieves constant regret probabilistic setting exists action average obtains strictly smaller loss action also provide simulation study comparing approach existing method', 'matrix completion given matrix value entry present want reconstruct missing one much work focused assumption data matrix low rank propose general assumption based denoising expect value missing entry predicted value neighboring point propose nonparametric version denoising based local iterated averaging mean shift possibly constrained preserve local low rank manifold structure user parameter required denoising scale number neighbor local dimensionality number iteration estimated cross validating reconstruction error using algorithm postprocessing step initial reconstruction provided e g low rank method show consistent improvement synthetic image motion capture data', 'recently substantial interest using large amount unlabeled data learn word representation used feature supervised classifier nlp task however current approach slow train model context word lack theoretical grounding paper present new learning method low rank multi view learning lr mvl us fast spectral method estimate low dimensional context specific word representation unlabeled data representation feature used supervised learner lr mvl extremely fast give guaranteed convergence global optimum theoretically elegant achieves state art performance named entity recognition ner chunking problem', 'present novel regularization based multitask learning mtl formulation structured output prediction case hierarchical task relation structured output learning often result dif cult inference problem requires large amount training data obtain accurate model propose use mtl exploit information available related structured output learning task mean hierarchical regularization due combination example set cost training model structured output prediction easily become infeasible real world application thus propose ef cient algorithm based bundle method solve optimization problem resulting mtl structured output learning demonstrate performance approach gene nding problem application domain computational biology show proposed solver achieves much faster convergence previous method hierarchical mtl approach clearly outperforms considered non mtl method', 'discriminative learning training test data belong different distribution challenging complex task often time labeled data test target distribution may plenty labeled data multiple related source different distribution difference distribution may marginal conditional probability existing domain adaptation work focus marginal probability distribution difference domain assuming conditional probability similar however many real world application conditional probability distribution difference commonplace marginal probability difference paper propose two stage domain adaptation methodology combine weighted data multiple source based marginal probability difference first stage well conditional probability difference second stage target domain data weight minimizing marginal probability difference estimated independently weight minimizing conditional probability difference computed simultaneously exploiting potential interaction among multiple source also provide theoretical analysis generalization performance proposed multi source domain adaptation formulation using weighted rademacher complexity measure empirical comparison existing state art domain adaptation method using three real world datasets demonstrate effectiveness proposed approach', 'principal component analysis pca often used feature extraction procedure given matrix x mathbb r n time whose row represent n data point respect feature top k right singular vector x called textit eigenfeatures arbitrary linear combination available feature eigenfeatures useful data analysis including regularization linear regression enforcing sparsity eigenfeatures e forcing linear combination textit small number actual feature opposed available feature promote better generalization error improve interpretability eigenfeatures present deterministic randomized algorithm construct sparse eigenfeatures emph provably achieving sample performance comparable regularized linear regression algorithm relatively simple practically efficient demonstrate performance several data set', 'consider problem learning rule natural language text source source news article web text created writer communicate information reader writer reader share substantial domain knowledge consequently text tend concise mention minimum information necessary reader draw correct conclusion study problem learning domain knowledge concise text instance general problem learning presence missing data however unlike standard approach missing data setting know fact likely missing text case reader infer fact mentioned combined domain knowledge hence explicitly model missingness process invert via probabilistic inference learn underlying domain knowledge paper introduces mention model model probability fact mentioned text based fact already mentioned domain knowledge form horn clause rule learning must simultaneously search space rule learn parameter mention model accomplish via application expectation maximization within markov logic framework experimental evaluation synthetic natural text data show method learn accurate rule apply new text make correct inference experiment also show method performs standard em approach assumes mention missing random', 'recent year semidefinite optimization become tool major importance various optimization machine learning problem many problem amount data practice large constant need faster algorithm work present first sublinear time approximation algorithm semidefinite program believe may useful problem size data may cause even linear time algorithm prohibitive running time practice present algorithm analysis alongside theoretical lower bound improved algorithm special problem supervised learning distance metric', 'knowledge based support vector machine kbsvms incorporate advice domain expert improve generalization significantly major limitation fully addressed occurs expert advice imperfect lead poorer model propose model extends kbsvms able learn data advice also simultaneously improve advice proposed approach particularly effective knowledge discovery domain labeled example proposed model contains bilinear constraint solved using two iterative approach successive linear programming constrained concave convex approach experimental result demonstrate algorithm yield useful refinement expert advice well improve performance learning algorithm overall', 'abstract missing', 'abstract missing', 'paper give new generalization error bound multiple kernel learning mkl general class regularization main target paper dense type regularization including p mkl imposes p mixed norm regularization instead mixed norm regularization according recent numerical experiment sparse regularization necessarily show good performance compared dense type regularization motivated fact paper give general theoretical tool derive fast learning rate applicable arbitrary monotone norm type regularization unifying manner product general result show fast learning rate p mkl tightest among existing bound also show general learning rate achieves minimax lower bound finally show complexity candidate reproducing kernel hilbert space inhomogeneous dense type regularization show better learning rate compared sparse regularization', 'graph cut optimization one standard workhorse image segmentation since binary random field representation image give globally optimal result efficient polynomial time implementation often random field applied flat partitioning image non intersecting element pixel super pixel paper show instead flat partitioning image represented hierarchical segmentation tree resulting energy combining unary boundary term still optimized using graph cut corresponding benefit global optimality efficiency result inference image get partitioned set segment may come different layer tree apply formulation call pylon model task semantic segmentation goal separate image area belonging different semantic class experiment highlight advantage inference segmentation tree flat partitioning demonstrate optimization pylon model able flexibly choose level segmentation across image overall proposed system superior segmentation accuracy several datasets graz stanford background compared previously suggested approach', 'many clustering technique aim optimizing empirical criterion form u statistic degree two given measure dissimilarity pair observation goal minimize within cluster point scatter class partition feature space purpose paper define general statistical framework relying theory u process studying performance clustering method setup adequate assumption complexity subset forming partition candidate excess clustering risk proved order sqrt n based recent result related tail behavior degenerate u process also shown establish tighter rate bound model selection issue related number cluster forming data partition particular also considered', 'paper considers problem combining multiple model achieve prediction accuracy much worse best single model least square regression known model mi specified model averaging superior model selection specifically let n sample size worst case regret former decay rate n worst case regret latter decay rate sqrt n literature important widely studied model averaging method achieves optimal n average regret exponential weighted model averaging ewma algorithm however method suffers several limitation purpose paper present new greedy model averaging procedure improves ewma prove strong theoretical guarantee new procedure illustrate theoretical result empirical example', 'abstract missing', 'many specie show avoidance reaction response looming object approach locust corresponding escape behavior correlate activity lobula giant movement detector lgmd neuron object approach firing rate reported gradually increase peak reached decline quickly eta function predicts lgmd activity product exponential function angular size exp theta angular velocity dot theta peak activity reached time contact ttc eta function become prevailing lgmd model reproduces many experimental observation even experimental evidence multiplicative operation reported several inconsistency remain unresolved though address issue new model psi model explicitly connects theta dot theta biophysical quantity psi model avoids biophysical problem associated implementing exp cdot implement multiplicative operation eta via divisive inhibition explains activity peak could occur ttc consistently predicts response feature lgmd provides excellent fit published experimental data goodness fit measure comparable corresponding fit eta function', 'paper present approach predicts effectiveness hiv combination therapy simultaneously addressing several problem affecting available hiv clinical data set different treatment background sample uneven representation level therapy experience missing treatment history information uneven therapy representation unbalanced therapy outcome representation computational validation clinical data show compared commonly used approach account issue mentioned model significantly higher predictive power especially true sample stemming patient longer treatment history sample associated rare therapy furthermore approach least powerful remaining sample', 'paper proposes novel boosting algorithm called vadaboost motivated recent empirical bernstein bound vadaboost iteratively minimizes cost function balance sample mean sample variance exponential loss step proposed algorithm minimizes cost efficiently providing weighted data weak learner rather requiring brute force evaluation possible weak learner thus proposed algorithm solves key limitation previous empirical bernstein boosting method required brute force enumeration possible weak learner experimental result confirm new algorithm achieves performance improvement ebboost yet go beyond decision stump handle weak learner significant performance gain obtained adaboost arbitrary weak learner including decision tree cart', 'work considers problem learning structure multivariate linear tree model include variety directed tree graphical model continuous discrete mixed latent variable linear gaussian model hidden markov model gaussian mixture model markov evolutionary tree setting one sample certain observed variable tree goal estimate tree structure e graph underlying hidden variable connected observed variable propose spectral recursive grouping algorithm efficient simple bottom procedure recovering tree structure independent sample observed variable finite sample size bound exact recovery tree structure reveal certain natural dependency underlying statistical structural property underlying joint distribution furthermore sample complexity guarantee explicit dependence dimensionality observed variable making algorithm applicable many high dimensional setting heart algorithm spectral quartet test determining relative topology quartet variable second order statistic', 'discrete undirected graphical model conditional independence node label specified graph structure study case another input random vector x e g observed feature distribution p x determined function x characterize higher order interaction among main contribution paper learn graph structure function conditioned x time prove discrete undirected graphical model feature x equivalent mul tivariate discrete model reparameterization potential function graphical model conditional log odds ratio latter offer advantage representation conditional independence structure functional space flexibly determined kernel additionally impose structure lasso slasso penalty group function learn graph structure group overlap designed enforce hierarchical function selection way able shrink higher order interaction obtain sparse graph structure', 'abstract missing', 'accurate model patient survival time help treatment care cancer patient common practice providing survival time estimate based population average site stage cancer ignores many important individual difference among patient paper propose local regression method learning patient specific survival time distribution based patient attribute blood test clinical assessment tested cohort cancer patient method give survival time prediction much accurate popular survival analysis model cox aalen regression model result also show using patient specific attribute reduce prediction error survival time much compared using cancer site stage', 'propose novel class bayesian nonparametric model sequential data called fragmentation coagulation process fcps fcps model set sequence using partition valued markov process evolves splitting merging cluster fcp exchangeable projective stationary reversible equilibrium distribution given chinese restaurant process opposed hidden markov model fcps allow flexible modelling number cluster avoid label switching non identifiability problem develop efficient gibbs sampler fcps us uniformization forward backward algorithm development fcps motivated application population genetics demonstrate utility fcps problem genotype imputation phased unphased snp data', 'present novel approach efficiently learn label tree large scale classification many class key contribution approach technique simultaneously determine structure tree learn classifier node tree approach also allows fine grained control efficiency v accuracy trade designing label tree leading balanced tree experiment performed large scale image classification class million image demonstrate significant improvement test accuracy efficiency le training time balanced tree compared previous state art bengio et al', 'multiclass prediction problem classifying object relevant target class consider problem learning multiclass predictor us feature particular number used feature increase sub linearly number possible class implies feature shared several class describe analyze shareboost algorithm learning multiclass predictor us shared feature prove shareboost efficiently find predictor us shared feature predictor exists small generalization error also describe use shareboost learning non linear predictor fast evaluation time series experiment natural data set demonstrate benefit shareboost evaluate success relatively state art approach', 'state art statistical method neuroscience enabled u fit mathematical model experimental data subsequently infer dynamic hidden parameter underlying observable phenomenon develop bayesian method inferring time varying mean variance synaptic input along dynamic ion channel single voltage trace neuron estimation problem may formulated basis state space model prior distribution penalize large fluctuation parameter optimizing hyperparameters maximizing marginal likelihood state space model provides time varying parameter input signal ion channel state proposed method tested simulated data hodgkin huxley type model also experimental data obtained cortical slice vitro', 'many experiment data point collected live high dimensional observation space yet assigned set label parameter electrophysiological recording instance response population neuron generally depend mixture experimentally controlled parameter heterogeneity diversity parameter dependency make visualization interpretation data extremely difficult standard dimensionality reduction technique principal component analysis pca provide succinct complete description data description constructed independent relevant task variable often hard interpret start assumption particularly informative description one reveals dependency high dimensional data individual parameter show modify loss function pca principal component seek capture maximum amount variance data also depending minimum number parameter call method demixed principal component analysis dpca principal component segregate parameter dependency phrase problem probabilistic graphical model present fast expectation maximization em algorithm demonstrate use algorithm electrophysiological data show serf demix parameter dependence neural population response', 'prove new oracle inequality support vector machine gaussian rbf kernel solving regularized least square regression problem end apply modulus smoothness help new oracle inequality derive learning rate also achieved simple data dependent parameter selection method finally turn learning rate asymptotically optimal regression function satisfying certain standard smoothness condition', 'kernel based reinforcement learning kbrl method learning decision policy set sample transition stand strong theoretical guarantee however size approximator grows number transition make approach impractical large problem paper introduce novel algorithm improve scalability kbrl resort special decomposition transition matrix called stochastic factorization fix size approximator time incorporating information contained data resulting algorithm kernel based stochastic factorization kbsf much faster still converges unique solution derive theoretical upper bound distance value function computed kbrl kbsf effectiveness method illustrated computational experiment four reinforcement learning problem including difficult task goal learn neurostimulation policy suppress occurrence seizure epileptic rat brain empirically demonstrate proposed approach able compress information contained kbrl model also task studied kbsf outperforms two prominent reinforcement learning algorithm namely least square policy iteration fitted q iteration', 'consider problem identifying sparse set relevant column row large data matrix highly corrupted entry problem identifying group collection bipartite variable protein drug biological specie gene sequence malware signature etc commonly referred biclustering co clustering despite great practical relevance although several ad hoc method available biclustering theoretical analysis problem largely non existent problem consider also closely related structured multiple hypothesis testing area statistic recently witnessed flurry activity make following contribution prove lower bound minimum signal strength needed successful recovery bicluster function noise variance size matrix bicluster interest ii show combinatorial procedure based scan statistic achieves optimal limit iii characterize snr required several computationally tractable procedure biclustering including element wise thresholding column row average thresholding convex relaxation approach sparse singular vector decomposition', 'paper derive method refine bayes network diagnostic model exploiting constraint implied expert decision test ordering step expert executes evidence gathering test suggests test relative diagnostic value demonstrate consistency expert test selection lead non convex constraint model parameter incorporate constraint augmenting network node represent constraint likelihood gibbs sampling stochastic hill climbing greedy search algorithm proposed find map estimate take account test ordering constraint data available demonstrate approach diagnostic session manufacturing scenario', 'abstract missing', 'many setting wish fit model behavior individual data consist aggregate information count low dimensional contingency table paper introduces collective graphical model framework modeling probabilistic inference operates directly sufficient statistic individual model derive highly efficient gibbs sampling algorithm sampling posterior distribution sufficient statistic conditioned noisy aggregate observation prove correctness demonstrate effectiveness experimentally', 'introduce gaussian process model function additive additive function one decomposes sum low dimensional function depending subset input variable additive gps generalize generalized additive model standard gp model use squared exponential kernel hyperparameter learning model seen bayesian hierarchical kernel learning hkl introduce expressive tractable parameterization kernel function allows efficient evaluation input interaction term whose number exponential input dimension additional structure discoverable model result increased interpretability well state art predictive power regression task', 'study problem reconstructing unknown matrix rank r dimension using rd polylog pauli measurement application quantum state tomography non commutative analogue well known problem compressed sensing recovering sparse vector fourier coefficient show almost set rd log pauli measurement satisfy rank r restricted isometry property rip implies recovered fixed universal set pauli measurement using nuclear norm minimization e g matrix lasso nearly optimal bound error similar result hold class measurement use orthonormal operator basis whose element small operator norm proof us dudley inequality gaussian process together bound covering number obtained via entropy duality', 'consider multi armed bandit problem two phase first phase experimentation phase decision maker free explore multiple option second phase decision maker commit one arm stick cost incurred phase higher cost experimentation phase analyze regret setup propose algorithm provide upper lower bound depend ratio duration experimentation phase duration commitment phase analysis reveals given choice optimal experiment theta ln step commit time horizon', 'investigate discriminatively trained model person object interaction recognizing common human action still image build locally order le spatial pyramid bag feature model shown perform extremely well range object scene human action recognition task introduce three principal contribution first replace standard quantized local hog sift feature stronger discriminatively trained body part object detector second introduce new person object interaction feature based spatial co occurrence individual body part object third address combinatorial problem large number possible interaction pair propose discriminative selection procedure using linear support vector machine svm sparsity inducing regularizer learning action specific body part object interaction bypass difficult problem estimating complete human body pose configuration benefit proposed model shown human action recognition consumer photograph outperforming strong bag feature baseline', 'consider problem stratified sampling monte carlo integration model problem multi armed bandit setting arm represent stratum goal estimate weighted average mean value arm propose strategy sample arm according upper bound standard deviation compare estimation quality ideal allocation would know standard deviation arm provide two regret analysis distribution dependent bound n depends measure disparity arm distribution free bound n best knowledge finite time analysis new problem', 'inexpensive rgb camera give rgb image together depth data become widely available paper use data build point cloud full indoor scene office address task semantic labeling point cloud propose graphical model capture various feature contextual relation including local visual appearance shape cue object co occurence relationship geometric relationship large number object class relation model parsimony becomes important address using multiple type edge potential model admits efficient approximate inference train using maximum margin learning approach experiment total scene home office composed view segment labeled object class get performance labeling object class office labeling object class home scene finally applied algorithm successfully mobile robot task finding object large cluttered room', 'derive instantaneous per round data dependent regret bound stochastic multiarmed bandit side information also known contextual bandit scaling regret bound number state context n go sqrt n rho rho mutual information state action side information used algorithm round algorithm us side information regret bound scale sqrt n ln k k number action arm however side information rho fully used regret bound significantly tighter extreme case rho dependence number state reduces linear logarithmic analysis allows provide algorithm large amount side information let algorithm decide side information relevant task penalize algorithm side information using de facto also present algorithm multiarmed bandit side information computational complexity linear number action', 'present joint image segmentation labeling model jsl given bag figure ground segment hypothesis extracted multiple image location scale construct joint probability distribution compatible image interpretation tiling image segmentation composed segment labeling category process drawing sample joint distribution interpreted first sampling tiling modeled maximal clique graph connecting spatially non overlapping segment bag followed sampling label segment conditioned choice particular tiling learn segmentation labeling parameter jointly based maximum likelihood novel incremental saddle point estimation procedure partition function tiling labelings increasingly accurately approximated including incorrect configuration yet competent model rate probable learning show proposed methodology match current state art stanford dataset well voc accuracy test set achieved', 'paper consider precis problem sampling k representative yet diverse data point large dataset problem arises frequently application video document summarization exploratory data analysis pre filtering formulate general theory encompasses traditional technique devised vector space also non euclidean manifold thereby enabling technique shape human activity texture many image video based datasets propose intrinsic manifold measure measuring quality selection point respect representative power diversity propose efficient algorithm optimize cost function using novel annealing based iterative alternation algorithm proposed formulation applicable manifold known geometry well manifold whose geometry need estimated sample experimental result show strength generality proposed approach', 'abstract missing', 'latent variable model frequently used identify structure dichotomous network data part give rise bernoulli product likelihood well understood consistent notion exchangeable random graph article propose conservative confidence set hold respect underlying bernoulli parameter function given partition network node enabling u ass estimate emph residual network structure structure cannot explained known covariates thus cannot easily verified manual inspection demonstrate proposed methodology analyzing student friendship network national longitudinal survey adolescent health include race gender school year covariates employ stochastic expectation maximization algorithm fit logistic regression model includes explanatory variable well latent stochastic blockmodel component additional node specific effect although maximum likelihood estimate appear consistent context able evaluate confidence set function different blockmodel partition enables u qualitatively ass significance estimated residual network structure relative baseline model covariates lack block structure', 'non negative data commonly encountered numerous field making non negative least square regression nnls frequently used tool least relative simplicity often performs rather well practice serious doubt usefulness arise modern high dimensional linear model even setting unlike first intuition may suggest show broad class design nnls resistant overfitting work excellently sparse recovery combined thresholding experimentally even outperforming l regularization since nnls also circumvents delicate choice regularization parameter finding suggest nnls may method choice', 'consider computational complexity probabilistic inference latent dirichlet allocation lda first study problem finding maximum posteriori map assignment topic word document topic distribution integrated show effective number topic per document small exact inference take polynomial time contrast show document large number topic finding map assignment topic word lda np hard next consider problem finding map topic distribution document topic word assignment integrated show problem also np hard finally briefly discus problem sampling posterior showing np hard one restricted setting leaving open general question', 'introduce novel active learning framework video annotation judiciously choosing frame user annotate obtain highly accurate track minimal user effort cast problem one active learning show obtain excellent performance querying frame annotated would produce large expected change estimated object track implement constrained tracker compute expected change putative annotation efficient dynamic programming algorithm demonstrate framework four datasets including two benchmark datasets constructed key frame annotation obtained amazon mechanical turk result indicate could obtain equivalent label small fraction original cost', 'derive new generalization bound based rademacher complexity theory model selection error estimation linear kernel classifier exploit availability unlabeled sample particular two result obtained first one show using unlabeled sample confidence term conventional bound reduced factor three second one show unlabeled sample used obtain much tighter bound building localized version hypothesis class containing optimal classifier', 'paper consider general rank minimization problem rank appearing either objective function constraint first show class matrix optimization problem solved lower dimensional vector optimization problem consequence establish class rank minimization problem closed form solution using result propose penalty decomposition method general rank minimization problem convergence result pd method shown longer version paper finally test performance method applying matrix completion nearest low rank correlation matrix problem computational result demonstrate method generally outperform existing method term solution quality speed', 'paper proposes parsing algorithm scene understanding includes four aspect computing scene layout detecting object e g furniture detecting face window door etc segmenting background contrast previous scene labeling work applied discriminative classifier pixel super pixel use generative stochastic scene grammar ssg grammar represents compositional structure visual entity scene category foreground background face line grammar includes three type production rule two type contextual relation production rule rule represent decomposition entity sub part ii rule represent switching among sub type entity iii set rule rep resent ensemble visual entity contextual relation cooperative relation represent positive link binding entity hinged face object aligned box ii competitive relation represents negative link competing entity mutually exclusive box design efficient mcmc inference algorithm namely hierarchical cluster sampling search large solution space scene configuration algorithm two stage clustering form possible higher level structure cluster lower level entity production rule contextual relation ii sampling jump alternative structure cluster layer hierarchy find probable configuration represented parse tree experiment demonstrate superiority algorithm existing method public dataset addition approach achieves richer structure parse tree', 'traditional approach probabilistic inference loopy belief propagation gibbs sampling typically compute marginals unobserved variable graphical model however many real world application user interest focused subset variable specified query case would wasteful uniformly sample say one million variable query concern ten paper propose query specific approach mcmc account query variable generalized mutual information neighboring variable order achieve higher computational efficiency surprisingly almost previous work query aware mcmc demonstrate success approach positive experimental result wide range graphical model', 'skill discovery algorithm reinforcement learning typically identify single state region state space correspond task specific subgoals however method directly address question many distinct skill appropriate solving task agent face highly inefficient many identified subgoals correspond underlying skill used individually skill goal furthermore skill created manner often transferable task share identical state space since corresponding subgoals across task merged single skill goal show problem overcome clustering subgoal data defined agent space using resulting cluster template skill termination condition clustering via dirichlet process mixture model used discover minimal sufficient collection portable skill', 'paper present algorithm learn multi label classifier attempt directly optimising f score key novelty formulation explicitly allow assortative submodular pairwise label interaction e leverage co ocurrence pair label order improve quality prediction prediction model consists minimising particular submodular set function accomplished exactly efficiently via graph cut learning however substantially involved requires solution intractable combinatorial optimisation problem present approximate algorithm problem prove sound sense never predicts incorrect label also present nontrivial test sufficient condition algorithm found optimal solution present experiment benchmark multi label datasets attest value proposed technique also make available source code enables reproduction experiment', 'abstract missing', 'present theoretical empirical result framework combine benefit apprenticeship autonomous reinforcement learning approach modifies existing apprenticeship learning framework relies teacher demonstration necessarily explore environment first change replacing previously used mistake bound model learner recently proposed framework meld kwik mistake bound supervised learning protocol second change introducing communication expected utility student teacher resulting system us teacher trace agent need learn concept cannot efficiently learn', 'multi class gaussian process classifier mgpcs often affected fitting problem labeling error occur far decision boundary prevent investigate robust mgpc rmgpc considers labeling error independently distance decision boundary expectation propagation used approximate inference experiment several datasets noise injected class label illustrate benefit rmgpc method performs better gaussian process alternative based considering latent gaussian noise heavy tailed process noise injected label rmgpc still performs equal better method finally show rmgpc used successfully identifying data instance difficult classify accurately practice', 'propose new sparse bayesian model multi task regression classification model able capture correlation task specifically low rank approximation covariance matrix sparse feature introduce general family group sparsity inducing prior based matrix variate gaussian scale mixture show amount sparsity learnt data combining approximate inference approach type ii maximum likelihood estimation hyperparameters empirical evaluation data set biology vision demonstrate applicability model regression classification task achieves competitive predictive performance compared previously proposed method', 'much evidence human animal utilize combination model based model free rl method although proposed system may dominate according relative statistical efficiency different circumstance little specific evidence especially human detail trade accordingly examine relative performance different rl approach situation statistic reward differentially noisy volatile using theory simulation show model free td learning relatively disadvantaged case high volatility low noise present data decision making experiment manipulating parameter showing human shift learning strategy accord prediction statistical circumstance favoring model based rl also promote high learning rate help explain psychology distinction strategy traditionally conceived term rule based v incremental learning', 'policy learning ability agent learn policy one following key element reinforcement learning recent year much work developing temporal different td algorithm guaranteed converge policy sampling remained open question however whether anything said priori quality td solution policy sampling employed function approximation general answer arbitrary policy sampling error td solution unboundedly large even approximator represent true value function well paper propose novel approach address problem show considering certain convex subset policy distribution indeed provide guarantee solution quality similar policy case furthermore show efficiently project convex set using sample generated system end result novel td algorithm approximation guarantee even case policy sampling empirically outperforms existing td method', 'present efficient algorithm problem online multiclass prediction bandit feedback fully adversarial setting measure regret respect log loss defined cite abernethyr parameterized scalar alpha prove regret newtron log alpha constant vary horizon alpha allowed increase infinity alpha log regret bounded sqrt thus solving open problem cite kst abernethyr algorithm based novel application online newton method cite hak test algorithm show perform well experiment even alpha small constant', 'propose algorithm called sparse manifold clustering embedding smce simultaneous clustering dimensionality reduction data lying multiple nonlinear manifold similar dimensionality reduction method smce find small neighborhood around data point connects point neighbor appropriate weight key difference smce find neighbor weight automatically done solving sparse optimization problem encourages selecting nearby point lie manifold approximately span low dimensional affine subspace optimal solution encodes information used clustering dimensionality reduction using spectral clustering embedding moreover size optimal neighborhood data point different different point provides estimate dimension manifold point belongs experiment demonstrate method effectively handle multiple manifold close manifold non uniform sampling hole well estimate intrinsic dimension manifold', 'analyze convergence gradient based optimization algorithm whose update depend delayed stochastic gradient information main application result development distributed minimization algorithm master node performs parameter update worker node compute stochastic gradient based local information parallel may give rise delay due asynchrony main contribution show smooth stochastic problem delay asymptotically negligible application distributed optimization show n node architecture whose optimization error stochastic problem spite asynchronous delay scale asymptotically order sqrt nt known optimal even absence delay', 'consider loss function multiclass prediction problem show multiclass loss expressed proper composite loss composition proper loss link function extend existing result binary loss multiclass loss determine stationarity condition bregman representation order sensitivity existence uniqueness composite representation multiclass loss also show integral representation binary proper loss extended multiclass loss subsume existing result classification calibration relating properness draw conclusion concerning design multiclass loss', 'agglomerative clustering algorithm merges similar pair cluster every iteration function evaluates similarity traditionally hand designed recent interest supervised semisupervised setting ground truth clustered data available training show train similarity function regarding action value function reinforcement learning problem apply general method segment image clustering superpixels application call learning agglomerate superpixel hierarchy lash applied challenging dataset brain image serial electron microscopy lash dramatically improved segmentation accuracy clustering supervoxels generated state boundary detection algorithm naive strategy directly training supervoxel similarity applying single linkage clustering produced le improvement', 'abstract missing', 'introduce approach learn discriminative visual representation exploiting external semantic knowledge object category relationship given hierarchical taxonomy capture semantic similarity object learn corresponding tree metric tom tree one metric non leaf node object hierarchy metric responsible discriminating among immediate subcategory child specifically mahalanobis metric learned given node must satisfy appropriate dis similarity constraint generated among subtree member training instance exploit semantics introduce novel regularizer coupling metric prefers sparse disjoint set feature selected metric relative ancestor supercategory node metric intuitively reflects visual cue useful distinguish generic class e g feline v canine different cue useful distinguish component fine grained class e g persian cat v siamese cat validate approach multiple image datasets using wordnet taxonomy show advantage alternative metric learning approach analyze meaning attribute feature selected algorithm', 'introduce new convergent variant q learning called speedy q learning address problem slow convergence standard form q learning algorithm prove pac bound performance sql show mdp n state action pair discount factor gamma big log n epsilon gamma big step required sql algorithm converge epsilon optimal action value function high probability bound better dependency epsilon gamma thus tighter best available result q learning bound also superior existing result model free model based instance batch q value iteration considered efficient incremental method like q learning', 'paper propose first exact algorithm minimizing difference two submodular function e discrete version c programming problem developed algorithm branch bound based algorithm responds structure problem relationship submodularity convexity programming problem cover broad range application machine learning generalizes optimization wide class set function empirically investigate performance algorithm illustrate difference exact approximate solution respectively obtained proposed existing algorithm feature selection discriminative structure learning', 'signal estimation random amplitude phase shift additive noise studied frequently problem estimating deterministic signal random time warping relatively unexplored present novel framework estimating unknown signal utilizes action warping group form equivalence relation signal first derive estimator equivalence class unknown signal using notion karcher mean quotient space equivalence class step requires use fisher rao riemannian metric square root representation signal enable computation distance mean metric define notion center class show center estimated class consistent estimator underlying unknown signal estimation algorithm many application registration alignment functional data separation phase amplitude component functional data joint demodulation carrier estimation sparse modeling functional data demonstrate given signal temporally aligned using nonlinear warping thus separated phase amplitude component proposed method signal alignment shown state art performance using berkeley growth handwritten signature neuroscience spike train data', 'divergence estimator based direct approximation density ratio without going separate approximation numerator denominator density successfully applied machine learning task involve distribution comparison outlier detection transfer learning two sample homogeneity test however since density ratio function often posse high fluctuation divergence estimation still challenging task practice paper propose use relative divergence distribution comparison involves approximation relative density ratio since relative density ratio always smoother corresponding ordinary density ratio proposed method favorable term non parametric convergence speed furthermore show proposed divergence estimator asymptotic variance independent model complexity parametric setup implying proposed estimator hardly overfits even complex model experiment demonstrate usefulness proposed approach', 'new le vy process prior proposed uncountable collection covariate dependent feature learning measure model called kernel beta process kbp available covariates handled efficiently via kernel construction covariates assumed observed data sample customer latent covariates learned feature dish customer selects dish infinite buffet manner analogous beta process added constraint customer first decides probabilistically whether consider dish based distance covariate space customer dish customer consider particular dish dish selected probabilistically beta process beta process recovered limiting case kbp efficient gibbs sampler developed computation state art result presented image processing music analysis task', 'address challenging task decoupling material property lighting property given single image last two decade virtually work concentrated exploiting edge information address problem take different route introducing new prior reflectance model reflectance value drawn sparse set basis color result random field model global latent variable basis color pixel accurate output reflectance value show without edge information high quality result achieved par method exploiting source information finally present competitive result integrating additional edge model believe approach solid starting point future development domain', 'simultaneous recording many neuron embedded within recurrently connected cortical network may provide concurrent view dynamical process network thus computational function principle dynamic might identified purely unsupervised statistical mean show hidden switching linear dynamical system hslds model multiple linear dynamical law approximate nonlinear potentially non stationary dynamical process able distinguish different dynamical regime within single trial motor cortical activity associated preparation initiation hand movement regime identified without reference behavioural experimental epoch nonetheless transition correlate strongly external event whose timing may vary trial trial hslds model also performs better recent comparable model predicting firing rate isolated neuron based firing rate others suggesting capture shared variance data thus method able trace dynamical process underlying coordinated evolution network activity way appears reflect computational role', 'topic model learned via statistical model variation within document collection designed extract meaningful semantic structure desirable trait include ability incorporate annotation metadata associated document discovery correlated pattern topic usage avoidance parametric assumption manual specification number topic propose doubly correlated nonparametric topic dcnt model first model simultaneously capture three property dcnt model metadata via flexible gaussian regression arbitrary input feature correlation via scalable square root covariance representation nonparametric selection unbounded series potential topic via stick breaking construction validate semantic structure predictive performance dcnt using corpus nip document annotated various metadata', 'derive upper bound local rademacher complexity lp norm multiple kernel learning yield tighter excess risk bound global approach previous local approach analyzed case p analysis cover case leq p leq infty assuming different feature mapping corresponding different kernel uncorrelated also show lower bound show bound tight derive consequence regarding excess loss namely fast convergence rate order n frac alpha alpha alpha minimum eigenvalue decay rate individual kernel', 'abstract missing', 'consider hypothesis testing problem detecting shift mean two multivariate normal distribution high dimensional setting allowing data dimension p exceed sample size n contribution new test statistic two sample test mean integrates random projection classical hotelling squared statistic working within high dimensional framework allows p n tend infinity first derive asymptotic power function test provide sufficient condition achieve greater power state art test using roc curve generated simulated data demonstrate superior performance competing test parameter regime anticipated theoretical result lastly illustrate advantage procedure comparison high dimensional gene expression dataset involving discrimination different type cancer', 'spectral clustering based spectral relaxation normalized ratio graph cut criterion spectral relaxation known loose shown recently non linear eigenproblem yield tight relaxation cheeger cut paper extend result considerably providing characterization balanced graph cut allow tight relaxation although resulting optimization problem non convex non smooth provide efficient first order scheme scale large graph moreover approach come quality guarantee given partition initialization algorithm either output better partition stop immediately', 'learning theory largely focused two main learning scenario classical statistical setting instance drawn fixed distribution adversarial scenario whereby every time step worst instance revealed player argued real world neither assumption reasonable define minimax value game adversary restricted move capturing stochastic non stochastic assumption data building sequential symmetrization approach define notion distribution dependent rademacher complexity spectrum problem ranging worst case bound let u immediately deduce variation type bound study smoothed online learning scenario show exponentially small amount noise make function class infinite littlestone dimension learnable', 'determining interaction entity overall organization clustering node network major challenge analyzing biological social network data extend indian buffet process ibp nonparametric bayesian model integrate noisy interaction score property individual entity inferring interaction network clustering node within network present application method study micrornas regulate mrna cell analysis synthetic real data indicates method improves upon prior method correctly recovers interaction cluster provides accurate biological prediction', 'policy gradient useful model free reinforcement learning approach tends suffer instability gradient estimate paper analyze improve stability policy gradient method first prove variance gradient estimate pgpe policy gradient parameter based exploration method smaller classical reinforce method mild assumption derive optimal baseline pgpe contributes reducing variance also theoretically show pgpe optimal baseline preferable reinforce optimal baseline term variance gradient estimate finally demonstrate usefulness improved pgpe method experiment', 'consider regularized risk minimization large dictionary reproducing kernel hilbert space rkhss target function sparse representation setting commonly referred sparse multiple kernel learning mkl may viewed non parametric extension group sparsity linear model two dominant algorithmic strand sparse learning namely convex relaxation using l norm e g lasso greedy method e g omp rigorously extended group sparsity sparse mkl literature farmainly adopted former withmild empirical success paper close gap proposing group omp based framework sparse multiple kernel learning unlike l mkl approach decouples sparsity regularizer via direct l constraint smoothness regularizer via rkhs norm lead better empirical performance well simpler optimization procedure requires black box single kernel solver algorithmic development empirical study complemented theoretical analysis term rademacher generalization bound sparse recovery condition analogous omp group omp', 'l regularized gaussian maximum likelihood estimator shown strong statistical guarantee recovering sparse inverse covariance matrix alternatively underlying graph structure gaussian markov random field limited sample propose novel algorithm solving resulting optimization problem regularized log determinant program contrast state art method largely use first order gradient information algorithm based newton method employ quadratic approximation modification leverage structure sparse gaussian mle problem show method superlinearly convergent also present experimental result using synthetic real application data demonstrate considerable improvement performance method compared state art method', 'paper introduces two new framework learning action model planning mistake bounded planning framework learner access planner given model representation simulator planning problem generator aim learn model polynomial number faulty plan planned exploration framework learner access problem generator must instead design problem plan converge polynomial number planning attempt paper reduces learning framework concept learning one sided error provides algorithm successful learning framework specific family hypothesis space shown efficiently learnable framework', 'consider latent structural version probit loss ramp loss show surrogate loss function consistent strong sense feature map finite infinite dimensional yield predictor approaching infimum task loss achievable linear predictor given feature also give finite sample generalization bound convergence rate loss function bound suggest probit loss converges rapidly however ramp loss easily optimized may ultimately practical', 'people determine element set representative set extend existing bayesian measure representativeness indicates representativeness sample distribution define measure representativeness item set show measure formally related machine learning method known bayesian set building connection derive analytic expression representativeness object described sparse vector binary feature apply measure large database image using determine image representative member different set comparing resulting prediction human judgment representativeness provides test measure naturalistic stimulus illustrates database commonly used computer vision machine learning used evaluate psychological theory', 'abstract missing', 'discus new method recovery signal block sparse structure based l minimization emphasis efficiently computable error bound recovery routine optimize bound respect method parameter construct estimator improved statistical property justify proposed approach oracle inequality link property recovery algorithm best estimation performance', 'work describes conceptually simple method structured sparse coding dictionary design supposing dictionary k atom introduce structure set penalty interaction every pair atom describe modification standard sparse coding algorithm inference setting describe experiment showing algorithm efficient show interesting dictionary learned interaction encode tree structure locally connected structure finally show framework allows u learn value interaction data rather pre specified', 'recently mahoney orecchia demonstrated popular diffusion based procedure compute quick approximation first nontrivial eigenvector data graph laplacian exactly solve certain regularized semi definite program sdps paper extend result providing statistical interpretation approximation procedure interpretation analogous manner l regularized l regularized l regression often called ridge regression lasso regression respectively interpreted term gaussian prior laplace prior respectively coefficient vector regression problem framework imply solution mahoney orecchia regularized sdp interpreted regularized estimate pseudoinverse graph laplacian conversely imply solution regularized estimation problem computed quickly running e g fast diffusion based pagerank procedure computing approximation first nontrivial eigenvector graph laplacian empirical result also provided illustrate manner approximate eigenvector computation implicitly performs statistical regularization relative running corresponding exact algorithm', 'paper describe maximum likelihood likelihood approach dictionary learning multiplicative exponential noise model model prevalent audio signal processing underlies generative composite model power spectrogram maximum joint likelihood estimation dictionary expansion coefficient lead nonnegative matrix factorization problem itakura saito divergence used optimality approach question number parameter include expansion coefficient grows number observation paper describe variational procedure optimization marginal likelihood e likelihood dictionary activation coefficient integrated given specific prior compare output maximum joint likelihood estimation e standard itakura saito nmf maximum marginal likelihood estimation mmle real synthetical datasets mmle approach shown embed automatic model order selection akin automatic relevance determination', 'majority approximate dynamic programming approach reinforcement learning problem categorized greedy value function method value based policy gradient method former approach although fast well known susceptible policy oscillation phenomenon take fresh view phenomenon casting considerable subset former approach limiting special case latter explain phenomenon term view illustrate underlying mechanism artificial example also use derive constrained natural actor critic algorithm interpolate aforementioned approach addition suggested literature oscillation phenomenon might subtly connected grossly suboptimal performance tetri benchmark problem attempted approximate dynamic programming method report empirical evidence connection favor alternative explanation finally report score tetri problem improve existing dynamic programming based result', 'group lasso extension lasso feature selection predefined non overlapping group feature non overlapping group structure limit applicability practice several recent attempt study general formulation group feature given potentially overlap group resulting optimization however much challenging solve due group overlap paper consider efficient optimization overlapping group lasso penalized problem reveal several key property proximal operator associated overlapping group lasso compute proximal operator solving smooth convex dual problem allows use gradient descent type algorithm optimization performed empirical evaluation using synthetic breast cancer gene expression data set consists gene organized overlapping gene set experimental result show proposed algorithm efficient existing state art algorithm', 'motor prosthesis aim restore function disabled patient despite compelling proof concept system barrier clinical translation remain one challenge develop low power fully implantable system dissipates minimal power damage tissue end implemented kalman filter based decoder via spiking neural network snn tested brain machine interface bmi experiment rhesus monkey kalman filter trained predict arm velocity mapped snn using neural engineer ing framework nef neuron embedded matlab snn implementation run real time closed loop performance quite comparable standard kalman filter success closed loop decoder hold promise hardware snn implementation statistical signal processing algorithm neuromorphic chip may offer power saving necessary overcome major obstacle successful clinical translation neural motor prosthesis', 'using ell norm regularize estimation parameter vector linear model lead unstable estimator covariates highly correlated paper introduce new penalty function take account correlation design matrix stabilize estimation norm called trace lasso us trace norm selected covariates convex surrogate rank criterion model complexity analyze property norm describe optimization algorithm based reweighted least square illustrate behavior norm synthetic data showing adapted strong correlation competing method elastic net', 'goal paper investigate advantage disadvantage learning banach space hilbert space many work carried generalizing hilbert method banach space paper consider simple problem learning parzen window classifier reproducing kernel banach space rkbs closely related notion embedding probability measure rkbs order carefully understand pro con hilbert space classifier show generalization yield richer distance measure probability compared hilbert space counterpart however suffers serious computational drawback limiting practical applicability therefore demonstrates need developing efficient learning algorithm banach space', 'abstract missing', 'abstract missing', 'show application tree structure approximate inference graphical model using expectation propagation algorithm approximation typically used graph short range cycle demonstrate approximation also help sparse graph long range loop one used coding theory approach channel capacity asymptotically large sparse graph expectation propagation algorithm together tree structure yield completely disconnected approximation graphical model finite length practical sparse graph tree structure approximation code graph provides accurate estimate marginal variable', 'abstract missing', 'paper considers problem embedding directed graph euclidean space retaining directional information model observed graph sample manifold endowed vector field design algo rithm separate recovers feature process geometry manifold data density vector field algorithm motivated analysis laplacian type operator continuous limit generator diffusion manifold illustrate recovery algorithm artificially constructed real data', 'approximate inference important technique dealing large intractable graphical model based exponential family distribution extend idea approximate inference exponential family defining new divergence divergence measure obtained via convex duality log partition function exponential family new entropy illustrate approach bayes point machine student prior', 'number recent scientific engineering problem require signal decomposed product slowly varying positive envelope quickly varying carrier whose instantaneous frequency also varies slowly time although signal processing provides algorithm called amplitude frequency demodulation afd well known problem existing method motivated fact afd ill posed approach problem using probabilistic inference new approach called probabilistic amplitude frequency demodulation pafd model instantaneous frequency using auto regressive generalization von mi distribution envelope using gaussian auto regressive dynamic positivity constraint novel form expectation propagation used inference demonstrate although pafd computationally demanding outperforms previous approach synthetic real signal clean noisy missing data setting', 'consider general inference setting discrete probabilistic graphical model seek maximum posteriori map estimate subset random variable max node marginalizing rest sum node present hybrid message passing algorithm accomplish hybrid algorithm pass mix sum max message depending type source node sum max derive algorithm showing fall solution particular relaxation variational framework show expectation maximization algorithm seen approximation algorithm experimental result synthetic real world datasets several baseline demonstrate efficacy proposed algorithm', 'consider problem bayesian inference continuous time multi stable stochastic system change diffusion drift parameter discrete time propose exact inference sampling methodology two specific case discontinuous dynamic given poisson process two state markovian switch test methodology simulated data apply two real data set finance system biology experimental result show approach lead valid inference non trivial insight', 'learning minimum volume set underlying nominal distribution effective approach anomaly detection several approach learning minimum volume set proposed literature including k point nearest neighbor graph k knng algorithm based geometric entropy minimization gem principle k knng detector possessing several desirable characteristic suffers high computation complexity simpler heuristic approximation leave one knng l knng proposed paper propose novel bipartite k nearest neighbor graph bp knng anomaly detection scheme estimating minimum volume set bipartite estimator retains desirable theoretical property k knng computationally simpler k knng surrogate l knng detector show bp knng asymptotically consistent recovering p value test point experimental result given illustrate superior performance bp knng compared l knng state art anomaly detection scheme', 'monte carlo tree search mcts proven powerful generic planning technique decision making single agent adversarial environment stochastic nature monte carlo simulation introduces error value estimate term bias variance whilst reducing bias typically addition domain knowledge studied mcts literature comparatively little effort focused reducing variance somewhat surprising since variance reduction technique well studied area classical statistic paper examine application standard technique variance reduction mcts including common random number antithetic variate control variate demonstrate technique applied mcts explore efficacy three different stochastic single agent setting pig stop dominion', 'neuron neocortex code compute part locally interconnected population large scale multi electrode recording make possible access population process empirically fitting statistical model unaveraged data statistical structure best describes concurrent spiking cell within local network argue cortex firing exhibit extensive correlation time space typical sample neuron still reflects small fraction local population appropriate model capture shared variability low dimensional latent process evolving smooth dynamic rather putative direct coupling test claim comparing latent dynamical model realistic spiking observation coupled generalised linear spike response model glms using cortical recording find latent dynamical approach outperforms glm term goodness fit reproduces temporal correlation data accurately also compare model whose observation model either derived gaussian point process model finding non gaussian model provides slightly better goodness fit realistic population spike count', 'abstract missing', 'paper address problem learning structure pairwise graphical model sample high dimensional setting first main result study sparsistency consistency sparsity pattern recovery property forward backward greedy algorithm applied general statistical model special case apply algorithm learn structure discrete graphical model via neighborhood estimation corollary general result derive sufficient condition number sample n maximum node degree problem size p well condition model parameter algorithm recovers edge high probability result guarantee graph selection sample scaling n omega log p contrast existing convex optimization based algorithm require sample complexity omega log p greedy algorithm requires restricted strong convexity condition typically milder irrepresentability assumption corroborate result using numerical simulation end', 'topic model potential improve search browsing extracting useful semantic theme web page text document learned topic coherent interpretable valuable faceted browsing result set diversity analysis document retrieval however dealing small collection noisy text e g web search result snippet blog post learned topic le coherent le interpretable le useful overcome propose two method regularize learning topic model regularizers work creating structured prior word reflect broad pattern external data using thirteen datasets show regularizers improve topic coherence interpretability learning faithful representation collection interest overall work make topic model useful across broader range text data', 'multi task learning mtl learns multiple related task simultaneously improve generalization performance alternating structure optimization aso popular mtl method learns shared low dimensional predictive structure hypothesis space multiple related task applied successfully many real world application alternative mtl approach clustered multi task learning cmtl assumes multiple task follow clustered structure e task partitioned set group task group similar clustered structure unknown priori objective aso cmtl differ multiple task related interestingly show paper equivalence relationship aso cmtl providing significant new insight aso cmtl well inherent relationship cmtl formulation non convex adopt convex relaxation cmtl formulation establish equivalence relationship proposed convex relaxation cmtl existing convex relaxation aso show proposed convex cmtl formulation significantly efficient especially high dimensional data addition present three algorithm solving convex cmtl formulation report experimental result benchmark datasets demonstrate efficiency proposed algorithm', 'recent deep learning unsupervised feature learning system learn unlabeled data achieved high performance benchmark using extremely large architecture many feature hidden unit layer unfortunately large architecture number parameter usually grows quadratically width network thus necessitating hand coded local receptive field limit number connection lower level feature higher one e g based spatial locality paper propose fast method choose connection may incorporated wide variety unsupervised training method specifically choose local receptive field group together low level feature similar according pairwise similarity metric approach allows u harness advantage local receptive field improved scalability reduced data requirement know specify receptive field hand unsupervised training algorithm obvious generalization topographic setting produce result showing method allows u use even simple unsupervised training algorithm train successful multi layered etworks achieve state art result cifar stl datasets accuracy respectively', 'abstract missing', 'standard gaussian process regression input location assumed noise free present simple yet effective gp model training input point corrupted gaussian noise make computation tractable use local linear expansion input point allows input noise recast output noise proportional squared gradient gp posterior mean input noise variance inferred data extra hyperparameters trained alongside hyperparameters usual method maximisation marginal likelihood training us iterative scheme alternate optimising hyperparameters calculating posterior gradient analytic predictive moment found gaussian distributed test point compare model others range different regression problem show improves current method', 'abstract missing', 'application robot control wireless communication require planning uncertainty partially observable markov decision process pomdps plan policy single agent uncertainty decentralized version dec pomdps find policy multiple agent policy infinite horizon pomdp dec pomdp problem represented finite state controller fscs introduce novel class periodic fscs composed layer connected previous next layer periodic fsc method find deterministic finite horizon policy convert initial periodic infinite horizon policy policy optimized new infinite horizon algorithm yield deterministic periodic policy new expectation maximization algorithm yield stochastic periodic policy method yield better result earlier planning method compute larger solution regular fscs', 'fitted value iteration fvi ordinary least square regression known diverge present new method expansion constrained ordinary least square ecols produce linear approximation also guarantee convergence used fvi ensure convergence constrain least square regression operator non expansion infinity norm show space function approximators satisfy constraint rich space averagers prove minimax property ecols residual error give efficient algorithm computing coefficient ecols based constraint generation illustrate algorithmic convergence fvi ecols suite experiment discus property', 'important task exploring analyzing real world data set detect unusual interesting phenomenon paper study group anomaly detection problem unlike traditional anomaly detection research focus data point goal discover anomalous aggregated behavior group point purpose propose flexible genre model fgm fgm designed characterize data group point level group level detect various type group anomaly evaluate effectiveness fgm synthetic real data set including image turbulence data show superior existing approach detecting group anomaly', 'abstract missing', 'budgeted optimization involves optimizing unknown function costly evaluate requesting limited number function evaluation intelligently selected input typical problem formulation assume experiment selected one time limited total number experiment fail capture important aspect many real world problem paper defines novel problem formulation following important extension allowing concurrent experiment allowing stochastic experiment duration placing constraint total number experiment total experimental time develop offline online algorithm selecting concurrent experiment new setting provide experimental result number optimization benchmark result show algorithm produce highly effective schedule compared natural baseline', 'focusing short term trend prediction financial context consider problem selective prediction whereby predictor abstain prediction order improve performance examine two type selective mechanism hmm predictor first rejection spirit chow well known ambiguity principle second specialized mechanism hmms identifies low quality hmm state abstain prediction state call model selective hmm shmm approach trade prediction coverage gain better accuracy controlled manner compare performance ambiguity based rejection technique shmm approach result indicate method effective shmm model superior', 'motivated application electronic game well teaching system investigate problem dynamic difficulty adjustment task repeatedly find game difficulty setting neither easy bore player difficult overburden player contribution paper formulation difficulty adjustment online learning problem partially ordered set ii exponential update algorithm dynamic difficulty adjustment iii bound number wrong difficulty setting relative best static setting chosen hindsight iv empirical investigation algorithm playing adversary', 'provide rigorous guarantee learning weighted trace norm arbitrary sampling distribution show standard weighted trace norm might fail sampling distribution product distribution e row column index selected independently present corrected variant establish strong learning guarantee demonstrate work better practice provide guarantee weighting either true empirical sampling distribution suggest even true distribution known uniform weighting empirical distribution may beneficial', 'abstract missing', 'introduce variational bayesian inference algorithm widely applied sparse linear model algorithm based spike slab prior bayesian perspective golden standard sparse inference apply method general multi task multiple kernel learning model common set gaussian process function linearly combined task specific sparse weight thus inducing relation task model unifies several sparse linear model generalized linear model sparse factor analysis matrix factorization missing value variational algorithm applied case demonstrate approach multi output gaussian process regression multi class classification image processing application collaborative filtering', 'consider problem classification using similarity distance function data specifically propose framework defining goodness dis similarity function respect given learning task propose algorithm guaranteed generalization property working good function framework unifies generalizes framework proposed balcan blum wang et al attractive feature framework adaptability data promote fixed notion goodness rather let data dictate show giving theoretical guarantee goodness criterion best suited problem learned make approach applicable variety domain problem propose landmarking based approach obtaining classifier learned goodness criterion provide novel diversity based heuristic perform task driven selection landmark point instead random selection demonstrate effectiveness goodness criterion learning method well landmark selection heuristic variety similarity based learning datasets benchmark uci datasets method consistently outperforms existing approach significant margin', 'compositional model provide elegant formalism representing visual appearance highly variable object model appealing theoretical point view difficult demonstrate lead performance advantage challenging datasets develop grammar model person detection show outperforms previous high performance system pascal benchmark model represents people using hierarchy deformable part variable structure explicit model occlusion partially visible object train model introduce new discriminative framework learning structured prediction model weakly labeled data', 'learning problem logistic regression typically formulated pure optimization problem defined loss function argue view ignores fact loss function depends stochastically generated data turn determines intrinsic scale precision statistical estimation considering statistical property update variable used optimization e g gradient construct frequentist hypothesis test determine reliability update utilize subset data computing update use hypothesis test determining batch size need increased provides computational benefit avoids overfitting stopping batch size become equal size full dataset moreover proposed algorithm depend single interpretable parameter probability update wrong direction set single value across algorithm datasets paper illustrate idea three l regularized coordinate algorithm l regularized l loss svms l regularized logistic regression lasso emphasize underlying method much generally applicable', 'probabilistic programming language allow modeler specify stochastic process using syntax resembles modern programming language program machine readable format variety technique compiler design program analysis used examine structure distribution represented probabilistic program show nonstandard interpretation probabilistic program used craft efficient inference algorithm information structure distribution gradient dependency generated monad like side computation executing program interpretation easily coded using special purpose object operator overloading implement two example nonstandard interpretation two different language use building block construct inference algorithm automatic differentiation enables gradient based method provenance tracking enables efficient construction global proposal', 'abstract missing', 'classical boosting algorithm adaboost build strong classifier without concern computational cost application particular computer vision may involve million training example feature context training time may become prohibitive several method exist accelerate training typically either sampling feature example used train weak learner even method precisely quantify speed improvement deliver offer guarantee efficient given amount time paper aim shading light problem e given fixed amount time particular problem strategy optimal order reduce training loss apply analysis design new algorithm estimate fly every iteration optimal trade number sample number feature look order maximize expected loss reduction experiment object recognition two standard computer vision data set show adaptive method propose outperform basic sampling state art bandit method', 'biased labelers systemic problem crowdsourcing comprehensive toolbox handling response still developed typical crowdsourcing application divided three step data collection data curation learning present step often treated separately present bayesian bias mitigation crowdsourcing bbmc bayesian model unify three data curation method account effect labeler bias modeling label coming single latent truth model capture source bias describing labelers influenced shared random effect approach account complex bias pattern arise ambiguous hard labeling task allows u merge data curation learning single computation active learning integrates data collection learning commonly considered infeasible gibbs sampling inference propose general approximation strategy markov chain efficiently quantify effect perturbation stationary distribution specialize approach active learning experiment show bbmc outperform many common heuristic', 'consider problem assigning class label unlabeled test data set given several labeled training data set drawn similar distribution problem arises several application data distribution fluctuate biological technical source variation develop distribution free kernel based approach problem approach involves identifying appropriate reproducing kernel hilbert space optimizing regularized empirical risk space present generalization error analysis describe universal kernel establish universal consistency proposed methodology experimental result flow cytometry data presented', 'introduce hierarchically supervised latent dirichlet allocation hslda model hierarchically multiply labeled bag word data example data include web page placement directory product description associated category product hierarchy free text clinical record assigned diagnosis code sample label prediction primary goal work improved lower dimensional representation bag word data also interest demonstrate hslda large scale data clinical document labeling retail product categorization task show leveraging structure hierarchical label improves sample label prediction substantially compared model', 'speech conveys different yet mixed information ranging linguistic speaker specific component exclusively used specific task however extremely difficult extract specific information component given fact nearly existing acoustic representation carry type speech information thus use representation speech speaker recognition hinders system producing better performance due interference irrelevant information paper present deep neural architecture extract speaker specific information mfccs result multi objective loss function proposed learning speaker specific characteristic regularization via normalizing interference non speaker related information avoiding information loss ldc benchmark corpus chinese speech corpus demonstrate resultant speaker specific representation insensitive text language spoken environmental mismatch hence outperforms mfccs state art technique speaker recognition discus relevant issue relate approach previous work', 'computational analysis dendritic computation often assume stationary input neuron ignoring pulsatile nature spike based communication neuron moment moment fluctuation caused spiking input conversely circuit computation spiking neuron usually formalized without regard rich nonlinear nature dendritic processing address computational challenge faced neuron compute represent analogue quantity communicate digital spike show reliable computation even purely linear function input require interplay strongly nonlinear subunit within postsynaptic dendritic tree theory predicts matching dendritic nonlinearities synaptic weight distribution joint statistic presynaptic input approach suggests normative role puzzling form nonlinear dendritic dynamic plasticity', 'consider minimization convex objective function defined hilbert space available unbiased estimate gradient problem includes standard machine learning algorithm kernel logistic regression least square regression commonly referred stochastic approximation problem operation research community provide non asymptotic analysis convergence two well known algorithm stochastic gradient descent k robbins monro algorithm well simple modification iterates averaged k polyak ruppert averaging analysis suggests learning rate proportional inverse number iteration leading optimal convergence rate strongly convex case robust lack strong convexity setting proportionality constant situation remedied using slower decay together averaging robustly leading optimal rate convergence illustrate theoretical result simulation synthetic standard datasets', 'many functional description spiking neuron assume cascade structure input passed initial linear filtering stage produce low dimensional signal drive subsequent nonlinear stage paper present novel systematic parameter estimation procedure model applies method two neural estimation problem compressed sensing based neural mapping multi neuron excitation ii estimation neural receptive yield sensory neuron proposed estimation algorithm model neuron via graphical model estimate parameter model using recently developed generalized approximate message passing gamp method gamp method based gaussian approximation loopy belief propagation neural connectivity problem gamp based method shown computational efficient provides exact modeling sparsity incorporate nonlinearities output significantly outperforms previous compressed sensing method receptive field estimation gamp method also exploit inherent structured sparsity linear weight method validated estimation linear nonlinear poisson lnp cascade model receptive field salamander retinal ganglion cell', 'many study uncovered evidence visual cortex contains specialized region involved processing face object class recent electrophysiology study cell several specialized region revealed least region organized hierarchical manner viewpoint specific cell projecting downstream viewpoint invariant identity specific cell freiwald tsao separate computational line reasoning lead claim transformation visual input preserve viewed object identity class specific particular image evoked face undergoing rotation produced image transformation would produce image evoked object another class undergoing rotation however within class face knowledge image transformation evoked rotation reliably transferred previously viewed face help identify novel face new viewpoint show computational simulation architecture applies method gaining invariance class specific transformation effective restricted face fails spectacularly applied across object class argue order accomplish viewpoint invariant face identification single example view visual cortex must separate circuitry involved discounting rotation face generic circuitry involved processing object resulting model ventral stream visual cortex consistent recent physiology result showing hierarchical organization face processing network', 'introduce picodes compact image descriptor nevertheless allows high performance object category recognition particular address novel category recognition task defining indexing structure image representation enable large collection image searched object category known index built instead training image defining category supplied query time explicitly learn descriptor given length small byte per image good object recognition performance contrast previous work domain object recognition choose arbitrary intermediate representation explicitly learn short code contrast previous approach learn compact code optimize explicitly upper bound classification performance optimization directly binary feature difficult nonconvex present alternation scheme convex upper bound demonstrate excellent performance practice picodes byte match accuracy current best known classifier caltech benchmark decrease database storage size factor speed training testing novel class order magnitude', 'abstract missing', 'extensive evidence suggests item encoded independently visual short term memory vstm however previous research quantitatively considered encoding item influence encoding item model dependency among vstm representation using multivariate gaussian distribution stimulus dependent mean covariance matrix report result experiment designed determine specific form stimulus dependence mean covariance matrix find magnitude covariance representation two item monotonically decreasing function difference item feature value similar gaussian process distance dependent stationary kernel function show type covariance function explained natural consequence encoding multiple stimulus population neuron correlated response', 'thompson sampling one oldest heuristic address exploration exploitation trade surprisingly popular literature present empirical result using thompson sampling simulated real data show highly competitive since heuristic easy implement argue part standard baseline compare', 'sizable literature focused problem estimating low dimensional feature space capturing neuron stimulus sensitivity however comparatively little work addressed problem estimating nonlinear function feature space neuron output spike rate use gaussian process gp prior infinite dimensional space nonlinear function obtain bayesian estimate nonlinearity linear nonlinear poisson lnp encoding model offer flexibility robustness computational tractability compared traditional method e g parametric form histogram cubic spline importantly develop framework optimal experimental design based uncertainty sampling involves adaptively selecting stimulus characterize nonlinearity little experimental data possible relies method rapidly updating hyperparameters using laplace approximation apply method data color tuned neuron macaque v estimate nonlinearities space cone contrast reveal v combine cone input highly nonlinear manner simulated experiment show optimal design substantially reduces amount data required estimate nonlinear combination rule', 'describe simple algorithm run time poly n gamma eps learns unknown n dimensional gamma margin halfspace accuracy eps presence malicious noise noise rate allowed high theta eps gamma sqrt log gamma previous efficient algorithm could learn accuracy eps presence malicious noise rate theta eps gamma algorithm work optimizing convex loss function show algorithm learning gamma margin halfspaces minimizes convex proxy misclassification error tolerate malicious noise rate greater theta eps gamma may partially explain previous algorithm could achieve higher noise tolerance new algorithm', 'propose robust filtering approach based semi supervised multiple instance learning mil assume posterior density would unimodal effect outlier wish explicitly model therefore seek point estimate outset rather generic approximation entire posterior approach thought combination standard finite dimensional filtering extended kalman filter unscented filter multiple instance learning whereby initial condition come putative set inlier measurement show state regression inlier set classification estimated iteratively causally processing current measurement illustrate approach visual tracking problem whereby object interest target move evolves result occlusion deformation partial knowledge target given form bounding box training set', 'develop unified information theoretic machinery deriving lower bound passive active learning scheme bound involve called alexander capacity function supremum function recently rediscovered hanneke context active learning name disagreement coefficient passive learning lower bound match upper bound gine koltchinskii constant generalize analogous result massart nedelec active learning provide first known lower bound based capacity function rather disagreement coefficient', 'local coordinate coding lcc method modeling function data lying non linear manifold provides set anchor point form local coordinate system data point manifold approximated linear combination anchor point linear weight become local coordinate coding paper propose encoding data using orthogonal anchor plane rather anchor point method need orthogonal anchor plane coding linearize alpha beta p lipschitz smooth nonlinear function fixed expected value upper bound approximation error high dimensional data practice orthogonal coordinate system easily learned minimizing upper bound using singular value decomposition svd apply method model coordinate locally linear svms classification task experiment mnist show using anchor plane method achieves error rate lcc achieves error rate using anchor point', 'action potential nervous system take form strong rapid brief voltage deflection known spike stark contrast action potential heart characterized broad voltage plateau derive shape neuronal action potential first principle postulating action potential generation strongly constrained brain need minimize energy expenditure given height action potential least energy consumed underlying current obey bang bang principle current giving rise spike intense yet short lived yielding spike sharp onset offset energy optimality predicts feature biophysics per se required producing characteristic neuronal action potential sodium current extraordinarily powerful inactivate voltage potassium sodium current kinetics bell shaped voltage dependence cooperative action multiple gate start flow current', 'abstract missing', 'variational method previously explored tractable approximation bayesian inference neural network however approach proposed far applicable simple network architecture paper introduces easy implement stochastic variational method equivalently minimum description length loss function applied neural network along way revisits several common regularisers variational perspective also provides simple pruning heuristic drastically reduce number network weight lead improved generalisation experimental result provided hierarchical multidimensional recurrent neural network applied timit speech corpus', 'abstract missing', 'high dimensional time series endemic application machine learning robotics sensor data computational biology gene expression data vision video sequence graphic motion capture data practical nonlinear probabilistic approach data required paper introduce variational gaussian process dynamical system work build recent variational approximation gaussian process latent variable model allow nonlinear dimensionality reduction simultaneously learning dynamical prior latent space approach also allows appropriate dimensionality latent space automatically determined demonstrate model human motion capture data set series high resolution video sequence', 'efficient coding hypothesis hold neural receptive field adapted statistic environment agnostic timescale adaptation occurs evolutionary developmental timescales work focus component adaptation occurs organism lifetime show number unsupervised feature learning algorithm account feature normal receptive field property across multiple primary sensory cortex furthermore show algorithm account altered receptive field property response experimentally altered environmental statistic based modeling result propose model phenomenological model receptive field plasticity organism lifetime finally due success model multiple sensory area suggest algorithm may provide constructive realization theory first proposed mountcastle qualitatively similar learning algorithm act throughout primary sensory cortex', 'multi armed bandit mab setting useful abstraction many online learning task focus trade exploration exploitation setting online algorithm fixed set alternative arm round selects one arm observes corresponding reward case small number arm well understood lot recent work focused multi armed bandit infinitely many arm one need assume extra structure order make problem tractable particular lipschitz mab problem underlying similarity metric space known algorithm two arm close metric space similar payoff paper consider realistic scenario metric space implicit defined available structure revealed algorithm directly specifically assume algorithm given tree based classification arm given problem instance classification implicitly defines similarity metric space numerical similarity information available algorithm provide algorithm setting whose performance guarantee almost match best known guarantee corresponding instance lipschitz mab problem', 'present asymptotic analysis viterbi training vt contrast conventional maximum likelihood ml approach parameter estimation hidden markov model ml estimator work locally maximizing likelihood observed data vt seek maximize probability likely hidden state sequence develop analytical framework based generating function formalism illustrate exactly solvable model hmm one unambiguous symbol particular model ml objective function continuously degenerate vt objective contrast shown finite degeneracy furthermore vt converges faster result sparser simpler model thus realizing automatic occam razor hmm learning general scenario vt worse compared ml still capable correctly recovering parameter', 'unsupervised feature learning shown effective learning representation perform well image video audio classification however many existing feature learning algorithm hard use require extensive hyperparameter tuning work present sparse filtering simple new algorithm efficient one hyperparameter number feature learn contrast feature learning method sparse filtering explicitly attempt construct model data distribution instead optimizes simple cost function sparsity l normalized feature easily implemented line matlab code sparse filtering scale gracefully handle high dimensional input also used learn meaningful feature additional layer greedy layer wise stacking evaluate sparse filtering natural image object classification stl phone classification timit show method work well range different modality', 'vast majority recent work sparse estimation algorithm performance evaluated using ideal quasi ideal dictionary e g random gaussian fourier characterized unit ell norm incoherent column feature reality type dictionary represent subset dictionary actually used practice largely restricted idealized compressive sensing application contrast herein sparse estimation considered context structured dictionary possibly exhibiting high coherence arbitrary group column row sparse penalized regression model analyzed purpose finding extent possible regime dictionary invariant performance particular type ii bayesian estimator dictionary dependent sparsity penalty shown number desirable invariance property leading provable advantage conventional penalty ell norm especially area existing theoretical recovery guarantee longer hold translate improved performance application model selection correlated feature source localization compressive sensing constrained measurement direction', 'propose approach linear unsupervised dimensionality reduction based sparse linear model used probabilistically interpret sparse coding formulate optimization problem learning linear projection original signal domain lower dimensional one way approximately preserve expectation pairwise inner product sparse domain derive solution problem present nonlinear extension discus relation compressed sensing experiment using facial image texture patch image object category suggest approach improve ability recover meaningful structure many class signal', 'sparse pca provides linear combination small number feature maximizes variance across data although sparse pca apparent advantage compared pca better interpretability generally thought computationally much expensive paper demonstrate surprising fact sparse pca easier pca practice reliably applied large data set come rigorous feature elimination pre processing result coupled favorable fact feature real life data typically exponentially decreasing variance allows many feature eliminated introduce fast block coordinate ascent algorithm much better computational complexity existing first order one provide experimental result obtained text corpus involving million document hundred thousand feature result illustrate sparse pca help organize large corpus text data user interpretable way providing attractive alternative approach topic model', 'work use branch bound bb efficiently detect object deformable part model instead evaluating classifier score exhaustively image location scale use bb focus promising image location core problem compute bound accommodate part deformation adapt dual tree data structure problem evaluate approach using mixture deformable part model obtain exactly result time faster average also develop multiple object detection variation system hypothesis category inserted common priority queue problem finding strongest category image result fold speedup', 'learning problem whose associated excess loss class beta b bernstein show theoretically possible track classification performance best unknown hypothesis class provided free abstain prediction region choice probabilistic volume rejected region domain shown diminishing rate b theta sqrt beta theta hanneke disagreement coefficient strategy achieving performance computational barrier requires empirical error minimization agnostic setting nevertheless heuristically approximate strategy develop novel selective classification algorithm using constrained svms show empirically resulting algorithm consistently outperforms traditional rejection mechanism based distance decision boundary', 'abstract missing', 'modern classification task usually involve many class label informed broad range feature many task tackled constructing set classifier applied test time pieced together fixed procedure determined advance training time present active classification process test time classifier large ensemble viewed potential observation might inform classification process observation selected dynamically based previous observation using value theoretic computation balance estimate expected classification gain observation well computational cost expected classification gain computed using probabilistic model us outcome previous observation active classification process applied test time individual test instance resulting efficient instance specific decision path demonstrate benefit active scheme various real world datasets show achieve comparable even higher classification accuracy fraction computational cost traditional method', 'bayesian approach partitioning distance matrix presented inspired translation invariant wishart dirichlet process tiwd vogt et al share number advantageous property like fully probabilistic nature inference model automatic selection number cluster applicability semi supervised setting addition method call fasttiwd overcomes main shortcoming original tiwd namely high computational cost fasttiwd reduces workload iteration gibbs sampler n tiwd n experiment show cost reduction compromise quality inferred partition new method possible mine large relational datasets probabilistic model thereby automatically detecting new potentially interesting cluster', 'although spectral clustering enjoyed considerable empirical success machine learning theoretical property yet fully developed analyze performance spectral algorithm hierarchical clustering show class hierarchically structured similarity matrix algorithm tolerate noise grows number data point still perfectly recovering hierarchical cluster high probability additionally improve upon previous result k way spectral clustering derive condition spectral clustering make mistake using minimax analysis derive tight upper lower bound clustering problem compare performance spectral clustering information theoretic limit also present experiment simulated real world data illustrating result', 'manuscript considers convergence rate boosting large class loss including exponential logistic loss best previous rate convergence exp first established setting weak learnability aid entire class granting rate ln next disjoint condition infimal empirical risk attainable characterized term sample weak learning class new proof given known rate ln finally established instance decomposed two smaller instance resembling two preceding special case yielding rate matching lower bound logistic loss principal technical hurdle throughout work potential unattainability infimal empirical risk technique overcoming barrier may general interest', 'variational bayesian matrix factorization vbmf efficiently approximates posterior distribution factorized matrix assuming matrix wise independence two factor recent study fully observed vbmf showed stronger assumption two factorized matrix column wise independent global optimal solution analytically computed however clear restrictive column wise independence assumption paper prove global solution matrix wise independence actually column wise independent implying column wise independence assumption harmless practical consequence theoretical finding global solution matrix wise independence standard setup obtained analytically computationally efficient way without iterative algorithm experimentally illustrate advantage using analytic solution probabilistic principal component analysis', 'describe family global optimization procedure automatically decompose optimization problem smaller loosely coupled problem combine solution message passing algorithm show empirically method excel avoiding local minimum produce better solution fewer function evaluation existing global optimization method develop method introduce notion coupling variable optimization generalizes notion coupling arises factoring function term involve small subset variable therefore subsumes notion independence random variable statistic sparseness hessian nonlinear optimization generalized distributive law despite general notion coupling easier verify empirically making structure estimation easy yet allows u migrate well established inference method graphical model setting global optimization', 'increasing number experimental study indicate perception encodes posterior probability distribution possible cause sensory stimulus used act close optimally environment one outstanding difficulty hypothesis exact posterior general complex represented directly thus neuron represent approximation distribution two influential proposal efficient posterior representation neural population neural activity represents sample underlying distribution represent parametric representation variational approximation posterior show approach combined inference scheme retains advantage able represent multiple mode arbitrary correlation feature sampling method reduces represented space region high probability mass strength variational approximation neurally combined method interpreted feed forward preselection relevant state space followed neural dynamic implementation markov chain monte carlo mcmc approximate posterior relevant state demonstrate effectiveness efficiency approach sparse coding model numerical experiment artificial data image patch compare performance algorithm exact em variational state space selection alone mcmc alone combined select sample approach select sample approach integrates advantage sampling variational approximation form robust neurally plausible efficient model processing learning cortical network sparse coding show application easily exceeding thousand observed thousand hidden dimension', 'previous research image categorization focused medium scale data set large scale image categorization million image thousand category remains challenge emergence structured large scale dataset imagenet rich information conceptual relationship image tree hierarchy among various image category become available human cognition complex visual world benefit underlying semantic relationship object class believe machine learning system leverage information well better performance paper employ semantic relatedness among image category large scale image categorization specifically category hierarchy utilized properly define loss function select common set feature related category efficient optimization method based proximal approximation accelerated parallel gradient method introduced experimental result subset imagenet containing million image category demonstrate effectiveness promise proposed approach', 'motivated application extract representative subset machine learning training data poor empirical performance observe popular minimum norm algorithm fact application minimum norm running time n n oracle call therefore propose fast approximate method minimize arbitrary submodular function large sub class submodular function algorithm exact submodular function iteratively approximated tight submodular upper bound repeatedly optimized show theoretical property empirical result suggest significant speedup minimum norm retaining higher accuracy', 'consider problem recovering parameter alpha r k sparse function f e number non zero entry alpha small compared number k feature given noisy evaluation f set well chosen sampling point introduce additional randomisation process called brownian sensing based computation stochastic integral produce gaussian sensing matrix good recovery property proven independently number sampling point n even feature arbitrarily non orthogonal assumption f h lder continuous exponent least provide estimate parameter alpha eta sqrt n eta observation noise method us set sampling point uniformly distributed along one dimensional curve selected according feature report numerical experiment illustrating method', 'abstract missing', 'investigate representational power sum product network computation network analogous neural network whose individual unit compute either product weighted sum theoretical analysis compare deep multiple hidden layer v shallow one hidden layer architecture prove exist family function represented much efficiently deep network shallow one e substantially fewer hidden unit result available contribute motivate recent research involving learning deep sum product network generally motivate research deep learning', 'markov random field mrfs proven powerful density estimator feature extractor classification however use often limited inability estimate partition function z paper exploit gradient descent training procedure restricted boltzmann machine type mrf bf track log partition function learning method relies two distinct source information estimating change delta z incurred gradient update estimating difference z small set tempered distribution using bridge sampling two source information combined using inference procedure similar kalman filtering learning mrfs tempered stochastic maximum likelihood estimate z using temperature required learning comparing exact value estimate using annealed importance sampling ai show several datasets method able accurately track log partition function contrast ai method provides estimate time step computational cost similar required training alone', 'common approach handling complexity inherent ambiguity human pose estimation use pose prior learned training data existing approach however either simplistic linear complex learn learn latent space simple data e single activity walking running paper present efficient stochastic gradient descent algorithm able learn probabilistic non linear latent space composed multiple activity furthermore derive incremental algorithm online setting update latent space without extensive relearning demonstrate effectiveness approach task monocular multi view tracking show approach outperforms state art', 'given set v n vector dimensional space provide efficient method computing quality upper lower bound euclidean distance pair vector v purpose define distance measure called m distance using mean standard deviation value vector v compute mean standard deviation value vector v dn time m distance provides upper lower bound euclidean distance pair vector v constant time furthermore bound refined converge monotonically exact euclidean distance within refinement step also provide analysis random sequence refinement step justify m distance refined provide tight bound step typical sequence m distance used various problem euclidean distance used measure proximity similarity object provide experimental result nearest farthest neighbor search', 'object people perceive image depend orientation relative scene reference frame example image symbol time differ degree rotation although real scene multiple image reference frame psychologist focused scene one reference frame propose ideal observer model based nonparametric bayesian statistic inferring number reference frame scene parameter ambiguous image could assigned two conflicting reference frame model predicts two factor influence reference frame inferred image image likely share reference frame closer object em proximity likely share reference frame containing object em alignment confirm people use cue using novel methodology allows easy testing human reference frame inference', 'variability single neuron model typically implemented either stochastic leaky integrate fire model model generalized linear model glm family use analytical numerical method relate state art model school thought first find analytical expression relating subthreshold voltage adaptive exponential integrate fire model adex spike response model escape noise srm example glm calculate numerically link function provides firing probability given deterministic membrane potential find mathematical expression link function test ability glm predict firing probability neuron receiving complex stimulation comparing prediction performance various link function find glm exponential link function provides excellent approximation adaptive exponential integrate fire colored noise input result help understand relationship different approach stochastic neuron model', 'able predict course arbitrary chemical reaction essential theory application organic chemistry previous approach high throughput generalizable scalable lack sufficient data effective describe single mechanistic reaction concerted electron movement electron orbital source electron orbital sink use existing rule based expert system derive dataset consisting productive mechanistic step million non productive mechanistic step pose identifying productive mechanistic step ranking problem rank potential orbital interaction top ranked interaction yield major product machine learning implementation follows two stage approach first train atom level reactivity filter prune non productive reaction le false negative rate train ensemble ranking model pair interacting orbitals learn relative productivity function single mechanistic reaction given system without use explicit transformation pattern ensemble perfectly rank productive mechanism top time rising time top ranked list four non productive reaction considered final system allows multi step reaction prediction furthermore generalizable making reasonable prediction reactant condition rule based expert system handle', 'maximum entropy model become popular statistical model neuroscience area biology useful tool obtaining estimate mu tual information biological system however maximum entropy model fit small data set subject sampling bias e true entropy data severely underestimated study sampling property estimate entropy obtained maximum entropy model show data generated distribution lie model class bias equal number parameter divided twice number observation however practice true distribution usually outside model class show misspecification lead much larger bias provide perturba tive approximation maximally expected bias true model model class illustrate result using numerical simulation ising model e second order maximum entropy distribution binary data', 'renewal process generalization poisson process real line whose interval drawn distribution modulated renewal process allow distribution vary time allowing introduction nonstationarity work take nonparametric bayesian approach modeling nonstationarity gaussian process approach based idea uniformization allowing u draw exact sample otherwise intractable distribution develop novel efficient mcmc sampler posterior inference experiment test number synthetic real datasets', 'present optimization approach linear svms based stochastic primal dual approach primal step akin importance weighted sgd dual step stochastic update importance weight yield optimization method sublinear dependence training set size first method learning linear svms runtime le size training set required learning', 'abstract missing', 'many clustering problem access multiple view data could individually used clustering exploiting information multiple view one hope find clustering accurate one obtained using individual view since true clustering would assign point cluster irrespective view approach problem looking clustering consistent across view e corresponding data point view cluster membership propose spectral clustering framework achieves goal co regularizing clustering hypothesis propose two co regularization scheme accomplish experimental comparison number baseline two synthetic three real world datasets establish efficacy proposed approach', 'distance dependent chinese restaurant process ddcrp recently introduced accommodate random partition non exchangeable data ddcrp cluster data biased way data point likely clustered data near external sense paper examines ddcrp spatial setting goal natural image segmentation explore bias spatial ddcrp model propose novel hierarchical extension better suited producing human like segmentation study sensitivity model various distance appearance hyperparameters provide first rigorous comparison nonparametric bayesian model image segmentation domain unsupervised image segmentation demonstrate similar performance existing nonparametric bayesian model possible substantially simpler model algorithm', 'abstract missing', 'train statistical mixture model massive data set paper show construct coresets mixture gaussians natural generalization coreset weighted subset data guarantee model fitting coreset also provide good fit original data set show perhaps surprisingly gaussian mixture admit coresets size independent size data set precisely prove weighted set dk eps data point suffices computing eps approximation optimal model original n data point moreover coresets efficiently constructed map reduce style computation well streaming setting result rely novel reduction statistical estimation problem computational geometry well new complexity result mixture gaussians empirically evaluate algorithm several real data set including density estimation problem context earthquake detection using accelerometer mobile phone', 'storing new pattern palimpsest memory system come cost interfering memory trace previously stored item knowing age pattern thus becomes critical recalling faithfully implies tight coupling estimate age form familiarity neural dynamic recollection something current theory omit using normative model autoassociative memory show dual memory system consisting two interacting module familiarity recollection best performance recollection recognition finding provides new window onto actively contentious psychological neural aspect recognition memory', 'unlike existing nonparametric bayesian model rely solely specially conceived prior incorporate domain knowledge discovering improved latent representation study nonparametric bayesian inference regularization desired posterior distribution prior indirectly affect posterior distribution bayes theorem imposing posterior regularization arguably direct case much easier particularly focus developing infinite latent support vector machine ilsvm multi task infinite latent support vector machine mt ilsvm explore large margin idea combination nonparametric bayesian model discovering predictive latent feature classification multi task learning respectively present efficient inference method report empirical study several benchmark datasets result appear demonstrate merit inherited large margin learning bayesian nonparametrics', 'consider adversarial online learning setting decision maker choose action every stage game addition observing reward chosen action decision maker get side observation reward would obtained chosen action observation structure encoded graph node linked node j sampling provides information reward j setting naturally interpolates well known expert setting decision maker view reward multi armed bandit setting decision maker view reward chosen action develop practical algorithm provable regret guarantee depend non trivial graph theoretic property information feedback structure also provide partially matching lower bound', 'computing good strategy large extensive form game often demand extraordinary amount computer memory necessitating use abstraction reduce game size typically strategy abstract game perform better real game granularity abstraction increased paper investigates two technique stitching base strategy coarse abstraction full game tree expert strategy fine abstraction smaller subtrees provide general framework creating static expert approach generalizes previous strategy stitching effort addition show static expert create strong agent player player leduc limit texas hold em poker specific class static expert preferred among number alternative furthermore describe poker agent used static expert player event annual computer poker competition', 'present type temporal restricted boltzmann machine defines probability distribution output sequence conditional input sequence share desirable property rbms efficient exact inference exponentially expressive latent state hmms ability model nonlinear structure dynamic apply model challenging real world graphic problem facial expression transfer result demonstrate improved performance several baseline modeling high dimensional data', 'psychologist long struck individual limitation expressing internal sensation impression evaluation via rating scale instead using absolute scale individual rely reference point recent experience relativity judgment limit informativeness response survey questionnaire evaluation form fortunately cognitive process map stimulus response simply noisy rather influenced recent experience lawful manner explore technique remove sequential dependency thereby decontaminate series rating obtain meaningful human judgment formulation problem infer latent subjective impression sequence stimulus label e g movie name response describe unsupervised approach simultaneously recovers impression parameter contamination model predicts recent judgment affect current response test iterated impression inference algorithm three domain rating gap dot desirability movie based advertisement morality action demonstrate significant objective improvement quality recovered impression', 'abstract missing', 'consider problem ising gaussian graphical model selection given n sample model propose efficient threshold based algorithm structure estimation based known conditional mutual information test simple local algorithm requires low order statistic data decides whether two node neighbor unknown graph transparent assumption establish proposed algorithm structurally consistent sparsistent number sample scale n omega j min log p p number node j min minimum edge potential also prove novel non asymptotic necessary condition graphical model selection', 'many fundamental question theoretical neuroscience involve optimal decoding computation shannon information rate population spiking neuron paper apply method asymptotic theory statistical inference obtain clearer analytical understanding quantity find large neural population carrying finite total amount information full spiking population response asymptotically informative single observation gaussian process whose mean covariance characterized explicitly term network single neuron property gaussian form asymptotic sufficient statistic allows u certain case perform optimal bayesian decoding simple linear transformation obtain closed form expression shannon information carried network one technical advantage theory may applied easily even non poisson point process network model example find condition neural population strong history dependent non poisson effect carry exactly information simpler equivalent population non interacting poisson neuron matched firing rate argue finding help clarify result recent literature neural decoding neuroprosthetic design', 'abstract missing', 'consider feature selection weighting nearest neighbor classifier technical challenge scenario cope discrete update nearest neighbor feature space metric changed learning process issue called target neighbor change properly addressed existing feature weighting metric learning literature paper propose novel feature weighting algorithm exactly efficiently keep track correct target neighbor via sequential quadratic programming best knowledge first algorithm guarantee consistency target neighbor feature space metric show proposed algorithm naturally combined regularization path tracking allowing computationally efficient selection regularization parameter demonstrate effectiveness proposed algorithm experiment', 'probabilistic logic receiving lot attention today expressive power knowledge representation learning however expressivity detrimental tractability inference done propositional level solve problem various lifted inference algorithm proposed reason first order level group object whole despite existence various lifted inference approach currently completeness result algorithm key contribution paper introduce formal definition lifted inference allows u reason completeness lifted inference algorithm relative particular class probabilistic model show obtain completeness result using first order knowledge compilation approach theory formula containing two logical variable', 'recovering hidden structure complex noisy non linear data one fundamental problem machine learning statistical inference data often high dimensional interest approximate low dimensional even one dimensional space since many important aspect data often intrinsically low dimensional furthermore many scenario underlying structure graph like e g river road network various trajectory paper develop framework extract well simplify one dimensional skeleton unorganized data using reeb graph algorithm simple require complex optimization easily applied unorganized high dimensional data point cloud proximity graph also represent arbitrary graph structure data also give theoretical result justify method provide number experiment demonstrate effectiveness generality algorithm including comparison existing method principal curve believe simplicity practicality algorithm help promote skeleton graph data analysis tool broad range application', 'paper study privacy preserving estimator using perturbed histogram proposed approach allows release wide class estimator differential privacy statistical utility without knowing priori particular inference procedure performance proposed method demonstrated careful study convergence rate practical algorithm given applied real world data set containing continuous categorical variable', 'extend classical problem predicting sequence outcome finite alphabet matrix domain extension alphabet n outcome replaced set dyad e outer product u u top u vector r n unit length whereas classical case goal learn e sequentially predict well best multinomial distribution matrix case desire learn density matrix best explains observed sequence dyad show popular online algorithm learning multinomial distribution extended learn density matrix intuitively learning n parameter density matrix much harder learning n parameter multinomial distribution completely surprisingly prove worst case regret certain classical algorithm matrix generalization identical reason worst case sequence dyad share common eigensystem e worst case regret achieved classical case matrix algorithm learn eigenvectors without regret', 'many real world application often need select correlated variable genetic variation imaging feature associated alzheimer disease high dimensional space correlation variable present challenge classical variable selection method address challenge elastic net developed successfully applied many application despite great success elastic net exploit correlation information embedded data select correlated variable overcome limitation present novel hybrid model eigennet us eigenstructures data guide variable selection specifically integrates sparse conditional classification model generative model capturing variable correlation principled bayesian framework develop efficient active set algorithm estimate model via evidence maximization experiment synthetic data imaging genetics data demonstrated superior predictive performance eigennet lasso elastic net automatic relevance determination', 'motivated spread line information general line petition particular recent research raised following combinatorial estimation problem tree cannot observe directly representing structure along information spread certain node randomly decide make copy information public case petition list name public copy petition also reveals path leading back root tree conclude property tree observe revealed path use structure observed tree estimate size full unobserved tree provide first algorithm size estimation task together provable guarantee performance also establish structural property observed tree providing first rigorous explanation unusual structural phenomenon present spread real chain letter petition internet', 'abstract missing', 'present explicit class probability distribution learned restricted boltzmann machine rbms depending number unit contain representative expressive power model use show maximal kullback leibler divergence rbm model n visible hidden unit bounded n log way specify number hidden unit guarantee sufficiently rich model containing different class distribution respecting given error tolerance', 'paper address problem finding nearest neighbor one r nearest neighbor query object q database n object use comparison oracle comparison oracle given two reference object query object return reference object similar query object main problem study search database nearest neighbor nn query minimizing question difficulty problem depends property underlying database show importance characterization emph combinatorial disorder defines approximate triangle inequality rank present lower bound omega log frac n average number question search phase randomized algorithm demonstrates fundamental role worst case behavior develop randomized scheme nn retrieval log n log n log log n question learning requires asking n log n log n log log n question n log n log bit store', 'machine learning competition netflix prize proven reasonably successful method crowdsourcing prediction task compe titions number weakness particularly incentive structure create participant propose new approach called crowdsourced learning mechanism participant collaboratively learn hypothesis given prediction task approach draw heavily concept prediction market trader bet likelihood future event framework mechanism continues publish current hypothesis par ticipants modify hypothesis wagering update critical centive property participant profit amount scale according much update improves performance released test set', 'consider statistical framework recurrent network spiking neuron learn generate spatio temporal spike pattern given biologically realistic stochastic neuronal dynamic derive tractable learning rule synaptic weight towards hidden visible neuron lead optimal recall training sequence show learning synaptic weight towards hidden neuron significantly improves storing capacity network furthermore derive approximate online learning rule show learning rule consistent spike timing dependent plasticity presynaptic spike shortly precedes postynaptic spike potentiation induced otherwise depression elicited', 'abstract missing', 'factored decentralized partially observable markov decision process dec pomdps form powerful framework multiagent planning uncertainty optimal solution require rigid history based policy representation paper allow inter agent communication turn problem centralized multiagent pomdp mpomdp map belief distribution state factor agent local action exploiting structure joint mpomdp policy key point sparse dependency agent decision exist often belief local state factor sufficient agent unequivocally identify optimal action communication avoided formalize notion casting problem convex optimization form present experimental result illustrating saving communication obtain', 'paper study problem accurately recovering sparse vector beta star highly corrupted linear measurement x beta star e star w e star sparse error vector whose nonzero entry may unbounded w bounded noise propose called extended lasso optimization take consideration sparse prior information beta star e star first result show extended lasso faithfully recover regression corruption vector analysis relied notion extended restricted eigenvalue design matrix x second set result applies general class gaussian design matrix x row oper n sigma provide surprising phenomenon extended lasso recover exact signed support beta star e star omega k log p log n observation even fraction corruption arbitrarily close one analysis also show amount observation required achieve exact signed support optimal', 'derive plausible learning rule updating synaptic efficacy feedforward feedback lateral connection observed latent neuron operating context generative model distribution spike sequence learning mechanism derived variational inference principle synaptic plasticity rule found interesting strongly reminiscent experimentally found result spike time dependent plasticity differ excitatory inhibitory neuron simulation confirms method applicability learning stationary temporal spike pattern', 'consider sequence bit trying predict next bit previous bit assume allowed say predict predict payoff prediction correct otherwise say point time loss algorithm number wrong prediction minus number right prediction far paper interested algorithm essentially zero expected loss string point time yet small regret respect always predicting always predicting sequence length algorithm regret epsilon loss sqrt e epsilon expectation string show tradeoff loss regret optimal constant factor technique extend general setting n expert related problem trading regret best expert regret special expert studied even dar et al colt obtain essentially zero loss respect special expert optimal loss regret tradeoff improving upon result even dar et al colt settling main question left open paper strong loss bound algorithm surprising consequence first obtain parameter free algorithm expert problem optimal regret bound respect k shifting optimum e bound respect optimum allowed change arm multiple time moreover em window size n regret algorithm expert never exceeds sqrt n log n log n number expert time horizon maintaining essentially zero loss property', 'f measure originally introduced information retrieval nowadays routinely used performance metric problem binary classification multi label classification structured output prediction optimizing measure remains statistically computationally challenging problem since closed form maximizer exists current algorithm approximate typically rely additional assumption regarding statistical distribution binary response variable paper present algorithm computationally efficient also exact regardless underlying distribution algorithm requires quadratic number parameter joint distribution respect number binary response illustrate practical performance mean experimental result multi label classification', 'abstract missing', 'stochastic gradient descent sgd popular algorithm achieve state art performance variety machine learning task several researcher recently proposed scheme parallelize sgd require performance destroying memory locking synchronization work aim show using novel theoretical analysis algorithm implementation sgd implemented without locking present update scheme called hogwild allows processor access shared memory possibility overwriting work show associated optimization problem sparse meaning gradient update modify small part decision variable hogwild achieves nearly optimal rate convergence demonstrate experimentally hogwild outperforms alternative scheme use locking order magnitude', 'loopy belief propagation performs approximate inference graphical model loop one might hope compensate approximation adjusting model parameter learning algorithm purpose explored previously claim made every set locally consistent marginals arise belief propagation run graphical model contrary show many probability distribution marginals cannot reached belief propagation using set model parameter learning algorithm call marginals unbelievable problem occurs whenever hessian bethe free energy positive definite target marginals learning algorithm belief propagation necessarily fail case producing belief set belief may even worse pre learning approximation show averaging inaccurate belief obtained belief propagation using model parameter perturbed learned mean value achieve unbelievable marginals', 'many real world network described connectivity information feature every node better model understand network present structure preserving metric learning spml algorithm learning mahalanobis distance metric network learned distance tied inherent connectivity structure network like graph embedding algorithm structure preserving embedding spml learns metric structure preserving meaning connectivity algorithm k nearest neighbor yield correct connectivity applied using distance learned metric show variety synthetic real world experiment spml predicts link pattern node feature accurately standard technique demonstrate method optimizing spml based stochastic gradient descent remove running time dependency size network allows method easily scale network thousand node million edge', 'model human visual search proposed predicts response time rt error rate rt function image parameter target contrast clutter model ideal observer optimizes bayes ratio tar get present v target absent ratio computed firing pattern v v neuron modeled poisson distribution optimal mechanism integrat ing information time shown soft max diffusion computed visual field hypercolumns neuron share receptive field different response property image feature approximation optimal bayesian observer based integrating local decision rather diffusion also derived shown experimentally produce similar pre diction psychophyisics experiment proposed may discriminate mechanism used human brain', 'latent tree graphical model natural tool expressing long range hierarchical dependency among many variable common computer vision bioinformatics natural language processing problem however existing model largely restricted discrete gaussian variable due computational constraint furthermore algorithm estimating latent tree structure learning model parameter largely restricted heuristic local search present method based kernel embeddings distribution latent tree graphical model continuous non gaussian variable method recover latent tree structure provable guarantee perform local minimum free parameter learning efficient inference experiment simulated real data show advantage proposed approach', 'introduce piecewise constant conditional intensity model model learning temporal dependency event stream describe closed form bayesian approach learning model describe importance sampling algorithm forecasting future event using model using proposal distribution based poisson superposition use synthetic data supercomputer event log web search query log illustrate learning algorithm efficiently learn nonlinear temporal dependency importance sampling algorithm effectively forecast future event', 'crowdsourcing system task electronically distributed numerous information piece worker emerged effective paradigm human powered solving large scale problem domain image classification data entry optical character recognition recommendation proofreading low paid worker unreliable nearly crowdsourcers must devise scheme increase confidence answer typically assigning task multiple time combining answer way majority voting paper consider general model rowdsourcing task pose problem minimizing total price e number task assignment must paid achieve target overall reliability give new algorithm deciding task assign worker inferring correct answer worker answer show algorithm significantly outperforms majority voting fact asymptotically optimal comparison oracle know reliability every worker', 'cancer complex pattern progression include converging well diverging progressional pathway vogelstein path model colon cancer pioneering contribution cancer research since several attempt made obtaining mathematical model cancer progression devising learning algorithm applying cross sectional data beerenwinkel em et al provided coined em like algorithm oncogenetic tree ots mixture given small size current future data set important minimize number parameter model reason focus tree based model introduce hidden variable oncogenetic tree hots contrast ots hots allow error data thereby provide realistic modeling also design global structural em algorithm learning hots mixture hots hot mixture algorithm global sense step find structure yield global maximum expected complete log likelihood rather merely one improves algorithm single hots performs well reasonable sized data set hot mixture requires data set size obtainable tomorrow cost efficient technology', 'paper study problem semi supervised learning vector field perspective many existing work use graph laplacian ensure smoothness prediction function data manifold however beyond smoothness suggested recent theoretical work ensure second order smoothness achieving faster rate convergence semi supervised regression problem achieve goal show second order smoothness measure linearity function gradient field linear function parallel vector field consequently propose find function minimizes empirical error simultaneously requires gradient field parallel possible give continuous objective function manifold discus discretize using random point discretized optimization problem turn sparse linear system solved efficiently experimental result demonstrated effectiveness proposed approach', 'metric learning become active research field popular representative mahalanobis metric learning seen learning linear transformation computing euclidean metric transformed space since linear transformation might always appropriate given learning problem kernelized version various metric learning algorithm exist however problem becomes finding appropriate kernel function multiple kernel learning address limitation learning linear combination number predefined kernel approach also readily used context multiple source learning fuse different data source surprisingly despite extensive work multiple kernel learning svms work area metric learning multiple kernel learning paper fill gap present general approach metric learning multiple kernel learning approach instantiated different metric learning algorithm provided satisfy constraint experimental evidence suggests approach outperforms metric learning unweighted kernel combination metric learning cross validation based kernel selection', 'abstract missing', 'abstract missing', 'abstract missing', 'nonparametric bayesian method developed analysis multi channel spike train data feature learning spike sorting performed jointly feature learning sorting performed simultaneously across channel dictionary learning implemented via beta bernoulli process spike sorting performed via dynamic hierarchical dirichlet process dhdp two model coupled dhdp augmented eliminate refractoryperiod violation allows appearance disappearance neuron time model smooth variation spike statistic', 'consider large matrix low rank address problem recovering matrix entry unknown matrix completion find application recommender system setting row matrix may correspond item column may correspond user known entry rating given user item aim predict unobserved rating problem commonly stated constrained optimization framework follow approach exploit geometry low rank constraint recast problem unconstrained optimization problem grassmann manifold apply first second order riemannian trust region method solve cost iteration linear number known entry method rtrmc outperform state art algorithm wide range problem instance', 'minwise hashing standard technique context search efficiently computing set similarity recent development b bit minwise hashing provides substantial improvement storing lowest b bit hashed value paper demonstrate b bit minwise hashing naturally integrated linear learning algorithm linear svm logistic regression solve large scale high dimensional statistical learning task especially data fit memory compare b bit minwise hashing count min cm vowpal wabbit vw algorithm essentially variance random projection theoretical empirical comparison illustrate b bit minwise hashing significantly accurate storage cost vw random projection binary data', 'argued perceptual multistability reflects probabilistic inference performed brain sensory input ambiguous alternatively traditional explanation multistability refer low level mechanism neuronal adaptation employ deep boltzmann machine dbm model cortical processing demonstrate two different approach combined framework based recent development machine learning show neuronal adaptation understood mechanism improves probabilistic sampling based inference using ambiguous necker cube image analyze perceptual switching exhibited model also examine influence spatial attention explore binocular rivalry modeled approach work join earlier study demonstrating principle underlying dbms relate cortical processing offer novel perspective neural implementation approximate probabilistic inference brain', 'inferring key unobservable feature individual important task applied science particular important source data field marketing social science medicine questionnaire answer questionnaire noisy measure target unobserved feature comprehensive survey help better estimate latent variable interest aiming high number question come price refusal participate survey go well rate missing data quality answer decline cost associated applying questionnaire also increase paper cast problem refining existing model questionnaire data follows solve constrained optimization problem preserving maximum amount information found latent variable model using subset existing question goal find optimal subset given size first define information theoretical measure quantifying quality reduced questionnaire three different approximate inference method introduced solve problem comparison simple powerful heuristic presented', 'many state art computer vision algorithm image segmentation important preprocessing step several image segmentation algorithm proposed however certain reservation due high computational load many hand tuning parameter correlation clustering graph partitioning algorithm often used natural language processing document clustering potential perform better previously proposed image segmentation algorithm improve basic correlation clustering formulation taking account higher order cluster relationship improves clustering presence local boundary ambiguity first apply pairwise correlation clustering image segmentation pairwise superpixel graph develop higher order correlation clustering hypergraph considers higher order relation among superpixels fast inference possible linear programming relaxation also effective parameter learning framework structured support vector machine possible experimental result various datasets show proposed higher order correlation clustering outperforms state art image segmentation algorithm', 'variational message passing vmp algorithmic implementation variational bayes vb method applies special case conjugate exponential family model propose extension vmp refer non conjugate variational message passing ncvmp aim alleviate restriction maintaining modularity allowing choice expectation calculated integrating existing message passing framework infer net demonstrate ncvmp logistic binary multinomial regression multinomial case introduce novel variational bound softmax factor tighter commonly used bound whilst maintaining computational tractability', 'high dimensional similarity search large scale database becomes important challenge due advent internet application specialized data structure required achieve computational efficiency traditional approach relied algorithmic construction often data independent locality sensitive hashing weakly dependent kd tree k mean tree supervised learning algorithm applied related problem proposed literature mainly focused learning hash code optimized compact embedding data rather search efficiency consequently embedding used linear scan another search algorithm hence learning hash directly address search efficiency issue paper considers new framework applies supervised learning directly optimize data structure support efficient large scale search approach take search quality computational cost consideration specifically learn boosted search forest optimized using pair wise similarity labeled example output search forest efficiently converted inverted indexing data structure leverage modern text search infrastructure achieve scalability efficiency experimental result show approach significantly outperforms start art learning hash method spectral hashing well state art high dimensional search algorithm lsh k mean tree', 'abstract missing', 'abstract missing', 'exploration exploitation trade among central challenge reinforcement learning optimal bayesian solution intractable general paper study extent analytic statement optimal learning possible belief gaussian process first order approximation learning loss dynamic nonlinear time varying system continuous time space subject relatively weak restriction dynamic described infinite dimensional partial differential equation approximate finite dimensional projection give impression result may helpful', 'neuron typically respond restricted number stimulus feature within high dimensional space natural stimulus describe explicit model based interpretation traditional estimator neuron multi dimensional feature space allows several important generalization extension first show traditional estimator based spike triggered average sta spike triggered covariance stc formalized term expected log likelihood linear nonlinear poisson lnp model gaussian stimulus model based formulation allows u define maximum likelihood bayesian estimator statistically consistent efficient wider variety setting naturalistic non gaussian stimulus also allows u employ bayesian method regularization smoothing sparsification model comparison provides bayesian confidence interval model parameter describe empirical bayes method selecting number feature extend model accommodate arbitrary elliptical nonlinear response function result powerful flexible model feature space inference validate method using neural data recorded extracellularly macaque primary visual cortex', 'hallmark modern machine learning ability deal high dimensional problem exploiting structural assumption limit degree freedom underlying model deep understanding capability limit high dimensional learning method specific assumption sparsity group sparsity low rank attained effort negahban et al chandrasekaran et al underway distill valuable experience proposing general unified framework achieve twin goal summarizing previous analysis enabling application notion structure hitherto unexplored inspired development propose analyze general computational scheme based greedy strategy solve convex optimization problem arise dealing structurally constrained high dimensional problem framework unifies existing greedy algorithm recovering special case also yield novel one finally extend result infinite dimensional problem using interesting connection smoothness norm behavior martingale banach space', 'show general class convex online learning problem mirror descent always achieve nearly optimal regret guarantee', 'nonparametric kernel based method realizing bayes rule proposed based kernel representation probability reproducing kernel hilbert space prior conditional probability expressed empirical kernel mean covariance operator respectively kernel mean posterior distribution computed form weighted sample kernel bayes rule applied wide variety bayesian inference problem demonstrate bayesian computation without likelihood filtering nonparametric state space model consistency rate posterior estimate established', 'problem selecting right state representation reinforcement learning problem considered several model function mapping past observation finite set observation given known least one model resulting state dynamic indeed markovian without knowing neither model correct one probabilistic characteristic resulting mdp required obtain much reward optimal policy correct model best correct model several propose algorithm achieves regret order horizon time', 'consider problem estimating neural spike extracellular voltage recording current method based clustering requires substantial human supervision produce systematic error failing properly handle temporally overlapping spike formulate problem one statistical inference recorded voltage noisy sum spike train neuron convolved associated spike waveform joint maximum posteriori map estimation waveform spike blind deconvolution problem coefficient sparse develop block coordinate descent method approximating map solution validate method data simulated according generative model well real data ground truth available via simultaneous intracellular recording case method substantially reduces number missed spike false positive compared standard clustering algorithm primarily recovering temporally overlapping spike method offer fully automated alternative clustering method le susceptible systematic error', 'improve theoretical analysis empirical performance algorithm stochastic multi armed bandit problem linear stochastic multi armed bandit problem particular show simple modification auer ucb algorithm auer achieves high probability constant regret importantly modify consequently improve analysis algorithm linear stochastic bandit problem studied auer dani et al rusmevichientong tsitsiklis li et al modification improves regret bound logarithmic factor though experiment show vast improvement case improvement stem construction smaller confidence set construction use novel tail inequality vector valued martingale', 'scene understanding task object detection depth estimation classifier need consider contextual information addition local feature capture contextual information taking input feature attribute region image however contextual dependence also varies spatial location region interest therefore need different set parameter spatial location result large number parameter work model independence property parameter location task defining markov random field mrf parameter particular two set parameter encouraged similar value spatially close semantically close method principle complementary way capturing context one use graphical model label instead extensive evaluation two different setting multi class object detection multiple scene understanding task scene categorization depth estimation geometric labeling method beat state art method four task', 'abstract missing', 'abstract missing', 'present probabilistic algorithm nonlinear inverse reinforcement learning goal inverse reinforcement learning learn reward function markov decision process expert demonstration prior inverse reinforcement learning algorithm represent reward linear combination set feature use gaussian process learn reward nonlinear function also determining relevance feature expert policy probabilistic algorithm allows complex behavior captured suboptimal stochastic demonstration automatically balancing simplicity learned reward structure consistency observed action', 'log linear model widely used probability model statistical pattern recognition typically log linear model trained according convex criterion recent year interest log linear model greatly increased optimization log linear model parameter costly therefore important topic particular large scale application different optimization algorithm evaluated empirically many paper work analyze optimization problem analytically show training log linear model highly ill conditioned verify finding two handwriting task making use convergence analysis obtain good result large scale continuous handwriting recognition task simple generic approach', 'loopy belief propagation lbp utilized wide variety application empirical success come theoretical guarantee especially interaction random variable graphical model strong behavior algorithm difficult analyze due underlying phase transition paper develop novel approach uniqueness problem lbp fixed point new necessary sufficient condition stated term graph sign sign denotes type attractive repulsive interaction e compatibility function edge previous work uniqueness guaranteed situation strength interaction sufficiently small certain sens contrast condition cover arbitrary strong interaction specified class signed graph result paper based recent theoretical advance lbp algorithm connection graph zeta function', 'given one feature novel animal human readily make inference feature animal example winged creature often fly creature eat fish often live water explore knowledge support inference compare two approach first approach proposes human rely abstract representation dependency relationship feature formalized graphical model second approach proposes human rely specific knowledge previously encountered animal formalized family exemplar model evaluate model using task participant reason chimera animal pair feature previously observed co occur result support hypothesis human rely explicit representation relationship feature', 'study particular class cyclic causal model variable possibly nonlinear function parent additive noise prove causal graph model generically identifiable bivariate gaussian noise case also propose method learn model observational data acyclic case method reduces ordinary regression challenging cyclic case additional term arises loss function make special case nonlinear independent component analysis illustrate proposed method synthetic data', 'increasingly optimization problem machine learning especially arising high dimensional statistical estimation large number variable modern statistical estimator developed past decade statistical sample complexity depends weakly number parameter structure problem sparsity central question whether similar advance made computational complexity well paper propose strategy indicate advance indeed made particular investigate greedy coordinate descent algorithm note performing greedy step efficiently weakens costly dependence problem size provided solution sparse propose suite method perform greedy step efficiently reduction nearest neighbor search also devise amenable form greedy descent composite non smooth objective well several approximate variant greedy descent develop practical implementation algorithm combine greedy coordinate descent locality sensitive hashing without tuning latter data structure able significantly speed vanilla greedy method also outperform cyclic descent problem size becomes large result indicate effectiveness nearest neighbor strategy also point many open question regarding development computational geometric technique tailored towards first order optimization method', 'component estimated independent component analysis related method typically independent real data common form nonlinear dependency component correlation variance ener gy propose principled probabilistic model model energy correlation latent variable two stage model includes linear mixing latent signal observed one like ica main new fea ture model energy correlation based structural equation model sem particular linear non gaussian sem sem closely related divisive normalization effectively reduces energy correlation new two stage model enables estimation linear mixing interaction lated energy correlation without resorting approximation likelihood function non principled approach demonstrate applicability method synthetic dataset natural image brain signal', 'paper examines problem ranking collection object using pairwise comparison ranking two object general ranking n object identified standard sorting method using n log n pairwise comparison interested natural situation relationship among object may allow ranking using far fewer pairwise comparison specifically assume object embedded dimensional euclidean space ranking reflect relative distance common reference point r show assumption number possible ranking grows like n demonstrate algorithm identify randomly selected ranking using slightly log n adaptively selected pairwise comparison average instead comparison chosen random almost pairwise comparison must made order identify ranking addition propose robust error tolerant algorithm requires pairwise comparison probably correct experimental study synthetic real datasets support conclusion theoretical analysis', 'given set v n element wish linearly order using pairwise preference label may non transitive due irrationality arbitrary noise goal linearly order element disagreeing pairwise preference label possible performance measured two parameter number disagreement loss query complexity number pairwise preference label algorithm adaptively query n poly log n eps preference label regret eps time optimal loss strictly better often significantly better non adaptive sampling could achieve main result help settle open problem posed learning rank pairwise information theoretician practitioner provably correct way sample preference label', 'generalized linear model glms single index model sims provide powerful generalization linear regression target variable assumed possibly unknown dimensional function linear predictor general problem entail non convex estimation procedure practice iterative local search heuristic often used kalai sastry provided first provably efficient method emph isotron algorithm learning sims glms assumption data fact generated glm certain monotonicity lipschitz bounded slope constraint isotron algorithm interleaf step perceptron like update isotonic regression fitting one dimensional non decreasing function however obtain provable performance method requires fresh sample every iteration paper provide algorithm learning glms sims computationally statistically efficient modify isotonic regression step isotron fit lipschitz monotonic function also provide efficient n log n algorithm step improving upon previous n algorithm provide brief empirical study demonstrating feasibility algorithm practice', 'abstract missing', 'latent variable mixture model powerful tool exploring structure large datasets common challenge interpreting model desire impose sparsity natural assumption data point contains latent feature since mixture distribution constrained l norm typical sparsity technique based l regularization become toothless concave regularization becomes necessary unfortunately concave regularization typically result em algorithm must perform problematic non concave step maximization work introduce technique circumventing difficulty using called mountain pas theorem provide easily verifiable condition step well behaved despite lacking concavity also develop correspondence logarithmic regularization term pseudo dirichlet distribution generalization ordinary dirichlet distribution well suited inducing sparsity demonstrate approach text corpus inferring sparse topic mixture model weblogs', 'nested chinese restaurant process extended design nonparametric topic model tree representation human choice tree branch corresponds type person node topic corresponding probability vector item may selected observed data assumed associated temporal covariates corresponding time choice made wish impose increasing time probable topic deeper tree utilized structure imposed developing new change point stick breaking model coupled poisson product gamma construction share topic across tree node topic distribution drawn dirichlet process demonstration concept analyze real data course selection undergraduate student duke university goal uncovering concisely representing structure curriculum characteristic student body', 'mini batch algorithm recently received significant attention way speed stochastic convex optimization problem paper study algorithm improved using accelerated gradient method provide novel analysis show standard gradient method may sometimes insufficient obtain significant speed propose novel accelerated gradient algorithm deal deficiency enjoys uniformly superior guarantee conclude paper experiment real world datasets validates algorithm substantiates theoretical insight', 'domain adaptation algorithm seek generalize model trained source domain new target domain many practical case source target distribution differ substantially case crucial target feature may support source domain paper introduce algorithm bridge gap source target domain slowly adding target feature instance current algorithm confident algorithm variant co training name coda co training domain adaptation unlike original co training work assume particular feature split instead iteration co training add target feature formulate single optimization problem simultaneously learns target predictor split feature space view shared subset source target feature include predictor coda significantly performs state art domain benchmark data set blitzer et al indeed wide range comparison target supervision ranging labeled target data relatively large number target label coda achieves best performance', 'many machine learning signal processing problem formulated linearly constrained convex program could efficiently solved alternating direction method adm however usually subproblems adm easily solvable linear mapping constraint identity address issue propose linearized adm ladm method linearizing quadratic penalty term adding proximal term solving subproblems fast convergence also allow penalty change adaptively according novel update rule prove global convergence ladm adaptive penalty ladmap example apply ladmap solve low rank representation lrr important subspace clustering technique yet suffers high computation cost combining ladmap skinny svd representation technique able reduce complexity n original adm based method rn r n rank size representation matrix respectively hence making lrr possible large scale application numerical experiment verify lrr ladmap based method much faster state art algorithm', 'transfer reinforcement learning rl method leverage experience collected set source task speed rl algorithm simple effective approach transfer sample source task include training set used solve target task paper investigate theoretical property transfer method introduce novel algorithm adapting transfer process basis similarity source target task finally report illustrative experimental result continuous chain problem', 'development statistical model continuous time longitudinal network data increasing interest machine learning social science leveraging idea survival event history analysis introduce continuous time regression modeling framework network event data incorporate time dependent network statistic time varying regression coefficient also develop efficient inference scheme allows approach scale large network synthetic real world data empirical result demonstrate proposed inference approach accurately estimate coefficient regression model useful interpreting evolution network furthermore learned model systematically better predictive performance compared standard baseline method', 'reinforcement learning model address animal behavioral adaptation changing external environment based assumption pavlovian habitual goal directed response seek maximize reward acquisition negative feedback model homeostatic regulation hand concerned behavioral adaptation response internal state animal assume animal behavioral objective minimize deviation key physiological variable hypothetical setpoints building upon drive reduction theory reward propose new analytical framework integrates learning regulatory system two seemingly unrelated objective reward maximization physiological stability prove identical proposed theory show behavioral adaptation internal external state disciplined way show proposed framework allows unified explanation behavioral phenomenon like motivational sensitivity different associative learning mechanism anticipatory response interaction among competing motivational system risk aversion', 'consider problem recovering matrix mathbf sum low rank matrix mathbf l sparse matrix mathbf small set linear measurement form mathbf mathcal mathbf mathcal bf l bf model subsumes three important class signal recovery problem compressive sensing affine rank minimization robust principal component analysis propose natural optimization problem signal recovery model develop new greedy algorithm called sparcs solve sparcs inherits number desirable property state art cosamp admira algorithm including exponential convergence efficient implementation simulation result video compressive sensing hyperspectral imaging robust matrix completion data set demonstrate accuracy efficacy algorithm', 'recent year rich variety shrinkage prior proposed great promise addressing massive regression problem general new prior expressed scale mixture normal complex form better property traditional cauchy double exponential prior first propose new class normal scale mixture novel generalized beta distribution encompasses many interesting prior special case encompassing framework prove useful comparing competing prior considering property revealing close connection develop class variational bayes approximation new hierarchy presented scale efficiently type truly massive data set encountered routinely', 'abstract missing', 'diagnosis alzheimer disease ad early stage disease development great clinical importance current clinical assessment relies primarily cognitive measure prof low sensitivity specificity fast growing neuroimaging technique hold great promise research far focused single neuroimaging modality however different modality provide complementary measure disease pathology fusion multi modality data may increase statistical power identification disease related brain region especially true early ad stage disease related region likely weak effect region difficult detected single modality alone propose sparse composite linear discriminant analysis model sclda identification disease related brain region early ad multi modality data sclda us novel formulation decomposes lda parameter product common parameter shared modality parameter specific modality enables joint analysis modality borrowing strength one another prove formulation equivalent penalized likelihood non convex regularization solved dc difference convex function programming show using dc programming property non convex regularization term preserving weak effect feature nicely revealed perform extensive simulation show sclda outperforms existing competing algorithm feature selection especially ability identifying weak effect feature apply sclda magnetic resonance imaging mri positron emission tomography pet image ad patient normal control nc study identifies disease related brain region consistent finding ad literature', 'sparse coding method explaining sensory data dictionary base possible attracted much attention computer vision visual object category recognition l regularized sparse coding combined spatial pyramid representation obtain state art performance however iterative optimization applying sparse coding onto every local feature descriptor extracted image database become major bottleneck overcome computational challenge paper present generalized lasso based approximation sparse coding glas representing distribution sparse coefficient slice transform fit piece wise linear mapping function generalized lasso also propose efficient post refinement procedure perform mutual inhibition base essential overcomplete setting experiment show glas obtains comparable performance l regularized sparse coding yet achieves significant speed demonstrating effectiveness large scale visual recognition problem', 'rational model causal induction successful accounting people judgment existence causal relationship however model focused explaining inference discrete data kind summarized contingency table severely limit scope model since world often provides non binary data develop new rational model causal induction using continuous dimension aim diminish gap empirical theoretical approach real world causal induction model successfully predicts human judgment previous study better model discrete causal inference outperforms several plausible model causal induction continuous cause accounting people inference new experiment', 'several recent advance state art image classification benchmark come better configuration existing technique rather novel approach feature learning traditionally hyper parameter optimization job human efficient regime trial possible presently computer cluster gpu processor make possible run trial show algorithmic approach find better result present hyper parameter optimization result task training neural network deep belief network dbns optimize hyper parameter using random search two new greedy sequential method based expected improvement criterion random search shown sufficiently efficient learning neural network several datasets show unreliable training dbns sequential algorithm applied difficult dbn learning problem larochelle et al find significantly better result best previously reported work contributes novel technique making response surface model p x many element hyper parameter assignment x known irrelevant given particular value element', 'study fundamental problem learning unknown large margin halfspace context parallel computation main positive result parallel algorithm learning large margin halfspace based interior point method convex optimization fast parallel algorithm matrix computation show algorithm learns unknown gamma margin halfspace n dimension using poly n gamma processor run time gamma log n contrast naive parallel algorithm learn gamma margin halfspace time depends polylogarithmically n omega gamma runtime dependence gamma main negative result deal boosting standard approach learning large margin halfspaces give information theoretic proof original pac framework weak learning algorithm provided oracle called booster boosting cannot parallelized ability call weak learner multiple time parallel within single boosting stage reduce overall number successive stage boosting required', 'diversified retrieval online learning two core research area design modern information retrieval system paper propose linear submodular bandit problem online learning setting optimizing general class feature rich submodular utility model diversified retrieval present algorithm called lsbgreedy prove efficiently converges near optimal model case study applied approach setting personalized news recommendation system must recommend small set news article selected ten thousand available article day live user study found lsbgreedy significantly outperforms existing online learning approach', 'online algorithm used machine learning today based variant mirror descent follow leader paper present online algorithm based completely different approach combine random playout randomized rounding loss subgradients application approach provide first computationally efficient online algorithm collaborative filtering trace norm constrained matrix second application solve open question linking batch learning transductive online learning', 'present computationally efficient technique compute distance high dimensional appearance descriptor vector image window method exploit relation appearance distance spatial overlap derive upper bound appearance distance given spatial overlap two window image use bound distance many pair two image propose algorithm build basic operation efficiently solve task relevant many computer vision application finding pair window two image distance smaller threshold finding single pair smallest distance experiment pascal voc dataset algorithm accurately solve problem greatly reducing number appearance distance computed achieve larger speedup approximate nearest neighbour algorithm based tree hashing example algorithm find similar pair window two image computing distance average', 'propose novel adaptive markov chain monte carlo algorithm compute partition function particular show accelerate flat histogram sampling technique significantly reducing number null move chain maintaining asymptotic convergence property experiment show method converges quickly highly accurate solution range benchmark instance outperforming state art method ijgp trw gibbs sampling run time accuracy also show obtaining called density state distribution allows efficient weight learning markov logic theory', 'present novel class actor critic algorithm actor consisting set interacting module present analyze theoretically empirically evaluate update rule module requires local information module input output td error broadcast critic update necessary computation compatible feature becomes prohibitively difficult also desirable increase biological plausibility reinforcement learning method', 'abstract missing', 'problem multiclass boosting considered new framework based multi dimensional codewords predictor introduced optimal set codewords derived margin enforcing loss proposed resulting risk minimized gradient descent multidimensional functional space two algorithm proposed cd mcboost based coordinate descent update one predictor component time gd mcboost based gradient descent update component jointly algorithm differ weak learner support shown bayes consistent margin enforcing convergent global minimum risk also reduce adaboost two class experiment show method outperform previous multiclass boosting approach number datasets', 'artist advertiser photographer routinely presented task creating image viewer remember may seem like image memorability purely subjective recent work show inexplicable phenomenon variation memorability image consistent across subject suggesting image intrinsically memorable others independent subject context bias paper used publicly available memorability dataset isola et al augmented object scene annotation interpretable spatial content aesthetic image property used feature selection scheme desirable explaining away property determine compact set attribute characterizes memorability individual image find image enclosed space containing people visible face memorable image vista peaceful scene contrary popular belief unusual aesthetically pleasing scene tend highly memorable work represents one first attempt understanding intrinsic image memorability open new domain investigation interface human cognition computer vision', 'consider problem optimizing sum smooth convex function non smooth convex function using proximal gradient method error present calculation gradient smooth term proximity operator respect second term show basic proximal gradient method basic proximal gradient method strong convexity assumption accelerated proximal gradient method achieve convergence rate error free case provided error decrease appropriate rate experimental result structured sparsity problem indicate sequence error appealing theoretical property lead practical performance improvement', 'analyze statistical performance recently proposed convex tensor decomposition algorithm conventionally tensor decomposition formulated non convex optimization problem hindered analysis performance show condition mean squared error convex method scale linearly quantity call normalized rank true tensor current analysis naturally extends analysis convex low rank matrix estimation tensor furthermore show numerical experiment theory precisely predict scaling behaviour practice', 'although standard formulation prediction problem involve fully observed noiseless data drawn manner many application involve noisy missing data possibly involving dependency study issue context high dimensional sparse linear regression propose novel estimator case noisy missing dependent data many standard approach noisy missing data using em algorithm lead optimization problem inherently non convex difficult establish theoretical guarantee practical algorithm approach also involves optimizing non convex program able analyze statistical error associated global optimum prove simple projected gradient descent algorithm converge polynomial time small neighborhood set global minimizers statistical side provide non asymptotic bound hold high probability case noisy missing dependent data computational side prove type condition required statistical consistency projected gradient descent algorithm converge geometric rate near global minimizer illustrate theoretical prediction simulation showing agreement predicted scaling', 'many nonparametric regressors recently shown converge rate depend intrinsic dimension data regressors thus escape curse dimension high dimensional data low intrinsic dimension e g manifold show k nn regression also adaptive intrinsic dimension particular rate local query x depend way mass ball centered x vary radius furthermore show simple way choose k k x locally x nearly achieve minimax rate x term unknown intrinsic dimension vicinity x also establish minimax rate depend particular choice metric space distribution rather minimax rate hold metric space doubling measure', 'used learn high dimensional parametric probabilistic model clas sical maximum likelihood ml learning often suffers computational tractability motivates active development non ml learning meth od yet divergent motivation form objective func tions many non ml learning method seemingly unrelated lack unified framework understand work based information geometric view parametric learning introduce general non ml learning principle termed minimum kl contraction seek optimal parameter minimizes contraction kl divergence two distribution transformed kl contraction operator show objective function several important recently developed non ml learn ing method including contrastive divergence noise contrastive estimation partial likelihood non local contrastive objective score match ing pseudo likelihood maximum conditional likelihood maximum mutual information maximum marginal likelihood conditional marginal composite likelihood unified minimum kl con traction framework different choice kl contraction operator', 'consider class sparsity inducing regularization term based submodular function previous work focused non decreasing function explore symmetric submodular function lova extension show lovasz extension may seen convex envelope function depends level set e set index whose corresponding component underlying predictor greater given constant lead class convex structured regularization term impose prior knowledge level set support underlying predictor provide unified set optimization algorithm proximal operator theoretical guarantee allowed level set recovery condition selecting specific submodular function give new interpretation known norm total variation also define new norm particular one based order statistic application clustering outlier detection noisy cut graph application change point detection presence outlier', 'multi structure model fitting traditionally taken two stage approach first sample large number model hypothesis select subset hypothesis optimise joint fitting model selection criterion disjoint two stage approach arguably suboptimal inefficient random sampling retrieve good set hypothesis optimised outcome represent good fit overcome weakness propose new multi structure fitting approach based reversible jump mcmc instrumental raising effectiveness method adaptive hypothesis generator whose proposal distribution learned incrementally online prove adaptive proposal satisfies diminishing adaptation property crucial ensuring ergodicity mcmc method effectively conduct hypothesis sampling optimisation simultaneously give superior computational efficiency method', 'consider problem computing euclidean projection vector length p onto non negative max heap ordered tree value node nonnegative value parent node le value child node euclidean projection play building block role optimization problem non negative max heap constraint constraint desirable feature follow ordered tree structure given feature selected given regression classification task parent node selected paper show euclidean projection problem admits analytical solution develop top algorithm key operation find called emph maximal root tree subtree rooted node naive approach finding maximal root tree enumerate possible root tree however scale well reveal several important property maximal root tree based design bottom algorithm merge efficiently finding maximal root tree proposed algorithm worst case linear time complexity sequential list p general tree report simulation result showing effectiveness max heap regression ordered tree structure empirical result show proposed algorithm expected linear time complexity many special case including sequential list full binary tree tree depth', 'abstract missing', 'propose novel inference framework finding maximal clique weighted graph satisfy hard constraint constraint specify graph node must belong solution well mutual exclusion graph node e set node cannot belong solution proposed inference based novel particle filter algorithm state permeation apply inference framework challenging problem learning part based deformable object model two core problem learning framework matching image patch finding salient part formulated two instance problem finding maximal clique hard constraint learning framework yield discriminative part based object model achieve good detection rate outperform method object class large deformation', 'abstract missing', 'paper consider problem compressed sensing goal recover almost sparse vector using small number fixed linear measurement problem propose novel partial hard thresholding operator leading general family iterative algorithm one extreme family yield well known hard thresholding algorithm like iti htp end spectrum lead novel algorithm call orthogonal matching pursuit replacement ompr ompr like classic greedy algorithm omp add exactly one coordinate support iteration based correlation current residual however unlike omp ompr also remove one coordinate support simple change allows u prove best known guarantee ompr term restricted isometry property condition measurement matrix contrast omp known weak performance guarantee rip also extend ompr using locality sensitive hashing get ompr hash first provably sub linear dimensionality algorithm sparse recovery proof technique novel flexible enough also permit tightest known analysis popular iterative algorithm cosamp subspace pursuit provide experimental result large problem providing recovery vector size million dimension demonstrate large scale problem proposed method robust faster existing method', 'abstract missing', 'performance markov chain monte carlo method often sensitive scaling correlation random variable interest important source information local correlation scale given hessian matrix target distribution often either computationally expensive infeasible paper propose mcmc sampler make use quasi newton approximation optimization literature approximate hessian target distribution previous sample gradient generated sampler key issue mcmc sampler depend history previous state general valid address problem using limited memory quasi newton method depend fixed window previous sample several real world datasets show quasi newton sampler effective sampler standard hamiltonian monte carlo fraction cost mcmc method require higher order derivative', 'propose online prediction version submodular set cover connection ranking repeated active learning round learning algorithm chooses sequence item algorithm receives monotone submodular function suffers loss equal cover time function number item needed item selected order chosen sequence achieve coverage constraint develop online learning algorithm whose loss converges approximately best sequence hindsight proposed algorithm readily extended setting multiple function revealed round bandit contextual bandit setting', 'study empirical strategy human follow teach target concept simple threshold robot previous study computational teaching particularly teaching dimension model curriculum learning principle offer contradictory prediction optimal strategy teacher follow teaching task show behavioral study human employ three distinct teaching strategy one consistent curriculum learning principle propose novel theoretical framework potential explanation strategy framework assumes teaching goal minimizing learner expected generalization error iteration extends standard teaching dimension model offer theoretical justification curriculum learning', 'independent component analysis ica variant successfully used unsupervised feature learning however standard ica requires orthonoramlity constraint enforced make dif cult learn overcomplete feature addition ica sensitive whitening property make challenging scale ica high dimensional data paper propose robust soft reconstruction cost ica allows u learn highly overcomplete sparse feature even unwhitened data formulation reveals formal connection ica sparse autoencoders previously observed empirically algorithm used conjunction shelf fast unconstrained optimizers show soft reconstruction cost also used prevent replicated feature tiled convolutional neural network using method learn highly overcomplete sparse feature tiled convolutional neural network obtain competitive performance wide variety object recognition task achieve state art test accuracy stl hollywood datasets', 'synaptic plasticity underlies learning thus central development memory recovery injury however often difficult detect change synaptic strength vivo since intracellular recording experimentally challenging present two method aimed inferring change coupling pair neuron extracellularly recorded spike train first using generalized bilinear model poisson output estimate time varying coupling assuming change spike timing dependent approach allows model based estimation stdp modification function pair spike train using recursive point process adaptive filtering method estimate general variation coupling strength time using simulation neuron undergoing spike timing dependent modification show true modification function recovered using multi electrode data motor cortex illustrate use technique vivo data', 'advent crowdsourcing service become quite cheap reasonably effective get dataset labeled multiple annotator short amount time various method proposed estimate consensus label correcting bias annotator different kind expertise often low quality annotator spammer annotator assign label randomly e g without actually looking instance spammer make cost acquiring label expensive potentially degrade quality consensus label paper formalize notion spammer define score used rank annotator spammer score close zero good annotator high score close one', 'abstract missing', 'develop demonstrate automatic image description method using large captioned photo collection one contribution technique automatic collection new dataset performing huge number flickr query filtering noisy result million image associated visually relevant caption collection allows u approach extremely challenging problem description generation using relatively simple non parametric method produce surprisingly effective result also develop method incorporating many state art fairly noisy estimate image content produce even pleasing result finally introduce new objective performance measure image captioning', 'bayesian filtering stochastic stimulus received great deal attention cently applied describe way biological system dy namically represent make decision environment exact result error biologically plausible setting inference point process however present exact analysis evolution mean squared error state estimation task using gaussian tuned point process sensor allows u study dynamic error optimal bayesian decoder providing insight limit obtainable task done markovian class non markovian gaussian process find optimal tuning width error minimized lead char acterization optimal encoding setting function statistic stimulus providing mathematically sound primer ecological theory sensory processing', 'show lambda return target used td lambda family algorithm maximum likelihood estimator specific model variance n step return estimate increase n introduce gamma return estimator alternative target based accurate model variance defines td gamma family complex backup temporal difference learning algorithm derive td gamma gamma return equivalent original td lambda algorithm eliminates lambda parameter perform update end episode requires time space proportional episode length derive second algorithm td gamma c capacity parameter c td gamma c requires c time time memory td lambda incremental online show td gamma outperforms td lambda setting lambda benchmark domain td gamma c performs well better td gamma intermediate setting c', 'abstract missing', 'introduce hd hierarchical deep model new compositional learning architecture integrates deep learning model structured hierarchical bayesian model specifically show learn hierarchical dirichlet process hdp prior activity top level feature deep boltzmann machine dbm compound hdp dbm model learns learn novel concept training example learning low level generic feature high level feature capture correlation among low level feature category hierarchy sharing prior high level feature typical different kind concept present efficient learning inference algorithm hdp dbm model show able learn new concept example cifar object recognition handwritten character recognition human motion capture datasets', 'paper address problem minimizing convex lipschitz function f convex compact set x stochastic bandit feedback model model algorithm allowed observe noisy realization function value f x query point x x demonstrate generalization ellipsoid algorithm incurs poly sqrt regret since algorithm regret least omega sqrt problem algorithm optimal term scaling', 'predicting node given graph fascinating theoretical problem application several domain since graph sparsification via spanning tree retains enough information making task much easier tree important special case problem although known predict node unweighted tree nearly optimal way weighted case fully satisfactory algorithm available yet fill hole introduce efficient node predictor shazoo nearly optimal weighted tree moreover show shazoo viewed common nontrivial generalization previous approach unweighted tree weighted line experiment real world datasets confirm shazoo performs well fully exploit structure input tree get close sometimes better le scalable energy minimization method', 'pomdp planning face two major computational challenge large state space long planning horizon recently introduced monte carlo value iteration mcvi tackle pomdps large discrete state space continuous state space performance degrades faced long planning horizon paper present macro mcvi extends mcvi exploiting macro action temporal abstraction provide sufficient condition macro mcvi inherit good theoretical property mcvi macro mcvi require explicit construction probabilistic model macro action thus easy apply practice experiment show macro mcvi substantially improves performance mcvi suitable macro action', 'study problem identifying best arm bandit multi bandit multi armed setting first propose algorithm called gap based exploration gape focus arm whose mean close mean best arm bandit e small gap introduce algorithm called gape v take account variance arm addition gap prove upper bound probability error algorithm since gape gape v need tune exploration parameter depends complexity problem often unknown advance also introduce variation algorithm estimate complexity online finally evaluate performance algorithm compare allocation strategy number synthetic problem', 'difficulty inverse reinforcement learning irl arises choosing best reward function since typically infinite number reward function yield given behaviour data optimal using bayesian framework address challenge using maximum posteriori map estimation reward function show previous irl algorithm modeled framework also present gradient method map estimation based sub differentiability posterior distribution show effectiveness approach comparing performance proposed method previous algorithm', 'abstract missing', 'derive algorithm generalised tensor factorisation gtf building upon well established theory generalised linear model algorithm general sense compute arbitrary factorisation message passing framework derived broad class exponential family distribution including special case tweedie distribution corresponding beta divergence bounding step size fisher scoring iteration glm obtain general update real data multiplicative update non negative data gtf framework extended easily address problem multiple observed tensor factorised simultaneously illustrate coupled factorisation approach synthetic data well musical audio restoration problem', 'describe novel technique feature combination bag word model image classification approach build discriminative compound word primitive cue learned independently training image main observation modeling joint cue distribution independently statistically robust typical classification problem attempting empirically estimate dependent joint cue distribution directly use information theoretic vocabulary compression find discriminative combination cue resulting vocabulary portmanteau word compact cue binding property support individual weighting cue final image representation state art result oxford flower caltech ucsd bird datasets demonstrate effectiveness technique compared significantly complex approach multi cue image representation', 'vector auto regressive model var useful tool analyzing time series data quite modern time series modelling task collection reliable time series turn major challenge either due slow progression dynamic process interest inaccessibility repetitive measurement dynamic process time situation however observe often easier collect large amount non sequence sample snapshot dynamic process interest work assume small amount time series data available propose method incorporate non sequence data penalized least square estimation var model consider non sequence data sample drawn stationary distribution underlying var model devise novel penalization scheme based discrete time lyapunov equation concerning covariance stationary distribution experiment synthetic video data demonstrate effectiveness proposed method']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus = []\n",
    "for i in range(0, 3847):\n",
    "   text = re.sub('[^a-zA-Z]', ' ', data['abstract'][i])\n",
    "   text = text.lower()\n",
    "   text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text) \n",
    "   text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "   text=text.split() \n",
    "   ps=PorterStemmer()\n",
    "    #Lemmatisation\n",
    "   lem = WordNetLemmatizer()\n",
    "   text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "   text = \" \".join(text)\n",
    "   corpus.append(text)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wordcloud.wordcloud.WordCloud object at 0x11a82d400>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stop_words,\n",
    "                          max_words=100,\n",
    "                          max_font_size=50, \n",
    "                          random_state=42\n",
    "                         ).generate(str(corpus))\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"word1.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3847x7036 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 80469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "X=cv.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3847x7036 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 80469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]\n",
    "a = cv.fit_transform(corpus)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'missing'),\n",
       " Text(0, 0, 'abstract'),\n",
       " Text(0, 0, 'model'),\n",
       " Text(0, 0, 'algorithm'),\n",
       " Text(0, 0, 'learning'),\n",
       " Text(0, 0, 'method'),\n",
       " Text(0, 0, 'problem'),\n",
       " Text(0, 0, 'data'),\n",
       " Text(0, 0, 'show'),\n",
       " Text(0, 0, 'approach'),\n",
       " Text(0, 0, 'based'),\n",
       " Text(0, 0, 'function'),\n",
       " Text(0, 0, 'result'),\n",
       " Text(0, 0, 'using'),\n",
       " Text(0, 0, 'feature'),\n",
       " Text(0, 0, 'image'),\n",
       " Text(0, 0, 'paper'),\n",
       " Text(0, 0, 'set'),\n",
       " Text(0, 0, 'distribution'),\n",
       " Text(0, 0, 'task')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Most frequently occuring words\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      \n",
    "                   vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                       reverse=True)\n",
    "    return words_freq[:n]\n",
    "#Convert most freq words to dataframe for plotting bar plot\n",
    "top_words = get_top_n_words(corpus, n=20)\n",
    "top_df = pd.DataFrame(top_words)\n",
    "top_df.columns=[\"Word\", \"Freq\"]\n",
    "#Barplot of most freq words\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "g = sns.barplot(x=\"Word\", y=\"Freq\", data=top_df)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bi- grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Bi-gram  Freq\n",
      "0         abstract missing  2694\n",
      "1                state art   145\n",
      "2       learning algorithm   111\n",
      "3         high dimensional    96\n",
      "4                 data set    89\n",
      "5         machine learning    89\n",
      "6               real world    87\n",
      "7      experimental result    86\n",
      "8          graphical model    72\n",
      "9     optimization problem    70\n",
      "10           loss function    69\n",
      "11  reinforcement learning    63\n",
      "12           paper propose    60\n",
      "13        learning problem    59\n",
      "14        gaussian process    56\n",
      "15             large scale    55\n",
      "16         semi supervised    54\n",
      "17         active learning    52\n",
      "18         online learning    50\n",
      "19           paper present    49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'abstract missing'),\n",
       " Text(0, 0, 'state art'),\n",
       " Text(0, 0, 'learning algorithm'),\n",
       " Text(0, 0, 'high dimensional'),\n",
       " Text(0, 0, 'data set'),\n",
       " Text(0, 0, 'machine learning'),\n",
       " Text(0, 0, 'real world'),\n",
       " Text(0, 0, 'experimental result'),\n",
       " Text(0, 0, 'graphical model'),\n",
       " Text(0, 0, 'optimization problem'),\n",
       " Text(0, 0, 'loss function'),\n",
       " Text(0, 0, 'reinforcement learning'),\n",
       " Text(0, 0, 'paper propose'),\n",
       " Text(0, 0, 'learning problem'),\n",
       " Text(0, 0, 'gaussian process'),\n",
       " Text(0, 0, 'large scale'),\n",
       " Text(0, 0, 'semi supervised'),\n",
       " Text(0, 0, 'active learning'),\n",
       " Text(0, 0, 'online learning'),\n",
       " Text(0, 0, 'paper present')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Most frequently occuring Bi-grams\n",
    "def get_top_n2_words(corpus, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=(2,2),  \n",
    "            max_features=3000).fit(corpus)\n",
    "    bag_of_words = vec1.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    return words_freq[:n]\n",
    "top2_words = get_top_n2_words(corpus, n=20)\n",
    "top2_df = pd.DataFrame(top2_words)\n",
    "top2_df.columns=[\"Bi-gram\", \"Freq\"]\n",
    "print(top2_df)\n",
    "#Barplot of most freq Bi-grams\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "h=sns.barplot(x=\"Bi-gram\", y=\"Freq\", data=top2_df)\n",
    "h.set_xticklabels(h.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tri grams  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Tri-gram  Freq\n",
      "0         support vector machine    32\n",
      "1       multiple kernel learning    27\n",
      "2       semi supervised learning    25\n",
      "3        markov decision process    21\n",
      "4       experimental result show    21\n",
      "5   principal component analysis    19\n",
      "6             markov chain monte    19\n",
      "7              chain monte carlo    19\n",
      "8            real world datasets    18\n",
      "9            markov random field    18\n",
      "10   convex optimization problem    18\n",
      "11              state art method    18\n",
      "12               real world data    17\n",
      "13         latent variable model    16\n",
      "14         high dimensional data    16\n",
      "15   latent dirichlet allocation    15\n",
      "16         state art performance    15\n",
      "17       least square regression    15\n",
      "18   empirical risk minimization    14\n",
      "19   stochastic gradient descent    14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'support vector machine'),\n",
       " Text(0, 0, 'multiple kernel learning'),\n",
       " Text(0, 0, 'semi supervised learning'),\n",
       " Text(0, 0, 'markov decision process'),\n",
       " Text(0, 0, 'experimental result show'),\n",
       " Text(0, 0, 'principal component analysis'),\n",
       " Text(0, 0, 'markov chain monte'),\n",
       " Text(0, 0, 'chain monte carlo'),\n",
       " Text(0, 0, 'real world datasets'),\n",
       " Text(0, 0, 'markov random field'),\n",
       " Text(0, 0, 'convex optimization problem'),\n",
       " Text(0, 0, 'state art method'),\n",
       " Text(0, 0, 'real world data'),\n",
       " Text(0, 0, 'latent variable model'),\n",
       " Text(0, 0, 'high dimensional data'),\n",
       " Text(0, 0, 'latent dirichlet allocation'),\n",
       " Text(0, 0, 'state art performance'),\n",
       " Text(0, 0, 'least square regression'),\n",
       " Text(0, 0, 'empirical risk minimization'),\n",
       " Text(0, 0, 'stochastic gradient descent')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_top_n3_words(corpus, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=(3,3),  \n",
    "            max_features=3000).fit(corpus)\n",
    "    bag_of_words = vec1.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    return words_freq[:n]\n",
    "top3_words = get_top_n3_words(corpus, n=20)\n",
    "top3_df = pd.DataFrame(top3_words)\n",
    "top3_df.columns=[\"Tri-gram\", \"Freq\"]\n",
    "print(top3_df)\n",
    "#Barplot of most freq Bi-grams\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "h=sns.barplot(x=\"Tri-gram\", y=\"Freq\", data=top3_df)\n",
    "h.set_xticklabels(h.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer()\n",
    "tfidf_transformer.fit_transform(X)\n",
    "# get feature names\n",
    "feature_names=cv.get_feature_names()\n",
    "# feature_names \n",
    "# # fetch document for which keywords needs to be extracted\n",
    "doc=corpus[532]\n",
    "# doc \n",
    "# # #generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.fit_transform(cv.transform([doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7036 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:\n",
      "abstract missing\n",
      "\n",
      "Keywords:\n",
      "missing 0.707\n",
      "abstract 0.707\n"
     ]
    }
   ],
   "source": [
    "#Function for sorting tf_idf in descending order\n",
    "from scipy.sparse import coo_matrix\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,5)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\nAbstract:\")\n",
    "print(doc)\n",
    "print(\"\\nKeywords:\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
